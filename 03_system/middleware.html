


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Middleware &mdash; DI-engine 0.1.0 documentation</title>
  

  <link rel="shortcut icon" href="../_static/images/favicon.ico" />
  
  

  

  
  
  

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/style.css" type="text/css" />
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="next" title="Distributed" href="distributed.html" />
  <link rel="prev" title="System Design" href="index.html" />
    <link href="../_static/css/style.css" rel="stylesheet" type="text/css">


  
  <script src="../_static/js/modernizr.min.js"></script>
  <script>
    MathJax = {
        chtml: {
            scale: 1,
            minScale: 1,
        },
        svg: {
            scale: 1,
            minScale: 1,
        }
    }
</script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/"
        aria-label="OpenMMLab"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/DI-engine" target="_blank">GitHub</a>
          </li>
          <li >
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a
                class="resource-option with-down-arrow">
                OpenDILab
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-engine" target="_blank">
                  <span class="dropdown-title">DI-engine </span>
                  <p>OpenDILab Decision AI Engine</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-star" target="_blank">
                  <span class="dropdown-title">DI-star </span>
                  <p>OpenDILab Decision AI in StarCraftII</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-drive" target="_blank">
                  <span class="dropdown-title">DI-drive </span>
                  <p>OpenDILab Auto-driving platform</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/GoBigger" target="_blank">
                  <span class="dropdown-title">GoBigger </span>
                  <p>OpenDILab Multi-Agent Environment</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-smartcross" target="_blank">
                  <span class="dropdown-title">DI-smartcross </span>
                  <p>Decision Intelligence Platform for Traffic Crossing Signal Control</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-treetensor" target="_blank">
                  <span class="dropdown-title">DI-treetensor </span>
                  <p>Tree Nested PyTorch Tensor Lib</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-sheep" target="_blank">
                  <span class="dropdown-title">DI-sheep </span>
                  <p>Deep Reinforcement Learning + 3 Tiles Game</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-model-based-RL" target="_blank">
                  <span class="dropdown-title">awesome-model-based-RL </span>
                  <p>A curated list of awesome model based RL resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-decision-transformer" target="_blank">
                  <span class="dropdown-title">awesome-decision-transformer </span>
                  <p>A curated list of Decision Transformer resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-exploration-rl" target="_blank">
                  <span class="dropdown-title">awesome-exploration-rl </span>
                  <p>A curated list of awesome exploration RL resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-multi-modal-reinforcement-learning" target="_blank">
                  <span class="dropdown-title">awesome-multi-modal-reinforcement-learning </span>
                  <p>A curated list of Multi-Modal Reinforcement Learning resources (continually updated)</p>
                </a>
              </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../00_intro/index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_quickstart/index.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_algo/index.html">RL Algorithm Taxonomy</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">System Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04_best_practice/index.html">Best Practice</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05_api_doc/index.html">API Doc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06_faq/index.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reinforcement Learning Tutorial</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../10_concepts/index.html">Introduction to RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11_dizoo/index.html">Learn From DI-zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../12_policies/index.html">RL Algorithms Cheat Sheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../13_envs/index.html">RL Env Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../20_spec/index.html">Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../21_code_style/index.html">Code Style Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../22_test/index.html">Unit Test Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../23_visual/index.html">Diagrams and Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../24_cooperation/index.html">Github Cooperation</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
            Docs
        </a> &gt;
      </li>

        
          <li><a href="index.html">System Design</a> &gt;</li>
        
      <li>Middleware</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/03_system/middleware.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
  <section id="middleware">
<h1>Middleware<a class="headerlink" href="#middleware" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
</div>
<p>In most reinforcement learning processes, there is a ‘collect-learn’ cycle between the environment and the agent – get data from the environment, train the agent, get better data, and so on. We will introduce the characteristics of each environment in the <a class="reference external" href=".../11_dizoo/index_zh.html">DI-zoo chapter</a>, and here we will focus on implementing the interaction strategy of the agent.</p>
<p>The complex strategy of reinforcement learning dictates that it is difficult to abstract all the entities involved in the interaction with objects, and as better strategies and algorithms continue to emerge, there is an endless supply of new concepts and objects. So our idea was not to do object abstraction, but to encapsulate only the process, and to ensure that the encapsulated code is reusable and replaceable. This gives rise to the concept of middleware, the foundation of the DI-engine.</p>
<a class="reference internal image-reference" href="../_images/middleware.png"><img alt="../_images/middleware.png" class="align-center" src="../_images/middleware.png" style="width: 600px;" /></a>
<p>As you can see above, each middleware (the green part in the picture) can be presumed by its name alone, and you only need to select the appropriate method in the DI-engine’s middleware library to combine them and complete the entire interaction strategy of the agent.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">task</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="n">async_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">OnlineRLContext</span><span class="p">()):</span>
    <span class="n">task</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="n">interaction_evaluator</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy</span><span class="o">.</span><span class="n">eval_mode</span><span class="p">,</span> <span class="n">evaluator_env</span><span class="p">))</span>
    <span class="n">task</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="n">eps_greedy_handler</span><span class="p">(</span><span class="n">cfg</span><span class="p">))</span>
    <span class="n">task</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="n">StepCollector</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy</span><span class="o">.</span><span class="n">collect_mode</span><span class="p">,</span> <span class="n">collector_env</span><span class="p">))</span>
    <span class="n">task</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="n">data_pusher</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">buffer_</span><span class="p">))</span>
    <span class="n">task</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="n">OffPolicyLearner</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy</span><span class="o">.</span><span class="n">learn_mode</span><span class="p">,</span> <span class="n">buffer_</span><span class="p">))</span>
    <span class="n">task</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="n">CkptSaver</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy</span><span class="p">,</span> <span class="n">train_freq</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
    <span class="n">task</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">max_step</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span>
</pre></div>
</div>
<p>Once you are familiar with the middleware, you will see that the major schools of reinforcement learning – Onpolicy, Offpolicy, Offline, etc. – have so many reusable parts of the process. With a few simple selection, you can transform the interaction flow of an offpolicy process into an onpolicy process.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">task</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="n">async_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">OnlineRLContext</span><span class="p">()):</span>
    <span class="n">task</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="n">interaction_evaluator</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy</span><span class="o">.</span><span class="n">eval_mode</span><span class="p">,</span> <span class="n">evaluator_env</span><span class="p">))</span>
    <span class="n">task</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="n">StepCollector</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy</span><span class="o">.</span><span class="n">collect_mode</span><span class="p">,</span> <span class="n">collector_env</span><span class="p">))</span>
    <span class="n">task</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="n">gae_estimator</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy</span><span class="o">.</span><span class="n">collect_mode</span><span class="p">))</span>
    <span class="n">task</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="n">multistep_trainer</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy</span><span class="o">.</span><span class="n">learn_mode</span><span class="p">))</span>
    <span class="n">task</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="n">CkptSaver</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy</span><span class="p">,</span> <span class="n">train_freq</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
    <span class="n">task</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">max_step</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span>
</pre></div>
</div>
<section id="context">
<h2>Context<a class="headerlink" href="#context" title="Permalink to this headline">¶</a></h2>
<p>Contexts are messengers that pass data between middleware, and different interaction policies determine what type of context they should use.
For example, <code class="docutils literal notranslate"><span class="pre">OnlineRLContext</span></code> and <code class="docutils literal notranslate"><span class="pre">OfflineRLContext</span></code> are provided in DI-engine.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@dataclasses</span><span class="o">.</span><span class="n">dataclass</span>
<span class="k">class</span> <span class="nc">OnlineRLContext</span><span class="p">(</span><span class="n">Context</span><span class="p">):</span>

    <span class="c1"># common</span>
    <span class="n">total_step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">env_step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">env_episode</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">train_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">train_data</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keep</span><span class="p">(</span><span class="s1">&#39;env_step&#39;</span><span class="p">,</span> <span class="s1">&#39;env_episode&#39;</span><span class="p">,</span> <span class="s1">&#39;train_iter&#39;</span><span class="p">,</span> <span class="s1">&#39;last_eval_iter&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">OnlineRLContext</span></code> holds the data needed for online training, and the task of each middleware is to use this data and submit new data to the context. For example, the task of the OffPolicyLearner middleware is to train the model using ctx.train_data and write the training results back to ctx.train_iter.</p>
<p>At the beginning of each loop, the context is replaced by a new instance, which ensures that the middleware only needs to focus on the data flow within a single loop, simplifying the logic and reducing the risk of memory leaks.</p>
<p>If you need to save some variables to the next loop, such as env_step, train_iter, and other values that need to be accumulated, you can set it as a reserved field with the ctx.keep method.
The variables called by ctx.keep are reserved for the next iteration, when the context is initialized to a new instance,
and the other variables will be reinitialized.
Note that, in theory, ctx.keep does not need and should not be used to keep collections or more complex variables,
such as list, dict, torch.tensor, or torch.nn.Module. It should only keep int, float and other types of data to the next iteration, if needed.</p>
<p>Note: __post_init__(self) is a method called immediately after __init__(self). In our Context, it means calling this method after each field is initialized.
We call self.keep in this function because we need to initialize each field before calling self.keep to keep selected variables.</p>
<section id="v0-4-2-changes-update-context-from-dict-to-dataclass">
<h3>v0.4.2 changes: Update Context from dict to dataclass<a class="headerlink" href="#v0-4-2-changes-update-context-from-dict-to-dataclass" title="Permalink to this headline">¶</a></h3>
<p>In <a class="reference external" href="https://github.com/opendilab/DI-engine/releases/tag/v0.4.2">v0.4.2</a>, We changed the Context from dict to dataclass.
The reason for this change is:</p>
<ul class="simple">
<li><p>Prevent the arbitrary addition of new variables during development, i.e. the variables in context must be clearly defined in the definition of Context class.</p></li>
<li><p>Prevent the access of variables using string, i.e. prevent ctx[‘xxx’].</p></li>
</ul>
<p>Because for middlewares, passing data through Context is different from passing data through input and output parameters of a function, for which there is an enforced constraint.
Arbitrarily defining a new variable externally, or using strings to access variables in the Context, can easily lead to confusion when reading code or cooperation,
and can easily lead to errors when combing different middleware together.</p>
<p>By changing the Context to the dataclass, we use the attributes rather than strings to access specific variables in the Context, and prevent the addition of new fields externally.
If you need to add a new field to the Context,
please do it during the <a class="reference external" href="https://github.com/opendilab/DI-engine/blob/main/ding/framework/context.py">initialization phase</a> .
Here’s a concrete example of a custom Context:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@dataclasses</span><span class="o">.</span><span class="n">dataclass</span>
<span class="k">class</span> <span class="nc">MyContext</span><span class="p">(</span><span class="n">Context</span><span class="p">):</span>

    <span class="c1"># common</span>
    <span class="n">total_step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">var1</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">var2</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">var3</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">var4</span><span class="p">:</span> <span class="n">List</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keep</span><span class="p">(</span><span class="s1">&#39;var1&#39;</span><span class="p">,</span> <span class="s1">&#39;var2&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>If you think a new field needs to be added to DI-egnine, make a PR to DI-engine and explain it.</p>
</section>
<section id="the-introduction-of-context-variables">
<h3>The introduction of Context variables<a class="headerlink" href="#the-introduction-of-context-variables" title="Permalink to this headline">¶</a></h3>
<p>Note: Updated position does not include the case that ctx.attribute = None.</p>
<section id="onlinerlcontext">
<h4>OnlineRLContext<a class="headerlink" href="#onlinerlcontext" title="Permalink to this headline">¶</a></h4>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 26%" />
<col style="width: 26%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Attribute</p></th>
<th class="head"><p>Keeped</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Role</p></th>
<th class="head"><p>Updated position</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>total_step</p></td>
<td><p>True</p></td>
<td><p>int</p></td>
<td><p>The number of total iteration steps.</p></td>
<td><p>In the beginning of each middleware execution loop.</p></td>
</tr>
<tr class="row-odd"><td><p>env_step</p></td>
<td><p>True</p></td>
<td><p>int</p></td>
<td><p>The number of environment steps.</p></td>
<td><p>rolloutor</p></td>
</tr>
<tr class="row-even"><td><p>env_episode</p></td>
<td><p>True</p></td>
<td><p>int</p></td>
<td><p>The number of environment episodes.</p></td>
<td><p>rolloutor</p></td>
</tr>
<tr class="row-odd"><td><p>train_iter</p></td>
<td><p>True</p></td>
<td><p>int</p></td>
<td><p>The number of training iterations.</p></td>
<td><p>trainer, multistep_trainer</p></td>
</tr>
<tr class="row-even"><td><p>train_data</p></td>
<td><p>False</p></td>
<td><p>Union[Dict, List]</p></td>
<td><p>The fetched data used to be trained.</p></td>
<td><p>gae_estimator, offpolicy_data_fetcher, offline_data_fetcher, her_data_enhancer</p></td>
</tr>
<tr class="row-odd"><td><p>train_output</p></td>
<td><p>False</p></td>
<td><p>Union[Dict, List[Dict]]</p></td>
<td><p>The training output including logit, action and other info.</p></td>
<td><p>OffPolicyLearner, HERLearner(List), trainer, multistep_trainer(Dict)</p></td>
</tr>
<tr class="row-even"><td><p>collect_kwargs</p></td>
<td><p>False</p></td>
<td><p>dict</p></td>
<td><p>The dict include epsilon value.</p></td>
<td><p>eps_greedy_handler</p></td>
</tr>
<tr class="row-odd"><td><p>obs</p></td>
<td><p>False</p></td>
<td><p>ttorch.Tensor</p></td>
<td><p>The input observations collected from all collector environments.</p></td>
<td><p>inferencer</p></td>
</tr>
<tr class="row-even"><td><p>action</p></td>
<td><p>False</p></td>
<td><p>List</p></td>
<td><p>The inferred actions listed by env_id.</p></td>
<td><p>inferencer</p></td>
</tr>
<tr class="row-odd"><td><p>inference_output</p></td>
<td><p>False</p></td>
<td><p>Dict[int, Dict]</p></td>
<td><p>The dict of which the key is env_id (int), and the value is inference result (Dict).</p></td>
<td><p>inferencer</p></td>
</tr>
<tr class="row-even"><td><p>trajectories</p></td>
<td><p>False</p></td>
<td><p>list</p></td>
<td><p>The trajectories collected from environment.</p></td>
<td><p>StepCollector, nstep_reward_enhancer</p></td>
</tr>
<tr class="row-odd"><td><p>episodes</p></td>
<td><p>False</p></td>
<td><p>list</p></td>
<td><p>The episodes collected from environment.</p></td>
<td><p>EpisodeCollector</p></td>
</tr>
<tr class="row-even"><td><p>trajectory_end_idx</p></td>
<td><p>False</p></td>
<td><p>list</p></td>
<td><p>The end index of each trajectory in ctx.trajectories.</p></td>
<td><p>StepCollector</p></td>
</tr>
<tr class="row-odd"><td><p>eval_value</p></td>
<td><p>False</p></td>
<td><p>float</p></td>
<td><p>The average reward in the current evaluation.</p></td>
<td><p>interaction_evaluator, metric_evaluator</p></td>
</tr>
<tr class="row-even"><td><p>last_eval_iter</p></td>
<td><p>True</p></td>
<td><p>int</p></td>
<td><p>The last ctx.train_iter that is evaluated.</p></td>
<td><p>interaction_evaluator, metric_evaluator</p></td>
</tr>
</tbody>
</table>
</section>
<section id="offlinerlcontext">
<h4>OfflineRLContext<a class="headerlink" href="#offlinerlcontext" title="Permalink to this headline">¶</a></h4>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 26%" />
<col style="width: 26%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Attribute</p></th>
<th class="head"><p>Keeped</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Role</p></th>
<th class="head"><p>Updated position</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>total_step</p></td>
<td><p>True</p></td>
<td><p>int</p></td>
<td><p>The number of total iteration steps.</p></td>
<td><p>In the beginning of each middleware execution loop.</p></td>
</tr>
<tr class="row-odd"><td><p>train_epoch</p></td>
<td><p>False</p></td>
<td><p>int</p></td>
<td><p>The count of training epoches.</p></td>
<td><p>offline_data_fetcher</p></td>
</tr>
<tr class="row-even"><td><p>train_iter</p></td>
<td><p>True</p></td>
<td><p>int</p></td>
<td><p>The number of training iterations.</p></td>
<td><p>trainer, multistep_trainer</p></td>
</tr>
<tr class="row-odd"><td><p>train_data</p></td>
<td><p>False</p></td>
<td><p>Union[Dict, List]</p></td>
<td><p>The fetched data used to be trained.</p></td>
<td><p>gae_estimator, offpolicy_data_fetcher, offline_data_fetcher, her_data_enhancer</p></td>
</tr>
<tr class="row-even"><td><p>train_output</p></td>
<td><p>False</p></td>
<td><p>Union[Dict, List[Dict]]</p></td>
<td><p>The training output including logit, action and other info.</p></td>
<td><p>OffPolicyLearner, HERLearner(List), trainer, multistep_trainer(Dict)</p></td>
</tr>
<tr class="row-odd"><td><p>eval_value</p></td>
<td><p>False</p></td>
<td><p>float</p></td>
<td><p>The average reward in the current evaluation.</p></td>
<td><p>interaction_evaluator, metric_evaluator</p></td>
</tr>
<tr class="row-even"><td><p>last_eval_iter</p></td>
<td><p>True</p></td>
<td><p>int</p></td>
<td><p>The last ctx.train_iter that is evaluated.</p></td>
<td><p>interaction_evaluator, metric_evaluator</p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>
<section id="using-task-to-execute-tasks-asynchronously">
<h2>Using task to execute tasks asynchronously<a class="headerlink" href="#using-task-to-execute-tasks-asynchronously" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">Task</span></code> is a global object used by DI-engine to manage reinforcement learning interaction tasks. All runtime state is maintained within task, and some syntactic sugar is provided to help make the process easier.</p>
<p>Asynchrony is of great benefit in a time-critical training environment. If the data for the next training (CPU intensive work) can be collected while the model is being trained (GPU intensive work), the training time can theoretically be halved. To implement the asynchrony, one needs to control complex processes and carefully maintain various states. Now, with middleware and tasks, it is possible to change only one parameter to achieve asynchrony in each step.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Sequential execution</span>
<span class="k">with</span> <span class="n">task</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="n">async_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">OnlineRLContext</span><span class="p">()):</span>
    <span class="o">...</span>

<span class="c1"># Asynchronous execution</span>
<span class="k">with</span> <span class="n">task</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="n">async_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">OnlineRLContext</span><span class="p">()):</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>In addition to training and collection, there are many ways to take advantage of asynchrony, such as moving the next batch of data to the GPU earlier while training the model, and evaluating the performance of historical models while training the model. In practice, you may want to try more to speed up the whole interaction process by asynchronous execution.</p>
<img alt="../_images/async.png" class="align-center" src="../_images/async.png" />
</section>
<section id="middleware-in-different-stages">
<h2>Middleware in different stages<a class="headerlink" href="#middleware-in-different-stages" title="Permalink to this headline">¶</a></h2>
<p>Most of the middleware can correspond to different stages. You can see the correspondence between the existing middleware and the stages in the following diagram in order to combine the various middleware correctly.</p>
<img alt="../_images/pipeline.png" class="align-center" src="../_images/pipeline.png" />
</section>
</section>


              </article>
              
            </div>
            <footer>
  
  <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
    
    <a href="distributed.html" class="btn btn-neutral float-right" title="Distributed" accesskey="n"
      rel="next">Next <img src="../_static/images/chevron-right-blue.svg"
        class="next-page"></a>
    
    
    <a href="index.html" class="btn btn-neutral" title="System Design" accesskey="p"
      rel="prev"><img src="../_static/images/chevron-right-blue.svg" class="previous-page"> Previous</a>
    
  </div>
  

  <hr>

  <div role="contentinfo">
    <p>
      &copy; Copyright 2021, OpenDILab Contributors.

    </p>
  </div>
  
  <div>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a
      href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the
      Docs</a>.
  </div>
   

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Middleware</a><ul>
<li><a class="reference internal" href="#context">Context</a><ul>
<li><a class="reference internal" href="#v0-4-2-changes-update-context-from-dict-to-dataclass">v0.4.2 changes: Update Context from dict to dataclass</a></li>
<li><a class="reference internal" href="#the-introduction-of-context-variables">The introduction of Context variables</a><ul>
<li><a class="reference internal" href="#onlinerlcontext">OnlineRLContext</a></li>
<li><a class="reference internal" href="#offlinerlcontext">OfflineRLContext</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#using-task-to-execute-tasks-asynchronously">Using task to execute tasks asynchronously</a></li>
<li><a class="reference internal" href="#middleware-in-different-stages">Middleware in different stages</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="../"
    src="../_static/documentation_options.js"></script>
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
  <script src="../_static/jquery.js"></script>
  <script src="../_static/underscore.js"></script>
  <script src="../_static/doctools.js"></script>
  

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  </div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/" aria-label="OpenMMLab"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/DI-engine" target="_blank">GitHub</a>
          </li>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>