


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ding.envs.env_wrappers.env_wrappers &mdash; DI-engine 0.1.0 documentation</title>
  

  <link rel="shortcut icon" href="../../../../_static/images/favicon.ico" />
  
  

  

  
  
  

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/style.css" type="text/css" />
  <link rel="index" title="Index" href="../../../../genindex.html" />
  <link rel="search" title="Search" href="../../../../search.html" />
    <link href="../../../../_static/css/style.css" rel="stylesheet" type="text/css">


  
  <script src="../../../../_static/js/modernizr.min.js"></script>
  <script>
    MathJax = {
        chtml: {
            scale: 1,
            minScale: 1,
        },
        svg: {
            scale: 1,
            minScale: 1,
        }
    }
</script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/"
        aria-label="OpenMMLab"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/DI-engine" target="_blank">GitHub</a>
          </li>
          <li >
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a
                class="resource-option with-down-arrow">
                OpenDILab
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-engine" target="_blank">
                  <span class="dropdown-title">DI-engine </span>
                  <p>OpenDILab Decision AI Engine</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-star" target="_blank">
                  <span class="dropdown-title">DI-star </span>
                  <p>OpenDILab Decision AI in StarCraftII</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-drive" target="_blank">
                  <span class="dropdown-title">DI-drive </span>
                  <p>OpenDILab Auto-driving platform</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/GoBigger" target="_blank">
                  <span class="dropdown-title">GoBigger </span>
                  <p>OpenDILab Multi-Agent Environment</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-smartcross" target="_blank">
                  <span class="dropdown-title">DI-smartcross </span>
                  <p>Decision Intelligence Platform for Traffic Crossing Signal Control</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-treetensor" target="_blank">
                  <span class="dropdown-title">DI-treetensor </span>
                  <p>Tree Nested PyTorch Tensor Lib</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-sheep" target="_blank">
                  <span class="dropdown-title">DI-sheep </span>
                  <p>Deep Reinforcement Learning + 3 Tiles Game</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-model-based-RL" target="_blank">
                  <span class="dropdown-title">awesome-model-based-RL </span>
                  <p>A curated list of awesome model based RL resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-decision-transformer" target="_blank">
                  <span class="dropdown-title">awesome-decision-transformer </span>
                  <p>A curated list of Decision Transformer resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-exploration-rl" target="_blank">
                  <span class="dropdown-title">awesome-exploration-rl </span>
                  <p>A curated list of awesome exploration RL resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-multi-modal-reinforcement-learning" target="_blank">
                  <span class="dropdown-title">awesome-multi-modal-reinforcement-learning </span>
                  <p>A curated list of Multi-Modal Reinforcement Learning resources (continually updated)</p>
                </a>
              </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../00_intro/index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_quickstart/index.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_algo/index.html">RL Algorithm Taxonomy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_system/index.html">System Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../04_best_practice/index.html">Best Practice</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../05_api_doc/index.html">API Doc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_faq/index.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reinforcement Learning Tutorial</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../10_concepts/index.html">Introduction to RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../11_dizoo/index.html">Learn From DI-zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../12_policies/index.html">RL Algorithms Cheat Sheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../13_envs/index.html">RL Env Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../20_spec/index.html">Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../21_code_style/index.html">Code Style Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../22_test/index.html">Unit Test Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../23_visual/index.html">Diagrams and Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../24_cooperation/index.html">Github Cooperation</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
            Docs
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
      <li>ding.envs.env_wrappers.env_wrappers</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
  <h1>Source code for ding.envs.env_wrappers.env_wrappers</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This code is adapted from OpenAI Baselines:</span>
<span class="sd">    https://github.com/openai/baselines/blob/master/baselines/common/atari_wrappers.py</span>

<span class="sd">List of Environment Wrappers:</span>
<span class="sd">- NoopResetWrapper: This wrapper facilitates the sampling of initial states by executing a random number of</span>
<span class="sd">    no-operation actions upon environment reset.</span>
<span class="sd">- MaxAndSkipWrapper: Incorporates max pooling across time steps, a method that reduces the temporal dimension by taking</span>
<span class="sd">    the maximum value over specified time intervals.</span>
<span class="sd">- WarpFrameWrapper: Implements frame warping by resizing the images to 84x84, a common preprocessing step in</span>
<span class="sd">    reinforcement learning on visual data, as described in the DeepMind Nature paper and subsequent works.</span>
<span class="sd">- ScaledFloatFrameWrapper: Normalizes observations to a range of 0 to 1, which is a common requirement for neural</span>
<span class="sd">    network inputs.</span>
<span class="sd">- ClipRewardWrapper: Clips the reward to {-1, 0, +1} based on its sign. This simplifies the reward structure and</span>
<span class="sd">    can make learning more stable in environments with high variance in rewards.</span>
<span class="sd">- DelayRewardWrapper: Returns cumulative reward at defined intervals, and at all other times, returns a reward of 0.</span>
<span class="sd">    This can be useful for sparse reward problems.</span>
<span class="sd">- FrameStackWrapper: Stacks the latest &#39;n&#39; frames as a single observation. This allows the agent to have a sense of</span>
<span class="sd">    dynamics and motion from the stacked frames.</span>
<span class="sd">- ObsTransposeWrapper: Transposes the observation to bring the channel to the first dimension, a common requirement</span>
<span class="sd">    for convolutional neural networks.</span>
<span class="sd">- ObsNormWrapper: Normalizes observations based on a running mean and standard deviation. This can help to standardize</span>
<span class="sd">    inputs for the agent and speed up learning.</span>
<span class="sd">- RewardNormWrapper: Normalizes reward based on a running standard deviation, which can stabilize learning in</span>
<span class="sd">    environments with high variance in rewards.</span>
<span class="sd">- RamWrapper: Wraps a RAM-based environment into an image-like environment. This can be useful for applying</span>
<span class="sd">    image-based algorithms to RAM-based Atari games.</span>
<span class="sd">- EpisodicLifeWrapper: Treats end of life as the end of an episode, but only resets on true game over. This can help</span>
<span class="sd">    the agent better differentiate between losing a life and losing the game.</span>
<span class="sd">- FireResetWrapper: Executes the &#39;fire&#39; action upon environment reset. This is specific to certain Atari games where</span>
<span class="sd">    the &#39;fire&#39; action starts the game.</span>
<span class="sd">- GymHybridDictActionWrapper: Transforms the original `gym.spaces.Tuple` action space into a `gym.spaces.Dict`.</span>
<span class="sd">- FlatObsWrapper: Flattens image and language observations into a single vector, which can be helpful for input into</span>
<span class="sd">    certain types of models.</span>
<span class="sd">- StaticObsNormWrapper: Provides functionality for normalizing observations according to a static mean and</span>
<span class="sd">    standard deviation.</span>
<span class="sd">- EvalEpisodeReturnWrapper: Evaluates the return over an episode during evaluation, providing a more comprehensive</span>
<span class="sd">    view of the agent&#39;s performance.</span>
<span class="sd">- GymToGymnasiumWrapper: Adapts environments from the Gym library to be compatible with the Gymnasium library.</span>
<span class="sd">- AllinObsWrapper: Consolidates all information into the observation, useful for environments where the agent&#39;s</span>
<span class="sd">    observation should include additional information such as the current score or time remaining.</span>
<span class="sd">- ObsPlusPrevActRewWrapper: This wrapper is used in policy NGU. It sets a dict as the new wrapped observation,</span>
<span class="sd">    which includes the current observation, previous action and previous reward.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">operator</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">reduce</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span>

<span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">gymnasium</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">easydict</span> <span class="kn">import</span> <span class="n">EasyDict</span>

<span class="kn">from</span> <span class="nn">ding.torch_utils</span> <span class="kn">import</span> <span class="n">to_ndarray</span>
<span class="kn">from</span> <span class="nn">ding.utils</span> <span class="kn">import</span> <span class="n">ENV_WRAPPER_REGISTRY</span><span class="p">,</span> <span class="n">import_module</span>


<div class="viewcode-block" id="NoopResetWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.NoopResetWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;noop_reset&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">NoopResetWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">       Sample initial states by taking random number of no-ops on reset.  No-op is assumed to be action 0.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, reset</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): the environment to wrap.</span>
<span class="sd">        - noop_max (:obj:`int`): the maximum value of no-ops to run.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="NoopResetWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.NoopResetWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">,</span> <span class="n">noop_max</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the NoopResetWrapper.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): the environment to wrap.</span>
<span class="sd">            - noop_max (:obj:`int`): the maximum value of no-ops to run. Defaults to 30.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noop_max</span> <span class="o">=</span> <span class="n">noop_max</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noop_action</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">assert</span> <span class="n">env</span><span class="o">.</span><span class="n">unwrapped</span><span class="o">.</span><span class="n">get_action_meanings</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;NOOP&#39;</span></div>

<div class="viewcode-block" id="NoopResetWrapper.reset"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.NoopResetWrapper.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Resets the state of the environment and returns an initial observation,</span>
<span class="sd">            after taking a random number of no-ops.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`Any`): The initial observation after no-ops.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">noops</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noop_max</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">noops</span><span class="p">):</span>
            <span class="n">obs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noop_action</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                <span class="n">obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">obs</span></div></div>


<div class="viewcode-block" id="MaxAndSkipWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.MaxAndSkipWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;max_and_skip&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">MaxAndSkipWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">       Wraps the environment to return only every ``skip``-th frame (frameskipping) \</span>
<span class="sd">       using most recent raw observations (for max pooling across time steps).</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, step</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">        - skip (:obj:`int`): Number of ``skip``-th frame. Defaults to 4.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="MaxAndSkipWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.MaxAndSkipWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">,</span> <span class="n">skip</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the MaxAndSkipWrapper.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">            - skip (:obj:`int`): Number of ``skip``-th frame. Defaults to 4.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_skip</span> <span class="o">=</span> <span class="n">skip</span></div>

<div class="viewcode-block" id="MaxAndSkipWrapper.step"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.MaxAndSkipWrapper.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Take the given action and repeat it for a specified number of steps. \</span>
<span class="sd">            The rewards are summed up and the maximum frame over the last observations is returned.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - action (:obj:`Any`): The action to repeat.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - max_frame (:obj:`np.array`): Max over last observations</span>
<span class="sd">            - total_reward (:obj:`Any`): Sum of rewards after previous action.</span>
<span class="sd">            - done (:obj:`Bool`): Whether the episode has ended.</span>
<span class="sd">            - info (:obj:`Dict`): Contains auxiliary diagnostic information (helpful for  \</span>
<span class="sd">                debugging, and sometimes learning)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs_list</span><span class="p">,</span> <span class="n">total_reward</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="p">[],</span> <span class="mf">0.</span><span class="p">,</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_skip</span><span class="p">):</span>
            <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">obs_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
            <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
            <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="n">max_frame</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">obs_list</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">max_frame</span><span class="p">,</span> <span class="n">total_reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span></div></div>


<div class="viewcode-block" id="WarpFrameWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.WarpFrameWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;warp_frame&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">WarpFrameWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">ObservationWrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        The WarpFrameWrapper class is a gym observation wrapper that resizes</span>
<span class="sd">        the frame of an environment observation to a specified size (default is 84x84).</span>
<span class="sd">        This is often used in the preprocessing pipeline of observations in reinforcement learning,</span>
<span class="sd">        especially for visual observations from Atari environments.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, observation</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): the environment to wrap.</span>
<span class="sd">        - size (:obj:`int`): the size to which the frames are to be resized.</span>
<span class="sd">        - observation_space (:obj:`gym.Space`): the observation space of the wrapped environment.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="WarpFrameWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.WarpFrameWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">84</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Constructor for WarpFrameWrapper class, initializes the environment and the size.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): the environment to wrap.</span>
<span class="sd">            - size (:obj:`int`): the size to which the frames are to be resized. Default is 84.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="n">obs_space</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obs_space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">tuple</span><span class="o">.</span><span class="n">Tuple</span><span class="p">):</span>
            <span class="n">obs_space</span> <span class="o">=</span> <span class="p">(</span><span class="n">obs_space</span><span class="p">,</span> <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">tuple</span><span class="o">.</span><span class="n">Tuple</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span>
                    <span class="n">low</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">obs_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">low</span><span class="p">),</span>
                    <span class="n">high</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">obs_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">high</span><span class="p">),</span>
                    <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">),</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">obs_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
                <span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">obs_space</span><span class="p">))</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="WarpFrameWrapper.observation"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.WarpFrameWrapper.observation">[docs]</a>    <span class="k">def</span> <span class="nf">observation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frame</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Resize the frame (observation) to the desired size.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - frame (:obj:`np.ndarray`): the frame to be resized.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - frame (:obj:`np.ndarray`): the resized frame.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">cv2</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">ditk</span> <span class="kn">import</span> <span class="n">logging</span>
            <span class="kn">import</span> <span class="nn">sys</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Please install opencv-python first.&quot;</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># deal with the `channel_first` case</span>
        <span class="k">if</span> <span class="n">frame</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
            <span class="n">frame</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">frame</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">),</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">INTER_AREA</span><span class="p">)</span>
            <span class="n">frame</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">frame</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_RGB2GRAY</span><span class="p">)</span>
            <span class="n">frame</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">),</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">INTER_AREA</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">frame</span></div></div>


<div class="viewcode-block" id="ScaledFloatFrameWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ScaledFloatFrameWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;scaled_float_frame&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ScaledFloatFrameWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">ObservationWrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        The ScaledFloatFrameWrapper normalizes observations to between 0 and 1.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, observation</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ScaledFloatFrameWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ScaledFloatFrameWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the ScaledFloatFrameWrapper, setting the scale and bias for normalization.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): the environment to wrap.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="n">low</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
        <span class="n">high</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">low</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">high</span> <span class="o">-</span> <span class="n">low</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span></div>

<div class="viewcode-block" id="ScaledFloatFrameWrapper.observation"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ScaledFloatFrameWrapper.observation">[docs]</a>    <span class="k">def</span> <span class="nf">observation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Scale the observation to be within the range [0, 1].</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): the original observation.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - scaled_observation (:obj:`np.ndarray`): the scaled observation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">((</span><span class="n">observation</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ClipRewardWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ClipRewardWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;clip_reward&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ClipRewardWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">RewardWrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        The ClipRewardWrapper class is a gym reward wrapper that clips the reward to {-1, 0, +1} based on its sign.</span>
<span class="sd">        This can be used to normalize the scale of the rewards in reinforcement learning algorithms.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, reward</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): the environment to wrap.</span>
<span class="sd">        - reward_range (:obj:`Tuple[int, int]`): the range of the reward values after clipping.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ClipRewardWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ClipRewardWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the ClipRewardWrapper class.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): the environment to wrap.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_range</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="ClipRewardWrapper.reward"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ClipRewardWrapper.reward">[docs]</a>    <span class="k">def</span> <span class="nf">reward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Clip the reward to {-1, 0, +1} based on its sign. Note: np.sign(0) == 0.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - reward (:obj:`float`): the original reward.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - reward (:obj:`float`): the clipped reward.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ActionRepeatWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ActionRepeatWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;action_repeat&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ActionRepeatWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        The ActionRepeatWrapper class is a gym wrapper that repeats the same action for a number of steps.</span>
<span class="sd">        This wrapper is particularly useful in environments where the desired effect is achieved by maintaining</span>
<span class="sd">        the same action across multiple time steps. For instance, some physical environments like motion control</span>
<span class="sd">        tasks might require consistent force input to produce a significant state change.</span>

<span class="sd">        Using this wrapper can reduce the temporal complexity of the problem, as it allows the agent to perform</span>
<span class="sd">        multiple actions within a single time step. This can speed up learning, as the agent has fewer decisions</span>
<span class="sd">        to make within a time step. However, it may also sacrifice some level of decision-making precision, as the</span>
<span class="sd">        agent cannot change its action across successive time steps.</span>

<span class="sd">        Note that the use of the ActionRepeatWrapper may not be suitable for all types of environments. Specifically,</span>
<span class="sd">        it may not be the best choice for environments where new decisions must be made at each time step, or where</span>
<span class="sd">        the time sequence of actions has a significant impact on the outcome.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, step</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): the environment to wrap.</span>
<span class="sd">        - action_repeat (:obj:`int`): the number of times to repeat the action.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ActionRepeatWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ActionRepeatWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">,</span> <span class="n">action_repeat</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the ActionRepeatWrapper class.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): the environment to wrap.</span>
<span class="sd">            - action_repeat (:obj:`int`): the number of times to repeat the action. Default is 1.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_repeat</span> <span class="o">=</span> <span class="n">action_repeat</span></div>

<div class="viewcode-block" id="ActionRepeatWrapper.step"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ActionRepeatWrapper.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Take the given action and repeat it for a specified number of steps. The rewards are summed up.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - action (:obj:`Union[int, np.ndarray]`): The action to repeat.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - obs (:obj:`np.ndarray`): The observation after repeating the action.</span>
<span class="sd">            - reward (:obj:`float`): The sum of rewards after repeating the action.</span>
<span class="sd">            - done (:obj:`bool`): Whether the episode has ended.</span>
<span class="sd">            - info (:obj:`Dict`): Contains auxiliary diagnostic information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_repeat</span><span class="p">):</span>
            <span class="n">obs</span><span class="p">,</span> <span class="n">rew</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">reward</span> <span class="o">+=</span> <span class="n">rew</span> <span class="ow">or</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="k">return</span> <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span></div></div>


<div class="viewcode-block" id="DelayRewardWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.DelayRewardWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;delay_reward&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">DelayRewardWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        The DelayRewardWrapper class is a gym wrapper that delays the reward. It cumulates the reward over a</span>
<span class="sd">        predefined number of steps and returns the cumulated reward only at the end of this interval.</span>
<span class="sd">        At other times, it returns a reward of 0.</span>

<span class="sd">        This wrapper is particularly useful in environments where the impact of an action is not immediately</span>
<span class="sd">        observable, but rather delayed over several steps. For instance, in strategic games or planning tasks,</span>
<span class="sd">        the effect of an action may not be directly noticeable, but it contributes to a sequence of actions that</span>
<span class="sd">        leads to a reward. In these cases, delaying the reward to match the action-effect delay can make the</span>
<span class="sd">        learning process more consistent with the problem&#39;s nature.</span>

<span class="sd">        However, using this wrapper may increase the difficulty of learning, as the agent needs to associate its</span>
<span class="sd">        actions with delayed outcomes. It also introduces a non-standard reward structure, which could limit the</span>
<span class="sd">        applicability of certain reinforcement learning algorithms.</span>

<span class="sd">        Note that the use of the DelayRewardWrapper may not be suitable for all types of environments. Specifically,</span>
<span class="sd">        it may not be the best choice for environments where the effect of actions is immediately observable and the</span>
<span class="sd">        reward should be assigned accordingly.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, reset, step</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): the environment to wrap.</span>
<span class="sd">        - delay_reward_step (:obj:`int`): the number of steps over which to delay and cumulate the reward.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="DelayRewardWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.DelayRewardWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">,</span> <span class="n">delay_reward_step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the DelayRewardWrapper class.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): the environment to wrap.</span>
<span class="sd">            - delay_reward_step (:obj:`int`): the number of steps over which to delay and cumulate the reward.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_delay_reward_step</span> <span class="o">=</span> <span class="n">delay_reward_step</span></div>

<div class="viewcode-block" id="DelayRewardWrapper.reset"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.DelayRewardWrapper.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">         Overview:</span>
<span class="sd">             Resets the state of the environment and resets the delay reward duration and current delay reward.</span>
<span class="sd">         Returns:</span>
<span class="sd">             - obs (:obj:`np.ndarray`): the initial observation of the environment.</span>
<span class="sd">         &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_delay_reward_duration</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_delay_reward</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">obs</span></div>

<div class="viewcode-block" id="DelayRewardWrapper.step"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.DelayRewardWrapper.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Take the given action and repeat it for a specified number of steps. The rewards are summed up.</span>
<span class="sd">            If the number of steps equals the delay reward step, return the cumulated reward and reset the</span>
<span class="sd">            delay reward duration and current delay reward. Otherwise, return a reward of 0.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - action (:obj:`Union[int, np.ndarray]`): the action to take in the step.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - obs (:obj:`np.ndarray`): The observation after the step.</span>
<span class="sd">            - reward (:obj:`float`): The cumulated reward after the delay reward step or 0.</span>
<span class="sd">            - done (:obj:`bool`): Whether the episode has ended.</span>
<span class="sd">            - info (:obj:`Dict`): Contains auxiliary diagnostic information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_delay_reward</span> <span class="o">+=</span> <span class="n">reward</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_delay_reward_duration</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">done</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_delay_reward_duration</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_delay_reward_step</span><span class="p">:</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_delay_reward</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_current_delay_reward</span> <span class="o">=</span> <span class="mf">0.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_delay_reward_duration</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="k">return</span> <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span></div></div>


<div class="viewcode-block" id="EvalEpisodeReturnWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.EvalEpisodeReturnWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;eval_episode_return&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">EvalEpisodeReturnWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        A wrapper for a gym environment that accumulates rewards at every timestep, and returns the total reward at the</span>
<span class="sd">        end of the episode in `info`. This is used for evaluation purposes.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, reset, step</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): the environment to wrap.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="EvalEpisodeReturnWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.EvalEpisodeReturnWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the EvalEpisodeReturnWrapper. This involves setting up the environment to wrap.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span></div>

<div class="viewcode-block" id="EvalEpisodeReturnWrapper.reset"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.EvalEpisodeReturnWrapper.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Reset the environment and initialize the accumulated reward to zero.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - obs (:obj:`np.ndarray`): The initial observation from the environment.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_eval_episode_return</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span></div>

<div class="viewcode-block" id="EvalEpisodeReturnWrapper.step"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.EvalEpisodeReturnWrapper.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Step the environment with the provided action, accumulate the returned reward, and add the total reward to</span>
<span class="sd">            `info` if the episode is done.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - action (:obj:`Any`): The action to take in the environment.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - obs (:obj:`np.ndarray`): The next observation from the environment.</span>
<span class="sd">            - reward (:obj:`float`): The reward from taking the action.</span>
<span class="sd">            - done (:obj:`bool`): Whether the episode is done.</span>
<span class="sd">            - info (:obj:`Dict[str, Any]`): A dictionary of extra information, which includes &#39;eval_episode_return&#39; if</span>
<span class="sd">                the episode is done.</span>
<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; env = gym.make(&quot;CartPole-v1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; env = EvalEpisodeReturnWrapper(env)</span>
<span class="sd">            &gt;&gt;&gt; obs = env.reset()</span>
<span class="sd">            &gt;&gt;&gt; done = False</span>
<span class="sd">            &gt;&gt;&gt; while not done:</span>
<span class="sd">            ...     action = env.action_space.sample()  # Replace with your own policy</span>
<span class="sd">            ...     obs, reward, done, info = env.step(action)</span>
<span class="sd">            ...     if done:</span>
<span class="sd">            ...         print(&quot;Total episode reward:&quot;, info[&#39;eval_episode_return&#39;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_eval_episode_return</span> <span class="o">+=</span> <span class="n">reward</span>
        <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
            <span class="n">info</span><span class="p">[</span><span class="s1">&#39;eval_episode_return&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_ndarray</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_eval_episode_return</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span></div></div>


<div class="viewcode-block" id="FrameStackWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.FrameStackWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;frame_stack&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">FrameStackWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">     Overview:</span>
<span class="sd">        FrameStackWrapper is a gym environment wrapper that stacks the latest n frames (generally 4 in Atari)</span>
<span class="sd">        as a single observation. It is commonly used in environments where the observation is an image,</span>
<span class="sd">        and consecutive frames provide useful temporal information for the agent.</span>
<span class="sd">     Interfaces:</span>
<span class="sd">         __init__, reset, step, _get_ob</span>
<span class="sd">     Properties:</span>
<span class="sd">         - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">         - n_frames (:obj:`int`): The number of frames to stack.</span>
<span class="sd">         - frames (:obj:`collections.deque`): A queue that holds the most recent frames.</span>
<span class="sd">         - observation_space (:obj:`gym.Space`): The space of the stacked observations.</span>
<span class="sd">     &quot;&quot;&quot;</span>

<div class="viewcode-block" id="FrameStackWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.FrameStackWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">,</span> <span class="n">n_frames</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the FrameStackWrapper. This process includes setting up the environment to wrap,</span>
<span class="sd">            the number of frames to stack, and the observation space.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">            - n_frame (:obj:`int`): The number of frames to stack.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_frames</span> <span class="o">=</span> <span class="n">n_frames</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frames</span> <span class="o">=</span> <span class="n">deque</span><span class="p">([],</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">n_frames</span><span class="p">)</span>
        <span class="n">obs_space</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obs_space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">tuple</span><span class="o">.</span><span class="n">Tuple</span><span class="p">):</span>
            <span class="n">obs_space</span> <span class="o">=</span> <span class="p">(</span><span class="n">obs_space</span><span class="p">,</span> <span class="p">)</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_frames</span><span class="p">,</span> <span class="p">)</span> <span class="o">+</span> <span class="n">obs_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">tuple</span><span class="o">.</span><span class="n">Tuple</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span>
                    <span class="n">low</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">obs_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">low</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">obs_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">high</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">obs_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
                <span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">obs_space</span><span class="p">))</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="FrameStackWrapper.reset"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.FrameStackWrapper.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Reset the environment and initialize frames with the initial observation.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - init_obs (:obj:`np.ndarray`): The stacked initial observations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_frames</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_ob</span><span class="p">()</span></div>

<div class="viewcode-block" id="FrameStackWrapper.step"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.FrameStackWrapper.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Perform a step in the environment with the given action, append the returned observation</span>
<span class="sd">            to frames, and return the stacked observations.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - action (:obj:`Any`): The action to perform a step with.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - self._get_ob() (:obj:`np.ndarray`): The stacked observations.</span>
<span class="sd">            - reward (:obj:`float`): The amount of reward returned after the previous action.</span>
<span class="sd">            - done (:obj:`bool`): Whether the episode has ended, in which case further step() calls will return</span>
<span class="sd">              undefined results.</span>
<span class="sd">            - info (:obj:`Dict[str, Any]`): Contains auxiliary diagnostic information (helpful for debugging,</span>
<span class="sd">              and sometimes learning).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_ob</span><span class="p">(),</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span></div>

    <span class="k">def</span> <span class="nf">_get_ob</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            The original wrapper used `LazyFrames`, but since we use an np buffer, it has no effect.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - stacked_frames (:obj:`np.ndarray`): The stacked frames.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frames</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>


<div class="viewcode-block" id="ObsTransposeWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ObsTransposeWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;obs_transpose&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ObsTransposeWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">ObservationWrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        The ObsTransposeWrapper class is a gym wrapper that transposes the observation to put the channel dimension</span>
<span class="sd">        first. This can be helpful for certain types of neural networks that expect the channel dimension to be</span>
<span class="sd">        the first dimension.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, observation</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">        - observation_space (:obj:`gym.spaces.Box`): The transformed observation space.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ObsTransposeWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ObsTransposeWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the ObsTransposeWrapper class and update the observation space according to the environment&#39;s</span>
<span class="sd">            observation space.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="n">obs_space</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obs_space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">tuple</span><span class="o">.</span><span class="n">Tuple</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span>
                <span class="n">low</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">obs_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">low</span><span class="p">),</span>
                <span class="n">high</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">obs_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">high</span><span class="p">),</span>
                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">obs_space</span><span class="p">),</span> <span class="n">obs_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">obs_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">obs_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">obs_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span>
                <span class="n">low</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">obs_space</span><span class="o">.</span><span class="n">low</span><span class="p">),</span>
                <span class="n">high</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">obs_space</span><span class="o">.</span><span class="n">high</span><span class="p">),</span>
                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">obs_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">obs_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">obs_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">obs_space</span><span class="o">.</span><span class="n">dtype</span>
            <span class="p">)</span></div>

<div class="viewcode-block" id="ObsTransposeWrapper.observation"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ObsTransposeWrapper.observation">[docs]</a>    <span class="k">def</span> <span class="nf">observation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">tuple</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">tuple</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Transpose the observation to put the channel dimension first. If the observation is a tuple, each element</span>
<span class="sd">            in the tuple is transposed independently.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - obs (:obj:`Union[tuple, np.ndarray]`): The original observation.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - obs (:obj:`Union[tuple, np.ndarray]`): The transposed observation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">new_obs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">obs</span><span class="p">)):</span>
                <span class="n">new_obs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">new_obs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">obs</span></div></div>


<span class="k">class</span> <span class="nc">RunningMeanStd</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">       The RunningMeanStd class is a utility that maintains a running mean and standard deviation calculation over</span>
<span class="sd">        a stream of data.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, update, reset, mean, std</span>
<span class="sd">    Properties:</span>
<span class="sd">        - mean (:obj:`np.ndarray`): The running mean.</span>
<span class="sd">        - std (:obj:`np.ndarray`): The running standard deviation.</span>
<span class="sd">        - _epsilon (:obj:`float`): A small number to prevent division by zero when calculating standard deviation.</span>
<span class="sd">        - _shape (:obj:`tuple`): The shape of the data stream.</span>
<span class="sd">        - _mean (:obj:`np.ndarray`): The current mean of the data stream.</span>
<span class="sd">        - _var (:obj:`np.ndarray`): The current variance of the data stream.</span>
<span class="sd">        - _count (:obj:`float`): The number of data points processed.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="p">()):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the RunningMeanStd object.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - epsilon (:obj:`float`, optional): A small number to prevent division by zero when calculating standard</span>
<span class="sd">                deviation. Default is 1e-4.</span>
<span class="sd">            - shape (:obj:`tuple`, optional): The shape of the data stream. Default is an empty tuple, which</span>
<span class="sd">                corresponds to scalars.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Update the running statistics with a new batch of data.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - x (:obj:`np.array`): A batch of data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">batch_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">batch_count</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">new_count</span> <span class="o">=</span> <span class="n">batch_count</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_count</span>
        <span class="n">mean_delta</span> <span class="o">=</span> <span class="n">batch_mean</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mean</span>
        <span class="n">new_mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mean</span> <span class="o">+</span> <span class="n">mean_delta</span> <span class="o">*</span> <span class="n">batch_count</span> <span class="o">/</span> <span class="n">new_count</span>
        <span class="c1"># this method for calculating new variable might be numerically unstable</span>
        <span class="n">m_a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_var</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_count</span>
        <span class="n">m_b</span> <span class="o">=</span> <span class="n">batch_var</span> <span class="o">*</span> <span class="n">batch_count</span>
        <span class="n">m2</span> <span class="o">=</span> <span class="n">m_a</span> <span class="o">+</span> <span class="n">m_b</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">mean_delta</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">*</span> <span class="n">batch_count</span> <span class="o">/</span> <span class="n">new_count</span>
        <span class="n">new_var</span> <span class="o">=</span> <span class="n">m2</span> <span class="o">/</span> <span class="n">new_count</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mean</span> <span class="o">=</span> <span class="n">new_mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_var</span> <span class="o">=</span> <span class="n">new_var</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">=</span> <span class="n">new_count</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Resets the state of the environment and reset properties:  \</span>
<span class="sd">                ``_mean``, ``_var``, ``_count``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">,</span> <span class="s1">&#39;float64&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">,</span> <span class="s1">&#39;float64&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epsilon</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">mean</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Get the current running mean.</span>
<span class="sd">        Returns:</span>
<span class="sd">            The current running mean.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mean</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">std</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Get the current running standard deviation.</span>
<span class="sd">        Returns:</span>
<span class="sd">            The current running mean.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_var</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epsilon</span>


<div class="viewcode-block" id="ObsNormWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ObsNormWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;obs_norm&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ObsNormWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">ObservationWrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        The ObsNormWrapper class is a gym observation wrapper that normalizes</span>
<span class="sd">        observations according to running mean and standard deviation (std).</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, step, reset, observation</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): the environment to wrap.</span>
<span class="sd">        - data_count (:obj:`int`): the count of data points observed so far.</span>
<span class="sd">        - clip_range (:obj:`Tuple[int, int]`): the range to clip the normalized observation.</span>
<span class="sd">        - rms (:obj:`RunningMeanStd`): running mean and standard deviation of the observations.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ObsNormWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ObsNormWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the ObsNormWrapper class.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): the environment to wrap.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clip_range</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rms</span> <span class="o">=</span> <span class="n">RunningMeanStd</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span></div>

<div class="viewcode-block" id="ObsNormWrapper.step"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ObsNormWrapper.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Take an action in the environment, update the running mean and std,</span>
<span class="sd">            and return the normalized observation.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - action (:obj:`Union[int, np.ndarray]`): the action to take in the environment.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - obs (:obj:`np.ndarray`): the normalized observation after the action.</span>
<span class="sd">            - reward (:obj:`float`): the reward after the action.</span>
<span class="sd">            - done (:obj:`bool`): whether the episode has ended.</span>
<span class="sd">            - info (:obj:`Dict`): contains auxiliary diagnostic information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rms</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">(</span><span class="n">observation</span><span class="p">),</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span></div>

<div class="viewcode-block" id="ObsNormWrapper.observation"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ObsNormWrapper.observation">[docs]</a>    <span class="k">def</span> <span class="nf">observation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Normalize the observation using the current running mean and std.</span>
<span class="sd">            If less than 30 data points have been observed, return the original observation.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): the original observation.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): the normalized observation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_count</span> <span class="o">&gt;</span> <span class="mi">30</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">((</span><span class="n">observation</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">rms</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">rms</span><span class="o">.</span><span class="n">std</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_range</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">observation</span></div>

<div class="viewcode-block" id="ObsNormWrapper.reset"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ObsNormWrapper.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Reset the environment and the properties related to the running mean and std.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - kwargs (:obj:`Dict`): keyword arguments to be passed to the environment&#39;s reset function.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): the initial observation of the environment.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rms</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="StaticObsNormWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.StaticObsNormWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;static_obs_norm&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">StaticObsNormWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">ObservationWrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        The StaticObsNormWrapper class is a gym observation wrapper that normalizes</span>
<span class="sd">        observations according to a precomputed mean and standard deviation (std) from a fixed dataset.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, observation</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): the environment to wrap.</span>
<span class="sd">        - mean (:obj:`numpy.ndarray`): the mean of the observations in the fixed dataset.</span>
<span class="sd">        - std (:obj:`numpy.ndarray`): the standard deviation of the observations in the fixed dataset.</span>
<span class="sd">        - clip_range (:obj:`Tuple[int, int]`): the range to clip the normalized observation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="StaticObsNormWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.StaticObsNormWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">,</span> <span class="n">mean</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">std</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the StaticObsNormWrapper class.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): the environment to wrap.</span>
<span class="sd">            - mean (:obj:`numpy.ndarray`): the mean of the observations in the fixed dataset.</span>
<span class="sd">            - std (:obj:`numpy.ndarray`): the standard deviation of the observations in the fixed dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clip_range</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span></div>

<div class="viewcode-block" id="StaticObsNormWrapper.observation"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.StaticObsNormWrapper.observation">[docs]</a>    <span class="k">def</span> <span class="nf">observation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Normalize the given observation using the precomputed mean and std.</span>
<span class="sd">            The normalized observation is then clipped within the specified range.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): the original observation.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): the normalized and clipped observation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">((</span><span class="n">observation</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_range</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span></div></div>


<div class="viewcode-block" id="RewardNormWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.RewardNormWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;reward_norm&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">RewardNormWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">RewardWrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        This wrapper class normalizes the reward according to running std. It extends the `gym.RewardWrapper`.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, step, reward, reset</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">        - cum_reward (:obj:`numpy.ndarray`): The cumulated reward, initialized as zero and updated in `step` method.</span>
<span class="sd">        - reward_discount (:obj:`float`): The discount factor for reward.</span>
<span class="sd">        - data_count (:obj:`int`): A counter for data, incremented in each `step` call.</span>
<span class="sd">        - rms (:obj:`RunningMeanStd`): An instance of RunningMeanStd to compute the running mean and std of reward.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="RewardNormWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.RewardNormWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">,</span> <span class="n">reward_discount</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the RewardNormWrapper, setup the properties according to running mean and std.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">            - reward_discount (:obj:`float`): The discount factor for reward.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cum_reward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="p">),</span> <span class="s1">&#39;float64&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_discount</span> <span class="o">=</span> <span class="n">reward_discount</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rms</span> <span class="o">=</span> <span class="n">RunningMeanStd</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">))</span></div>

<div class="viewcode-block" id="RewardNormWrapper.step"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.RewardNormWrapper.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Step the environment with the given action, update properties and return the new observation, reward,</span>
<span class="sd">            done status and info.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - action (:obj:`Any`): The action to execute in the environment.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): Normalized observation after executing the action and updated `self.rms`.</span>
<span class="sd">            - reward (:obj:`float`): Amount of reward returned after the action execution (normalized) and updated</span>
<span class="sd">                `self.cum_reward`.</span>
<span class="sd">            - done (:obj:`bool`): Whether the episode has ended, in which case further step() calls will return</span>
<span class="sd">                undefined results.</span>
<span class="sd">            - info (:obj:`Dict`): Contains auxiliary diagnostic information (helpful for debugging, and sometimes</span>
<span class="sd">                learning).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">reward</span><span class="p">],</span> <span class="s1">&#39;float64&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cum_reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cum_reward</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_discount</span> <span class="o">+</span> <span class="n">reward</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rms</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cum_reward</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">observation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="p">(</span><span class="n">reward</span><span class="p">),</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span></div>

<div class="viewcode-block" id="RewardNormWrapper.reward"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.RewardNormWrapper.reward">[docs]</a>    <span class="k">def</span> <span class="nf">reward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Normalize reward if `data_count` is more than 30.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - reward (:obj:`float`): The raw reward.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - reward (:obj:`float`): Normalized reward.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_count</span> <span class="o">&gt;</span> <span class="mi">30</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">reward</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">rms</span><span class="o">.</span><span class="n">std</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span></div>

<div class="viewcode-block" id="RewardNormWrapper.reset"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.RewardNormWrapper.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Resets the state of the environment and reset properties (`NumType` ones to 0, \</span>
<span class="sd">                and ``self.rms`` as reset rms wrapper)</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - kwargs (:obj:`Dict`): Reset with this key argumets</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cum_reward</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rms</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="RamWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.RamWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;ram&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">RamWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        This wrapper class wraps a RAM environment into an image-like environment. It extends the `gym.Wrapper`.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, reset, step</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">        - observation_space (:obj:`gym.spaces.Box`): The observation space of the wrapped environment.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="RamWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.RamWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">,</span> <span class="n">render</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the RamWrapper and set up the observation space to wrap the RAM environment.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">            - render (:obj:`bool`): Whether to render the environment, default is False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span>
            <span class="n">low</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">low</span><span class="p">),</span>
            <span class="n">high</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">high</span><span class="p">),</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="RamWrapper.reset"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.RamWrapper.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Resets the state of the environment and returns a reshaped observation.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): New observation after reset and reshaped.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">obs</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span></div>

<div class="viewcode-block" id="RamWrapper.step"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.RamWrapper.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Execute one step within the environment with the given action. Repeat action, sum reward and reshape the</span>
<span class="sd">            observation.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - action (:obj:`Any`): The action to take in the environment.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): Reshaped observation after step with type restriction.</span>
<span class="sd">            - reward (:obj:`Any`): Amount of reward returned after previous action.</span>
<span class="sd">            - done (:obj:`bool`): Whether the episode has ended, in which case further step() calls will return</span>
<span class="sd">              undefined results.</span>
<span class="sd">            - info (:obj:`Dict`): Contains auxiliary diagnostic information (helpful for debugging, and sometimes</span>
<span class="sd">              learning).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">obs</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span></div></div>


<div class="viewcode-block" id="EpisodicLifeWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.EpisodicLifeWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;episodic_life&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">EpisodicLifeWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        This wrapper makes end-of-life equivalent to end-of-episode, but only resets on</span>
<span class="sd">        true game over. This helps in better value estimation.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, step, reset</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">        - lives (:obj:`int`): The current number of lives.</span>
<span class="sd">        - was_real_done (:obj:`bool`): Whether the last episode was ended due to game over.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="EpisodicLifeWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.EpisodicLifeWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the EpisodicLifeWrapper, setting lives to 0 and was_real_done to True.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lives</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">was_real_done</span> <span class="o">=</span> <span class="kc">True</span></div>

<div class="viewcode-block" id="EpisodicLifeWrapper.step"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.EpisodicLifeWrapper.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Execute the given action in the environment, update properties based on the new</span>
<span class="sd">            state and return the new observation, reward, done status and info.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - action (:obj:`Any`): The action to execute in the environment.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): Normalized observation after the action execution and updated `self.rms`.</span>
<span class="sd">            - reward (:obj:`float`): Amount of reward returned after the action execution.</span>
<span class="sd">            - done (:obj:`bool`): Whether the episode has ended, in which case further step() calls will return</span>
<span class="sd">                undefined results.</span>
<span class="sd">            - info (:obj:`Dict`): Contains auxiliary diagnostic information (helpful for debugging, and</span>
<span class="sd">                sometimes learning).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">was_real_done</span> <span class="o">=</span> <span class="n">done</span>
        <span class="c1"># check current lives, make loss of life terminal, then update lives to</span>
        <span class="c1"># handle bonus lives</span>
        <span class="n">lives</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">unwrapped</span><span class="o">.</span><span class="n">ale</span><span class="o">.</span><span class="n">lives</span><span class="p">()</span>
        <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">lives</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">lives</span><span class="p">:</span>
            <span class="c1"># For Qbert sometimes we stay in lives == 0 condition for a few frames,</span>
            <span class="c1"># so it is important to keep lives &gt; 0, so that we only reset</span>
            <span class="c1"># once the environment is actually done.</span>
            <span class="n">done</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lives</span> <span class="o">=</span> <span class="n">lives</span>
        <span class="k">return</span> <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span></div>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Resets the state of the environment and updates the number of lives, only when</span>
<span class="sd">            lives are exhausted. This way all states are still reachable even though lives</span>
<span class="sd">            are episodic, and the learner need not know about any of this behind-the-scenes.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): New observation after reset with no-op step to advance from</span>
<span class="sd">                terminal/lost life state.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">was_real_done</span><span class="p">:</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># no-op step to advance from terminal/lost life state</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lives</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">unwrapped</span><span class="o">.</span><span class="n">ale</span><span class="o">.</span><span class="n">lives</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">obs</span></div>


<div class="viewcode-block" id="FireResetWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.FireResetWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;fire_reset&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">FireResetWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        This wrapper takes a fire action at environment reset.</span>
<span class="sd">        Related discussion: https://github.com/openai/baselines/issues/240</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, reset</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="FireResetWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.FireResetWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the FireResetWrapper. Assume that the second action of the environment</span>
<span class="sd">            is &#39;FIRE&#39; and there are at least three actions.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">env</span><span class="o">.</span><span class="n">unwrapped</span><span class="o">.</span><span class="n">get_action_meanings</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;FIRE&#39;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">unwrapped</span><span class="o">.</span><span class="n">get_action_meanings</span><span class="p">())</span> <span class="o">&gt;=</span> <span class="mi">3</span></div>

<div class="viewcode-block" id="FireResetWrapper.reset"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.FireResetWrapper.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Resets the state of the environment and executes a fire action, i.e. reset with action 1.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): New observation after reset and fire action.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span></div></div>


<div class="viewcode-block" id="GymHybridDictActionWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.GymHybridDictActionWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;gym_hybrid_dict_action&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">GymHybridDictActionWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">ActionWrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Transform Gym-Hybrid&#39;s original `gym.spaces.Tuple` action space to `gym.spaces.Dict`.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, action</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">        - action_space (:obj:`gym.spaces.Dict`): The new action space.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="GymHybridDictActionWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.GymHybridDictActionWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the GymHybridDictActionWrapper, setting up the new action space.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Dict</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
                <span class="c1"># shape = (2, )  0 is for acceleration; 1 is for rotation</span>
                <span class="s1">&#39;mask&#39;</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
                <span class="s1">&#39;args&#39;</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span>
                    <span class="n">low</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                    <span class="n">high</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                    <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">),</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span>
                <span class="p">),</span>
            <span class="p">}</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="GymHybridDictActionWrapper.step"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.GymHybridDictActionWrapper.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Execute the given action in the environment, transform the action from Dict to Tuple,</span>
<span class="sd">            and return the new observation, reward, done status and info.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - action (:obj:`Dict`): The action to execute in the environment, structured as a dictionary.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`Dict`): The wrapped observation, which includes the current observation,</span>
<span class="sd">                previous action and previous reward.</span>
<span class="sd">            - reward (:obj:`float`): Amount of reward returned after the action execution.</span>
<span class="sd">            - done (:obj:`bool`): Whether the episode has ended, in which case further step() calls will return</span>
<span class="sd">                undefined results.</span>
<span class="sd">            - info (:obj:`Dict`): Contains auxiliary diagnostic information (helpful for debugging, and</span>
<span class="sd">                sometimes learning).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># # From Dict to Tuple</span>
        <span class="c1"># action_type = action[0]</span>
        <span class="c1"># if action_type == 0:</span>
        <span class="c1">#     action_mask = np.array([1, 0], dtype=np.int64)</span>
        <span class="c1">#     action_args = np.array([action[1][0], 0], dtype=np.float32)</span>
        <span class="c1"># elif action_type == 1:</span>
        <span class="c1">#     action_mask = np.array([0, 1], dtype=np.int64)</span>
        <span class="c1">#     action_args = np.array([0, action[1][1]], dtype=np.float32)</span>
        <span class="c1"># elif action_type == 2:</span>
        <span class="c1">#     action_mask = np.array([0, 0], dtype=np.int64)</span>
        <span class="c1">#     action_args = np.array([0, 0], dtype=np.float32)</span>

        <span class="c1"># From Dict to Tuple</span>
        <span class="n">action_type</span><span class="p">,</span> <span class="n">action_mask</span><span class="p">,</span> <span class="n">action_args</span> <span class="o">=</span> <span class="n">action</span><span class="p">[</span><span class="s1">&#39;type&#39;</span><span class="p">],</span> <span class="n">action</span><span class="p">[</span><span class="s1">&#39;mask&#39;</span><span class="p">],</span> <span class="n">action</span><span class="p">[</span><span class="s1">&#39;args&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">((</span><span class="n">action_type</span><span class="p">,</span> <span class="n">action_args</span><span class="p">))</span></div></div>


<div class="viewcode-block" id="ObsPlusPrevActRewWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ObsPlusPrevActRewWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;obs_plus_prev_action_reward&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ObsPlusPrevActRewWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        This wrapper is used in policy NGU. It sets a dict as the new wrapped observation,</span>
<span class="sd">        which includes the current observation, previous action and previous reward.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, reset, step</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">        - prev_action (:obj:`int`): The previous action.</span>
<span class="sd">        - prev_reward_extrinsic (:obj:`float`): The previous reward.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ObsPlusPrevActRewWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ObsPlusPrevActRewWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the ObsPlusPrevActRewWrapper, setting up the previous action and reward.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Dict</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s1">&#39;obs&#39;</span><span class="p">:</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span>
                <span class="s1">&#39;prev_action&#39;</span><span class="p">:</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span>
                <span class="s1">&#39;prev_reward_extrinsic&#39;</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span>
                    <span class="n">low</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">reward_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">high</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">reward_range</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span>
                <span class="p">)</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prev_action</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>  <span class="c1"># null action</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prev_reward_extrinsic</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># null reward</span></div>

<div class="viewcode-block" id="ObsPlusPrevActRewWrapper.reset"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ObsPlusPrevActRewWrapper.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Resets the state of the environment, and returns the wrapped observation.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`Dict`): The wrapped observation, which includes the current observation,</span>
<span class="sd">                previous action and previous reward.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;obs&#39;</span><span class="p">:</span> <span class="n">obs</span><span class="p">,</span> <span class="s1">&#39;prev_action&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">prev_action</span><span class="p">,</span> <span class="s1">&#39;prev_reward_extrinsic&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">prev_reward_extrinsic</span><span class="p">}</span>
        <span class="k">return</span> <span class="n">obs</span></div>

<div class="viewcode-block" id="ObsPlusPrevActRewWrapper.step"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.ObsPlusPrevActRewWrapper.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Execute the given action in the environment, save the previous action and reward</span>
<span class="sd">            to be used in the next observation, and return the new observation, reward,</span>
<span class="sd">            done status and info.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - action (:obj:`Any`): The action to execute in the environment.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`Dict`): The wrapped observation, which includes the current observation,</span>
<span class="sd">                previous action and previous reward.</span>
<span class="sd">            - reward (:obj:`float`): Amount of reward returned after the action execution.</span>
<span class="sd">            - done (:obj:`bool`): Whether the episode has ended, in which case further step() calls will return</span>
<span class="sd">                undefined results.</span>
<span class="sd">            - info (:obj:`Dict`): Contains auxiliary diagnostic information (helpful for debugging, and sometimes</span>
<span class="sd">                learning).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;obs&#39;</span><span class="p">:</span> <span class="n">obs</span><span class="p">,</span> <span class="s1">&#39;prev_action&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">prev_action</span><span class="p">,</span> <span class="s1">&#39;prev_reward_extrinsic&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">prev_reward_extrinsic</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prev_action</span> <span class="o">=</span> <span class="n">action</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prev_reward_extrinsic</span> <span class="o">=</span> <span class="n">reward</span>
        <span class="k">return</span> <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span></div></div>


<span class="k">class</span> <span class="nc">TransposeWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        This class is used to transpose the observation space of the environment.</span>

<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, _process_obs, step, reset</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the TransposeWrapper, setting up the new observation space.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="n">old_space</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">)</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">old_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="o">*</span><span class="n">old_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span>
            <span class="n">low</span><span class="o">=</span><span class="n">old_space</span><span class="o">.</span><span class="n">low</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">high</span><span class="o">=</span><span class="n">old_space</span><span class="o">.</span><span class="n">high</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">shape</span><span class="o">=</span><span class="n">new_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">old_space</span><span class="o">.</span><span class="n">dtype</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_process_obs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Transpose the observation into the format (channels, height, width).</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - obs (:obj:`np.ndarray`): The observation to transform.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - obs (:obj:`np.ndarray`): The transposed observation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">to_ndarray</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">obs</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Execute the given action in the environment, process the observation and return</span>
<span class="sd">            the new observation, reward, done status, and info.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - action (:obj:`Any`): The action to execute in the environment.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): The processed observation after the action execution.</span>
<span class="sd">            - reward (:obj:`float`): Amount of reward returned after the action execution.</span>
<span class="sd">            - done (:obj:`bool`): Whether the episode has ended, in which case further step() calls will return</span>
<span class="sd">                undefined results.</span>
<span class="sd">            - info (:obj:`Dict`): Contains auxiliary diagnostic information (helpful for debugging, and sometimes</span>
<span class="sd">                learning).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_obs</span><span class="p">(</span><span class="n">obs</span><span class="p">),</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Resets the state of the environment and returns the processed observation.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): The processed observation after reset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_obs</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>


<div class="viewcode-block" id="TimeLimitWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.TimeLimitWrapper">[docs]</a><span class="k">class</span> <span class="nc">TimeLimitWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        This class is used to enforce a time limit on the environment.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, reset, step</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="TimeLimitWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.TimeLimitWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">,</span> <span class="n">max_limit</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the TimeLimitWrapper, setting up the maximum limit of time steps.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">            - max_limit (:obj:`int`): The maximum limit of time steps.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_limit</span> <span class="o">=</span> <span class="n">max_limit</span></div>

<div class="viewcode-block" id="TimeLimitWrapper.reset"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.TimeLimitWrapper.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Resets the state of the environment and the time counter.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): The new observation after reset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span></div>

<div class="viewcode-block" id="TimeLimitWrapper.step"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.TimeLimitWrapper.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Execute the given action in the environment, update the time counter, and</span>
<span class="sd">            return the new observation, reward, done status and info.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - action (:obj:`Any`): The action to execute in the environment.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): The new observation after the action execution.</span>
<span class="sd">            - reward (:obj:`float`): Amount of reward returned after the action execution.</span>
<span class="sd">            - done (:obj:`bool`): Whether the episode has ended, in which case further step() calls will return</span>
<span class="sd">                undefined results.</span>
<span class="sd">            - info (:obj:`Dict`): Contains auxiliary diagnostic information (helpful for debugging, and sometimes</span>
<span class="sd">                learning).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_count</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_limit</span><span class="p">:</span>
            <span class="n">done</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">info</span><span class="p">[</span><span class="s1">&#39;time_limit&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">info</span><span class="p">[</span><span class="s1">&#39;time_limit&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">info</span><span class="p">[</span><span class="s1">&#39;time_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_count</span>
        <span class="k">return</span> <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span></div></div>


<div class="viewcode-block" id="FlatObsWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.FlatObsWrapper">[docs]</a><span class="k">class</span> <span class="nc">FlatObsWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        This class is used to flatten the observation space of the environment.</span>
<span class="sd">        Note: only suitable for environments like minigrid.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, observation, reset, step</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="FlatObsWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.FlatObsWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">,</span> <span class="n">maxStrLen</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">96</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the FlatObsWrapper, setup the new observation space.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">            - maxStrLen (:obj:`int`): The maximum length of mission string, default is 96.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">maxStrLen</span> <span class="o">=</span> <span class="n">maxStrLen</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">numCharCodes</span> <span class="o">=</span> <span class="mi">28</span>

        <span class="n">imgSpace</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">spaces</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span>
        <span class="n">imgSize</span> <span class="o">=</span> <span class="n">reduce</span><span class="p">(</span><span class="n">operator</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="n">imgSpace</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span>
            <span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">high</span><span class="o">=</span><span class="mi">255</span><span class="p">,</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">imgSize</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">numCharCodes</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxStrLen</span><span class="p">,</span> <span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cachedStr</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="FlatObsWrapper.observation"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.FlatObsWrapper.observation">[docs]</a>    <span class="k">def</span> <span class="nf">observation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Process the observation, convert the mission into one-hot encoding and concatenate</span>
<span class="sd">            it with the image data.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - obs (:obj:`Union[np.ndarray, Tuple]`): The raw observation to process.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - obs (:obj:`np.ndarray`): The processed observation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>  <span class="c1"># for compatibility of gymnasium</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span>
        <span class="n">mission</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;mission&quot;</span><span class="p">]</span>

        <span class="c1"># Cache the last-encoded mission string</span>
        <span class="k">if</span> <span class="n">mission</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cachedStr</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mission</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxStrLen</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;mission string too long (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">mission</span><span class="p">)</span><span class="si">}</span><span class="s2"> chars)&quot;</span>
            <span class="n">mission</span> <span class="o">=</span> <span class="n">mission</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

            <span class="n">strArray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">maxStrLen</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">numCharCodes</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">ch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mission</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">ch</span> <span class="o">&gt;=</span> <span class="s2">&quot;a&quot;</span> <span class="ow">and</span> <span class="n">ch</span> <span class="o">&lt;=</span> <span class="s2">&quot;z&quot;</span><span class="p">:</span>
                    <span class="n">chNo</span> <span class="o">=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">ch</span><span class="p">)</span> <span class="o">-</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">ch</span> <span class="o">==</span> <span class="s2">&quot; &quot;</span><span class="p">:</span>
                    <span class="n">chNo</span> <span class="o">=</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;z&quot;</span><span class="p">)</span> <span class="o">-</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="k">elif</span> <span class="n">ch</span> <span class="o">==</span> <span class="s2">&quot;,&quot;</span><span class="p">:</span>
                    <span class="n">chNo</span> <span class="o">=</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;z&quot;</span><span class="p">)</span> <span class="o">-</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Character </span><span class="si">{</span><span class="n">ch</span><span class="si">}</span><span class="s2"> is not available in mission string.&quot;</span><span class="p">)</span>
                <span class="k">assert</span> <span class="n">chNo</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">numCharCodes</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> : </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">ch</span><span class="p">,</span> <span class="n">chNo</span><span class="p">)</span>
                <span class="n">strArray</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="n">chNo</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">cachedStr</span> <span class="o">=</span> <span class="n">mission</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cachedArray</span> <span class="o">=</span> <span class="n">strArray</span>

        <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">image</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">cachedArray</span><span class="o">.</span><span class="n">flatten</span><span class="p">()))</span>

        <span class="k">return</span> <span class="n">obs</span></div>

<div class="viewcode-block" id="FlatObsWrapper.reset"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.FlatObsWrapper.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Resets the state of the environment and returns the processed observation.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): The processed observation after reset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span></div>

<div class="viewcode-block" id="FlatObsWrapper.step"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.FlatObsWrapper.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Execute the given action in the environment, and return the processed observation,</span>
<span class="sd">            reward, done status, and info.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): The processed observation after the action execution.</span>
<span class="sd">            - reward (:obj:`float`): Amount of reward returned after the action execution.</span>
<span class="sd">            - done (:obj:`bool`): Whether the episode has ended, in which case further step() calls will return</span>
<span class="sd">                undefined results.</span>
<span class="sd">            - info (:obj:`Dict`): Contains auxiliary diagnostic information (helpful for debugging, and sometimes</span>
<span class="sd">                learning).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">o</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">(</span><span class="n">o</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">o</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">i</span></div></div>


<div class="viewcode-block" id="GymToGymnasiumWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.GymToGymnasiumWrapper">[docs]</a><span class="k">class</span> <span class="nc">GymToGymnasiumWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        This class is used to wrap a gymnasium environment to a gym environment.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, seed, reset</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="GymToGymnasiumWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.GymToGymnasiumWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gymnasium</span><span class="o">.</span><span class="n">Env</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the GymToGymnasiumWrapper.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gymnasium.Env`): The gymnasium environment to wrap.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">gymnasium</span><span class="o">.</span><span class="n">Env</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="o">=</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="GymToGymnasiumWrapper.seed"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.GymToGymnasiumWrapper.seed">[docs]</a>    <span class="k">def</span> <span class="nf">seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Set the seed for the environment.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - seed (:obj:`int`): The seed to set.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="o">=</span> <span class="n">seed</span></div>

<div class="viewcode-block" id="GymToGymnasiumWrapper.reset"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.GymToGymnasiumWrapper.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Resets the state of the environment and returns the new observation. If a seed</span>
<span class="sd">            was set, use it in the reset.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`np.ndarray`): The new observation after reset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_seed</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="AllinObsWrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.AllinObsWrapper">[docs]</a><span class="nd">@ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s1">&#39;reward_in_obs&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">AllinObsWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        This wrapper is used in policy ``Decision Transformer``, which is proposed in paper</span>
<span class="sd">        https://arxiv.org/abs/2106.01345. It sets a dict {&#39;obs&#39;: obs, &#39;reward&#39;: reward}</span>
<span class="sd">        as the new wrapped observation, which includes the current observation and previous reward.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        __init__, reset, step, seed</span>
<span class="sd">    Properties:</span>
<span class="sd">        - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="AllinObsWrapper.__init__"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.AllinObsWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the AllinObsWrapper.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - env (:obj:`gym.Env`): The environment to wrap.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span></div>

<div class="viewcode-block" id="AllinObsWrapper.reset"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.AllinObsWrapper.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Resets the state of the environment and returns the new observation.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - observation (:obj:`Dict`): The new observation after reset, includes the current observation and reward.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;obs&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">(),</span> <span class="s1">&#39;reward&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">])}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Dict</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s1">&#39;obs&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span>
                <span class="s1">&#39;reward&#39;</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">ret</span></div>

<div class="viewcode-block" id="AllinObsWrapper.step"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.AllinObsWrapper.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Execute the given action in the environment, and return the new observation,</span>
<span class="sd">            reward, done status, and info.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - action (:obj:`Any`): The action to execute in the environment.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - timestep (:obj:`BaseEnvTimestep`): The timestep after the action execution.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;obs&#39;</span><span class="p">:</span> <span class="n">obs</span><span class="p">,</span> <span class="s1">&#39;reward&#39;</span><span class="p">:</span> <span class="n">reward</span><span class="p">}</span>
        <span class="kn">from</span> <span class="nn">ding.envs</span> <span class="kn">import</span> <span class="n">BaseEnvTimestep</span>
        <span class="k">return</span> <span class="n">BaseEnvTimestep</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span><span class="p">)</span></div>

<div class="viewcode-block" id="AllinObsWrapper.seed"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.AllinObsWrapper.seed">[docs]</a>    <span class="k">def</span> <span class="nf">seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dynamic_seed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Set the seed for the environment.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - seed (:obj:`int`): The seed to set.</span>
<span class="sd">            - dynamic_seed (:obj:`bool`): Whether to use dynamic seed, default is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">dynamic_seed</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="update_shape"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.update_shape">[docs]</a><span class="k">def</span> <span class="nf">update_shape</span><span class="p">(</span><span class="n">obs_shape</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">act_shape</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">rew_shape</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">wrapper_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Get new shapes of observation, action, and reward given the wrapper.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        - obs_shape (:obj:`Any`): The original shape of observation.</span>
<span class="sd">        - act_shape (:obj:`Any`): The original shape of action.</span>
<span class="sd">        - rew_shape (:obj:`Any`): The original shape of reward.</span>
<span class="sd">        - wrapper_names (:obj:`List[str]`): The names of the wrappers.</span>
<span class="sd">    Returns:</span>
<span class="sd">        - obs_shape (:obj:`Any`): The new shape of observation.</span>
<span class="sd">        - act_shape (:obj:`Any`): The new shape of action.</span>
<span class="sd">        - rew_shape (:obj:`Any`): The new shape of reward.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">wrapper_name</span> <span class="ow">in</span> <span class="n">wrapper_names</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">wrapper_name</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">obs_shape</span><span class="p">,</span> <span class="n">act_shape</span><span class="p">,</span> <span class="n">rew_shape</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">wrapper_name</span><span class="p">)</span><span class="o">.</span><span class="n">new_shape</span><span class="p">(</span><span class="n">obs_shape</span><span class="p">,</span> <span class="n">act_shape</span><span class="p">,</span> <span class="n">rew_shape</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="k">continue</span>
    <span class="k">return</span> <span class="n">obs_shape</span><span class="p">,</span> <span class="n">act_shape</span><span class="p">,</span> <span class="n">rew_shape</span></div>


<div class="viewcode-block" id="create_env_wrapper"><a class="viewcode-back" href="../../../../05_api_doc/env.html#ding.envs.create_env_wrapper">[docs]</a><span class="k">def</span> <span class="nf">create_env_wrapper</span><span class="p">(</span><span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">,</span> <span class="n">env_wrapper_cfg</span><span class="p">:</span> <span class="n">EasyDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Create an environment wrapper according to the environment wrapper configuration and the environment instance.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        - env (:obj:`gym.Env`): The environment instance to be wrapped.</span>
<span class="sd">        - env_wrapper_cfg (:obj:`EasyDict`): The configuration for the environment wrapper.</span>
<span class="sd">    Returns:</span>
<span class="sd">        - env (:obj:`gym.Wrapper`): The wrapped environment instance.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">env_wrapper_cfg</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">env_wrapper_cfg</span><span class="p">)</span>
    <span class="k">if</span> <span class="s1">&#39;import_names&#39;</span> <span class="ow">in</span> <span class="n">env_wrapper_cfg</span><span class="p">:</span>
        <span class="n">import_module</span><span class="p">(</span><span class="n">env_wrapper_cfg</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;import_names&#39;</span><span class="p">))</span>
    <span class="n">env_wrapper_type</span> <span class="o">=</span> <span class="n">env_wrapper_cfg</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;type&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ENV_WRAPPER_REGISTRY</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">env_wrapper_type</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="o">**</span><span class="n">env_wrapper_cfg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;kwargs&#39;</span><span class="p">,</span> <span class="p">{}))</span></div>
</pre></div>

              </article>
              
            </div>
            <footer>
  

  <hr>

  <div role="contentinfo">
    <p>
      &copy; Copyright 2021, OpenDILab Contributors.

    </p>
  </div>
  
  <div>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a
      href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the
      Docs</a>.
  </div>
   

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="../../../../"
    src="../../../../_static/documentation_options.js"></script>
  <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
  <script src="../../../../_static/jquery.js"></script>
  <script src="../../../../_static/underscore.js"></script>
  <script src="../../../../_static/doctools.js"></script>
  

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  </div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/" aria-label="OpenMMLab"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/DI-engine" target="_blank">GitHub</a>
          </li>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>