


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ding.torch_utils.data_helper &mdash; DI-engine 0.1.0 documentation</title>
  

  <link rel="shortcut icon" href="../../../_static/images/favicon.ico" />
  
  

  

  
  
  

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/style.css" type="text/css" />
  <link rel="index" title="Index" href="../../../genindex.html" />
  <link rel="search" title="Search" href="../../../search.html" />
    <link href="../../../_static/css/style.css" rel="stylesheet" type="text/css">


  
  <script src="../../../_static/js/modernizr.min.js"></script>
  <script>
    MathJax = {
        chtml: {
            scale: 1,
            minScale: 1,
        },
        svg: {
            scale: 1,
            minScale: 1,
        }
    }
</script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/"
        aria-label="OpenMMLab"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/DI-engine" target="_blank">GitHub</a>
          </li>
          <li >
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a
                class="resource-option with-down-arrow">
                OpenDILab
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-engine" target="_blank">
                  <span class="dropdown-title">DI-engine </span>
                  <p>OpenDILab Decision AI Engine</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/LightZero" target="_blank">
                  <span class="dropdown-title">LightZero </span>
                  <p>OpenDILab Decision Monte Carlo Tree Search Framework</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/GenerativeRL" target="_blank">
                  <span class="dropdown-title">GenerativeRL </span>
                  <p>OpenDILab Generative AI Framework</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-star" target="_blank">
                  <span class="dropdown-title">DI-star </span>
                  <p>OpenDILab Decision AI in StarCraftII</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-drive" target="_blank">
                  <span class="dropdown-title">DI-drive </span>
                  <p>OpenDILab Auto-driving platform</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/GoBigger" target="_blank">
                  <span class="dropdown-title">GoBigger </span>
                  <p>OpenDILab Multi-Agent Environment</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-smartcross" target="_blank">
                  <span class="dropdown-title">DI-smartcross </span>
                  <p>Decision Intelligence Platform for Traffic Crossing Signal Control</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-treetensor" target="_blank">
                  <span class="dropdown-title">DI-treetensor </span>
                  <p>Tree Nested PyTorch Tensor Lib</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-sheep" target="_blank">
                  <span class="dropdown-title">DI-sheep </span>
                  <p>Deep Reinforcement Learning + 3 Tiles Game</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-model-based-RL" target="_blank">
                  <span class="dropdown-title">awesome-model-based-RL </span>
                  <p>A curated list of awesome model based RL resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-decision-transformer" target="_blank">
                  <span class="dropdown-title">awesome-decision-transformer </span>
                  <p>A curated list of Decision Transformer resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-exploration-rl" target="_blank">
                  <span class="dropdown-title">awesome-exploration-rl </span>
                  <p>A curated list of awesome exploration RL resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-multi-modal-reinforcement-learning" target="_blank">
                  <span class="dropdown-title">awesome-multi-modal-reinforcement-learning </span>
                  <p>A curated list of Multi-Modal Reinforcement Learning resources (continually updated)</p>
                </a>
              </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../00_intro/index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../01_quickstart/index.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../02_algo/index.html">RL Algorithm Taxonomy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../03_system/index.html">System Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../04_best_practice/index.html">Best Practice</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../05_api_doc/index.html">API Doc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../06_faq/index.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reinforcement Learning Tutorial</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../10_concepts/index.html">Introduction to RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../11_dizoo/index.html">Learn From DI-zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../12_policies/index.html">RL Algorithms Cheat Sheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../13_envs/index.html">RL Env Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../20_spec/index.html">Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../21_code_style/index.html">Code Style Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../22_test/index.html">Unit Test Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../23_visual/index.html">Diagrams and Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../24_cooperation/index.html">Github Cooperation</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
            Docs
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>ding.torch_utils.data_helper</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
  <h1>Source code for ding.torch_utils.data_helper</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">List</span>
<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Sequence</span>
<span class="kn">import</span> <span class="nn">numbers</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">threading</span> <span class="kn">import</span> <span class="n">Thread</span>
<span class="kn">from</span> <span class="nn">queue</span> <span class="kn">import</span> <span class="n">Queue</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">treetensor.torch</span> <span class="k">as</span> <span class="nn">ttorch</span>

<span class="kn">from</span> <span class="nn">ding.utils.default_helper</span> <span class="kn">import</span> <span class="n">get_shape0</span>


<div class="viewcode-block" id="to_device"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.to_device">[docs]</a><span class="k">def</span> <span class="nf">to_device</span><span class="p">(</span><span class="n">item</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">ignore_keys</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[])</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Transfer data to certain device.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        - item (:obj:`Any`): The item to be transferred.</span>
<span class="sd">        - device (:obj:`str`): The device wanted.</span>
<span class="sd">        - ignore_keys (:obj:`list`): The keys to be ignored in transfer, default set to empty.</span>
<span class="sd">    Returns:</span>
<span class="sd">        - item (:obj:`Any`): The transferred item.</span>
<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; setup_data_dict[&#39;module&#39;] = nn.Linear(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; device = &#39;cuda&#39;</span>
<span class="sd">        &gt;&gt;&gt; cuda_d = to_device(setup_data_dict, device, ignore_keys=[&#39;module&#39;])</span>
<span class="sd">        &gt;&gt;&gt; assert cuda_d[&#39;module&#39;].weight.device == torch.device(&#39;cpu&#39;)</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; setup_data_dict[&#39;module&#39;] = nn.Linear(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; device = &#39;cuda&#39;</span>
<span class="sd">        &gt;&gt;&gt; cuda_d = to_device(setup_data_dict, device)</span>
<span class="sd">        &gt;&gt;&gt; assert cuda_d[&#39;module&#39;].weight.device == torch.device(&#39;cuda:0&#39;)</span>

<span class="sd">    .. note:</span>

<span class="sd">        Now supports item type: :obj:`torch.nn.Module`, :obj:`torch.Tensor`, :obj:`Sequence`, \</span>
<span class="sd">            :obj:`dict`, :obj:`numbers.Integral`, :obj:`numbers.Real`, :obj:`np.ndarray`, :obj:`str` and :obj:`None`.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">item</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">ttorch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="s1">&#39;prev_state&#39;</span> <span class="ow">in</span> <span class="n">item</span><span class="p">:</span>
            <span class="n">prev_state</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">prev_state</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">item</span><span class="o">.</span><span class="n">prev_state</span>
            <span class="n">item</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">item</span><span class="o">.</span><span class="n">prev_state</span> <span class="o">=</span> <span class="n">prev_state</span>
            <span class="k">return</span> <span class="n">item</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">item</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">item</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">item</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">to_device</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">item</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">new_item</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ignore_keys</span><span class="p">:</span>
                <span class="n">new_item</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_item</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_item</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Real</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">item</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">bool_</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">item</span>
    <span class="k">elif</span> <span class="n">item</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">item</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Distribution</span><span class="p">):</span>  <span class="c1"># for compatibility</span>
        <span class="k">return</span> <span class="n">item</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;not support item type: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">item</span><span class="p">)))</span></div>


<div class="viewcode-block" id="to_dtype"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.to_dtype">[docs]</a><span class="k">def</span> <span class="nf">to_dtype</span><span class="p">(</span><span class="n">item</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="nb">type</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Change data to certain dtype.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        - item (:obj:`Any`): The item for changing the dtype.</span>
<span class="sd">        - dtype (:obj:`type`): The type wanted.</span>
<span class="sd">    Returns:</span>
<span class="sd">        - item (:obj:`object`): The item with changed dtype.</span>
<span class="sd">    Examples (tensor):</span>
<span class="sd">        &gt;&gt;&gt; t = torch.randint(0, 10, (3, 5))</span>
<span class="sd">        &gt;&gt;&gt; tfloat = to_dtype(t, torch.float)</span>
<span class="sd">        &gt;&gt;&gt; assert tfloat.dtype == torch.float</span>

<span class="sd">    Examples (list):</span>
<span class="sd">        &gt;&gt;&gt; tlist = [torch.randint(0, 10, (3, 5))]</span>
<span class="sd">        &gt;&gt;&gt; tlfloat = to_dtype(tlist, torch.float)</span>
<span class="sd">        &gt;&gt;&gt; assert tlfloat[0].dtype == torch.float</span>

<span class="sd">    Examples (dict):</span>
<span class="sd">        &gt;&gt;&gt; tdict = {&#39;t&#39;: torch.randint(0, 10, (3, 5))}</span>
<span class="sd">        &gt;&gt;&gt; tdictf = to_dtype(tdict, torch.float)</span>
<span class="sd">        &gt;&gt;&gt; assert tdictf[&#39;t&#39;].dtype == torch.float</span>

<span class="sd">    .. note:</span>

<span class="sd">        Now supports item type: :obj:`torch.Tensor`, :obj:`Sequence`, :obj:`dict`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">item</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">to_dtype</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">item</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">to_dtype</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">dtype</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;not support item type: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">item</span><span class="p">)))</span></div>


<div class="viewcode-block" id="to_tensor"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.to_tensor">[docs]</a><span class="k">def</span> <span class="nf">to_tensor</span><span class="p">(</span>
        <span class="n">item</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ignore_keys</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[],</span> <span class="n">transform_scalar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Convert ``numpy.ndarray`` object to ``torch.Tensor``.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        - item (:obj:`Any`): The ``numpy.ndarray`` objects to be converted. It can be exactly a ``numpy.ndarray`` \</span>
<span class="sd">            object or a container (list, tuple or dict) that contains several ``numpy.ndarray`` objects.</span>
<span class="sd">        - dtype (:obj:`torch.dtype`): The type of wanted tensor. If set to ``None``, its dtype will be unchanged.</span>
<span class="sd">        - ignore_keys (:obj:`list`): If the ``item`` is a dict, values whose keys are in ``ignore_keys`` will not \</span>
<span class="sd">            be converted.</span>
<span class="sd">        - transform_scalar (:obj:`bool`): If set to ``True``, a scalar will be also converted to a tensor object.</span>
<span class="sd">    Returns:</span>
<span class="sd">        - item (:obj:`Any`): The converted tensors.</span>

<span class="sd">    Examples (scalar):</span>
<span class="sd">        &gt;&gt;&gt; i = 10</span>
<span class="sd">        &gt;&gt;&gt; t = to_tensor(i)</span>
<span class="sd">        &gt;&gt;&gt; assert t.item() == i</span>

<span class="sd">    Examples (dict):</span>
<span class="sd">        &gt;&gt;&gt; d = {&#39;i&#39;: i}</span>
<span class="sd">        &gt;&gt;&gt; dt = to_tensor(d, torch.int)</span>
<span class="sd">        &gt;&gt;&gt; assert dt[&#39;i&#39;].item() == i</span>

<span class="sd">    Examples (named tuple):</span>
<span class="sd">        &gt;&gt;&gt; data_type = namedtuple(&#39;data_type&#39;, [&#39;x&#39;, &#39;y&#39;])</span>
<span class="sd">        &gt;&gt;&gt; inputs = data_type(np.random.random(3), 4)</span>
<span class="sd">        &gt;&gt;&gt; outputs = to_tensor(inputs, torch.float32)</span>
<span class="sd">        &gt;&gt;&gt; assert type(outputs) == data_type</span>
<span class="sd">        &gt;&gt;&gt; assert isinstance(outputs.x, torch.Tensor)</span>
<span class="sd">        &gt;&gt;&gt; assert isinstance(outputs.y, torch.Tensor)</span>
<span class="sd">        &gt;&gt;&gt; assert outputs.x.dtype == torch.float32</span>
<span class="sd">        &gt;&gt;&gt; assert outputs.y.dtype == torch.float32</span>

<span class="sd">    .. note:</span>

<span class="sd">        Now supports item type: :obj:`dict`, :obj:`list`, :obj:`tuple` and :obj:`None`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">new_data</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ignore_keys</span><span class="p">:</span>
                <span class="n">new_data</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_data</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">ignore_keys</span><span class="p">,</span> <span class="n">transform_scalar</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_data</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Real</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">transform</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="s1">&#39;_fields&#39;</span><span class="p">):</span>  <span class="c1"># namedtuple</span>
            <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">item</span><span class="p">)(</span><span class="o">*</span><span class="p">[</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">item</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_data</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">item</span><span class="p">:</span>
                <span class="n">new_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">ignore_keys</span><span class="p">,</span> <span class="n">transform_scalar</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">new_data</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">item</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">item</span>
    <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">transform_scalar</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">item</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">item</span>
    <span class="k">elif</span> <span class="n">item</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">item</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">item</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;not support item type: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">item</span><span class="p">)))</span></div>


<div class="viewcode-block" id="to_ndarray"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.to_ndarray">[docs]</a><span class="k">def</span> <span class="nf">to_ndarray</span><span class="p">(</span><span class="n">item</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Convert ``torch.Tensor`` to ``numpy.ndarray``.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        - item (:obj:`Any`): The ``torch.Tensor`` objects to be converted. It can be exactly a ``torch.Tensor`` \</span>
<span class="sd">            object or a container (list, tuple or dict) that contains several ``torch.Tensor`` objects.</span>
<span class="sd">        - dtype (:obj:`np.dtype`): The type of wanted array. If set to ``None``, its dtype will be unchanged.</span>
<span class="sd">    Returns:</span>
<span class="sd">        - item (:obj:`object`): The changed arrays.</span>

<span class="sd">    Examples (ndarray):</span>
<span class="sd">        &gt;&gt;&gt; t = torch.randn(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; tarray1 = to_ndarray(t)</span>
<span class="sd">        &gt;&gt;&gt; assert tarray1.shape == (3, 5)</span>
<span class="sd">        &gt;&gt;&gt; assert isinstance(tarray1, np.ndarray)</span>

<span class="sd">    Examples (list):</span>
<span class="sd">        &gt;&gt;&gt; t = [torch.randn(5, ) for i in range(3)]</span>
<span class="sd">        &gt;&gt;&gt; tarray1 = to_ndarray(t, np.float32)</span>
<span class="sd">        &gt;&gt;&gt; assert isinstance(tarray1, list)</span>
<span class="sd">        &gt;&gt;&gt; assert tarray1[0].shape == (5, )</span>
<span class="sd">        &gt;&gt;&gt; assert isinstance(tarray1[0], np.ndarray)</span>

<span class="sd">    .. note:</span>

<span class="sd">        Now supports item type: :obj:`torch.Tensor`,  :obj:`dict`, :obj:`list`, :obj:`tuple` and :obj:`None`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">new_data</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">new_data</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_ndarray</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_data</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Real</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">transform</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="s1">&#39;_fields&#39;</span><span class="p">):</span>  <span class="c1"># namedtuple</span>
            <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">item</span><span class="p">)(</span><span class="o">*</span><span class="p">[</span><span class="n">to_ndarray</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">item</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_data</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">item</span><span class="p">:</span>
                <span class="n">new_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">to_ndarray</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">dtype</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">new_data</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">item</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">item</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">item</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">item</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">item</span>
    <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">item</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;not support item type: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">item</span><span class="p">)))</span></div>


<div class="viewcode-block" id="to_list"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.to_list">[docs]</a><span class="k">def</span> <span class="nf">to_list</span><span class="p">(</span><span class="n">item</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Convert ``torch.Tensor``, ``numpy.ndarray`` objects to ``list`` objects, and keep their dtypes unchanged.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        - item (:obj:`Any`): The item to be converted.</span>
<span class="sd">    Returns:</span>
<span class="sd">        - item (:obj:`Any`): The list after conversion.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; data = { \</span>
<span class="sd">                &#39;tensor&#39;: torch.randn(4), \</span>
<span class="sd">                &#39;list&#39;: [True, False, False], \</span>
<span class="sd">                &#39;tuple&#39;: (4, 5, 6), \</span>
<span class="sd">                &#39;bool&#39;: True, \</span>
<span class="sd">                &#39;int&#39;: 10, \</span>
<span class="sd">                &#39;float&#39;: 10., \</span>
<span class="sd">                &#39;array&#39;: np.random.randn(4), \</span>
<span class="sd">                &#39;str&#39;: &quot;asdf&quot;, \</span>
<span class="sd">                &#39;none&#39;: None, \</span>
<span class="sd">            } \</span>
<span class="sd">        &gt;&gt;&gt; transformed_data = to_list(data)</span>

<span class="sd">    .. note::</span>

<span class="sd">        Now supports item type: :obj:`torch.Tensor`, :obj:`numpy.ndarray`, :obj:`dict`, :obj:`list`, \</span>
<span class="sd">        :obj:`tuple` and :obj:`None`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">item</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">item</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">item</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">item</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">to_list</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">item</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">to_list</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">item</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;not support item type: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">item</span><span class="p">)))</span></div>


<div class="viewcode-block" id="tensor_to_list"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.tensor_to_list">[docs]</a><span class="k">def</span> <span class="nf">tensor_to_list</span><span class="p">(</span><span class="n">item</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Convert ``torch.Tensor`` objects to ``list``, and keep their dtypes unchanged.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        - item (:obj:`Any`): The item to be converted.</span>
<span class="sd">    Returns:</span>
<span class="sd">        - item (:obj:`Any`): The lists after conversion.</span>

<span class="sd">    Examples (2d-tensor):</span>
<span class="sd">        &gt;&gt;&gt; t = torch.randn(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; tlist1 = tensor_to_list(t)</span>
<span class="sd">        &gt;&gt;&gt; assert len(tlist1) == 3</span>
<span class="sd">        &gt;&gt;&gt; assert len(tlist1[0]) == 5</span>

<span class="sd">    Examples (1d-tensor):</span>
<span class="sd">        &gt;&gt;&gt; t = torch.randn(3, )</span>
<span class="sd">        &gt;&gt;&gt; tlist1 = tensor_to_list(t)</span>
<span class="sd">        &gt;&gt;&gt; assert len(tlist1) == 3</span>

<span class="sd">    Examples (list)</span>
<span class="sd">        &gt;&gt;&gt; t = [torch.randn(5, ) for i in range(3)]</span>
<span class="sd">        &gt;&gt;&gt; tlist1 = tensor_to_list(t)</span>
<span class="sd">        &gt;&gt;&gt; assert len(tlist1) == 3</span>
<span class="sd">        &gt;&gt;&gt; assert len(tlist1[0]) == 5</span>

<span class="sd">    Examples (dict):</span>
<span class="sd">        &gt;&gt;&gt; td = {&#39;t&#39;: torch.randn(3, 5)}</span>
<span class="sd">        &gt;&gt;&gt; tdlist1 = tensor_to_list(td)</span>
<span class="sd">        &gt;&gt;&gt; assert len(tdlist1[&#39;t&#39;]) == 3</span>
<span class="sd">        &gt;&gt;&gt; assert len(tdlist1[&#39;t&#39;][0]) == 5</span>

<span class="sd">    .. note::</span>

<span class="sd">        Now supports item type: :obj:`torch.Tensor`, :obj:`dict`, :obj:`list`, :obj:`tuple` and :obj:`None`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">item</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">item</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">item</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">tensor_to_list</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">item</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">tensor_to_list</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">item</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;not support item type: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">item</span><span class="p">)))</span></div>


<div class="viewcode-block" id="to_item"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.to_item">[docs]</a><span class="k">def</span> <span class="nf">to_item</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">ignore_error</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Convert data to python native scalar (i.e. data item), and keep their dtypes unchanged.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        - data (:obj:`Any`): The data that needs to be converted.</span>
<span class="sd">        - ignore_error (:obj:`bool`): Whether to ignore the error when the data type is not supported. That is to \</span>
<span class="sd">            say, only the data can be transformed into a python native scalar will be returned.</span>
<span class="sd">    Returns:</span>
<span class="sd">        - data (:obj:`Any`): Converted data.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt;&gt; data = { \</span>
<span class="sd">                &#39;tensor&#39;: torch.randn(1), \</span>
<span class="sd">                &#39;list&#39;: [True, False, torch.randn(1)], \</span>
<span class="sd">                &#39;tuple&#39;: (4, 5, 6), \</span>
<span class="sd">                &#39;bool&#39;: True, \</span>
<span class="sd">                &#39;int&#39;: 10, \</span>
<span class="sd">                &#39;float&#39;: 10., \</span>
<span class="sd">                &#39;array&#39;: np.random.randn(1), \</span>
<span class="sd">                &#39;str&#39;: &quot;asdf&quot;, \</span>
<span class="sd">                &#39;none&#39;: None, \</span>
<span class="sd">             }</span>
<span class="sd">        &gt;&gt;&gt;&gt; new_data = to_item(data)</span>
<span class="sd">        &gt;&gt;&gt;&gt; assert np.isscalar(new_data[&#39;tensor&#39;])</span>
<span class="sd">        &gt;&gt;&gt;&gt; assert np.isscalar(new_data[&#39;array&#39;])</span>
<span class="sd">        &gt;&gt;&gt;&gt; assert np.isscalar(new_data[&#39;list&#39;][-1])</span>

<span class="sd">    .. note::</span>

<span class="sd">        Now supports item type: :obj:`torch.Tensor`, :obj:`torch.Tensor`, :obj:`ttorch.Tensor`, \</span>
<span class="sd">        :obj:`bool`, :obj:`str`, :obj:`dict`, :obj:`list`, :obj:`tuple` and :obj:`None`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">data</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">data</span>
    <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">data</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">ttorch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">to_item</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">new_data</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">ignore_error</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">new_data</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_item</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
                <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">RuntimeError</span><span class="p">):</span>
                    <span class="k">pass</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_data</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_item</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_data</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;not support data type: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data</span><span class="p">))</span></div>


<div class="viewcode-block" id="same_shape"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.same_shape">[docs]</a><span class="k">def</span> <span class="nf">same_shape</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Judge whether all data elements in a list have the same shapes.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        - data (:obj:`list`): The list of data.</span>
<span class="sd">    Returns:</span>
<span class="sd">        - same (:obj:`bool`): Whether the list of data all have the same shape.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; tlist = [torch.randn(3, 5) for i in range(5)]</span>
<span class="sd">        &gt;&gt;&gt; assert same_shape(tlist)</span>
<span class="sd">        &gt;&gt;&gt; tlist = [torch.randn(3, 5), torch.randn(4, 5)]</span>
<span class="sd">        &gt;&gt;&gt; assert not same_shape(tlist)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span>
    <span class="n">shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">shapes</span><span class="p">))</span> <span class="o">==</span> <span class="mi">1</span></div>


<div class="viewcode-block" id="LogDict"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.LogDict">[docs]</a><span class="k">class</span> <span class="nc">LogDict</span><span class="p">(</span><span class="nb">dict</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Derived from ``dict``. Would convert ``torch.Tensor`` to ``list`` for convenient logging.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        ``_transform``, ``__setitem__``, ``update``.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="LogDict._transform"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.LogDict._transform">[docs]</a>    <span class="k">def</span> <span class="nf">_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Convert tensor objects to lists for better logging.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - data (:obj:`Any`): The input data to be converted.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">new_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_data</span> <span class="o">=</span> <span class="n">data</span>
        <span class="k">return</span> <span class="n">new_data</span></div>

    <span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Override the ``__setitem__`` function of built-in dict.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - key (:obj:`Any`): The key of the data item.</span>
<span class="sd">            - value (:obj:`Any`): The value of the data item.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__setitem__</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">new_value</span><span class="p">)</span>

<div class="viewcode-block" id="LogDict.update"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.LogDict.update">[docs]</a>    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Override the ``update`` function of built-in dict.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - data (:obj:`dict`): The dict for updating current object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="fm">__setitem__</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="build_log_buffer"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.build_log_buffer">[docs]</a><span class="k">def</span> <span class="nf">build_log_buffer</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">LogDict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Build log buffer, a subclass of dict, which can convert the input data into log format.</span>
<span class="sd">    Returns:</span>
<span class="sd">        - log_buffer (:obj:`LogDict`): Log buffer dict.</span>
<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; log_buffer = build_log_buffer()</span>
<span class="sd">        &gt;&gt;&gt; log_buffer[&#39;not_tensor&#39;] = torch.randn(3)</span>
<span class="sd">        &gt;&gt;&gt; assert isinstance(log_buffer[&#39;not_tensor&#39;], list)</span>
<span class="sd">        &gt;&gt;&gt; assert len(log_buffer[&#39;not_tensor&#39;]) == 3</span>
<span class="sd">        &gt;&gt;&gt; log_buffer.update({&#39;not_tensor&#39;: 4, &#39;a&#39;: 5})</span>
<span class="sd">        &gt;&gt;&gt; assert log_buffer[&#39;not_tensor&#39;] == 4</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">LogDict</span><span class="p">()</span></div>


<div class="viewcode-block" id="CudaFetcher"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.CudaFetcher">[docs]</a><span class="k">class</span> <span class="nc">CudaFetcher</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Fetch data from source, and transfer it to a specified device.</span>
<span class="sd">    Interfaces:</span>
<span class="sd">        ``__init__``, ``__next__``, ``run``, ``close``.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="CudaFetcher.__init__"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.CudaFetcher.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_source</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">queue_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">sleep</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Initialize the CudaFetcher object using the given arguments.</span>
<span class="sd">        Arguments:</span>
<span class="sd">            - data_source (:obj:`Iterable`): The iterable data source.</span>
<span class="sd">            - device (:obj:`str`): The device to put data to, such as &quot;cuda:0&quot;.</span>
<span class="sd">            - queue_size (:obj:`int`): The internal size of queue, such as 4.</span>
<span class="sd">            - sleep (:obj:`float`): Sleeping time when the internal queue is full.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span> <span class="o">=</span> <span class="n">data_source</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_queue</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="n">queue_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stream</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_producer_thread</span> <span class="o">=</span> <span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_producer</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;cuda_fetcher_producer&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sleep</span> <span class="o">=</span> <span class="n">sleep</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">device</span></div>

    <span class="k">def</span> <span class="fm">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Response to the request for data. Return one data item from the internal queue.</span>
<span class="sd">        Returns:</span>
<span class="sd">            - item (:obj:`Any`): The data item on the required device.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_queue</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>

<div class="viewcode-block" id="CudaFetcher.run"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.CudaFetcher.run">[docs]</a>    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Start ``producer`` thread: Keep fetching data from source, change the device, and put into \</span>
<span class="sd">            ``queue`` for request.</span>
<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; timer = EasyTimer()</span>
<span class="sd">            &gt;&gt;&gt; dataloader = iter([torch.randn(3, 3) for _ in range(10)])</span>
<span class="sd">            &gt;&gt;&gt; dataloader = CudaFetcher(dataloader, device=&#39;cuda&#39;, sleep=0.1)</span>
<span class="sd">            &gt;&gt;&gt; dataloader.run()</span>
<span class="sd">            &gt;&gt;&gt; data = next(dataloader)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_end_flag</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_producer_thread</span><span class="o">.</span><span class="n">start</span><span class="p">()</span></div>

<div class="viewcode-block" id="CudaFetcher.close"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.CudaFetcher.close">[docs]</a>    <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Stop ``producer`` thread by setting ``end_flag`` to ``True`` .</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_end_flag</span> <span class="o">=</span> <span class="kc">True</span></div>

<div class="viewcode-block" id="CudaFetcher._producer"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.CudaFetcher._producer">[docs]</a>    <span class="k">def</span> <span class="nf">_producer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overview:</span>
<span class="sd">            Keep fetching data from source, change the device, and put into ``queue`` for request.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream</span><span class="p">):</span>
            <span class="k">while</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_end_flag</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_queue</span><span class="o">.</span><span class="n">full</span><span class="p">():</span>
                    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_sleep</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="p">)</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="n">to_device</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">data</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="get_tensor_data"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.get_tensor_data">[docs]</a><span class="k">def</span> <span class="nf">get_tensor_data</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Get pure tensor data from the given data (without disturbing grad computation graph).</span>
<span class="sd">    Arguments:</span>
<span class="sd">        - data (:obj:`Any`): The original data. It can be exactly a tensor or a container (Sequence or dict).</span>
<span class="sd">    Returns:</span>
<span class="sd">        - output (:obj:`Any`): The output data.</span>
<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; a = { \</span>
<span class="sd">                &#39;tensor&#39;: torch.tensor([1, 2, 3.], requires_grad=True), \</span>
<span class="sd">                &#39;list&#39;: [torch.tensor([1, 2, 3.], requires_grad=True) for _ in range(2)], \</span>
<span class="sd">                &#39;none&#39;: None \</span>
<span class="sd">            }</span>
<span class="sd">        &gt;&gt;&gt; tensor_a = get_tensor_data(a)</span>
<span class="sd">        &gt;&gt;&gt; assert not tensor_a[&#39;tensor&#39;].requires_grad</span>
<span class="sd">        &gt;&gt;&gt; for t in tensor_a[&#39;list&#39;]:</span>
<span class="sd">        &gt;&gt;&gt;     assert not t.requires_grad</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">get_tensor_data</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">get_tensor_data</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;not support type in get_tensor_data: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span></div>


<div class="viewcode-block" id="unsqueeze"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.unsqueeze">[docs]</a><span class="k">def</span> <span class="nf">unsqueeze</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Unsqueeze the tensor data.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        - data (:obj:`Any`): The original data. It can be exactly a tensor or a container (Sequence or dict).</span>
<span class="sd">        - dim (:obj:`int`): The dimension to be unsqueezed.</span>
<span class="sd">    Returns:</span>
<span class="sd">        - output (:obj:`Any`): The output data.</span>

<span class="sd">    Examples (tensor):</span>
<span class="sd">        &gt;&gt;&gt; t = torch.randn(3, 3)</span>
<span class="sd">        &gt;&gt;&gt; tt = unsqueeze(t, dim=0)</span>
<span class="sd">        &gt;&gt;&gt; assert tt.shape == torch.Shape([1, 3, 3])</span>

<span class="sd">    Examples (list):</span>
<span class="sd">        &gt;&gt;&gt; t = [torch.randn(3, 3)]</span>
<span class="sd">        &gt;&gt;&gt; tt = unsqueeze(t, dim=0)</span>
<span class="sd">        &gt;&gt;&gt; assert tt[0].shape == torch.Shape([1, 3, 3])</span>

<span class="sd">    Examples (dict):</span>
<span class="sd">        &gt;&gt;&gt; t = {&quot;t&quot;: torch.randn(3, 3)}</span>
<span class="sd">        &gt;&gt;&gt; tt = unsqueeze(t, dim=0)</span>
<span class="sd">        &gt;&gt;&gt; assert tt[&quot;t&quot;].shape == torch.Shape([1, 3, 3])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">unsqueeze</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;not support type in unsqueeze: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span></div>


<div class="viewcode-block" id="squeeze"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.squeeze">[docs]</a><span class="k">def</span> <span class="nf">squeeze</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Squeeze the tensor data.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        - data (:obj:`Any`): The original data. It can be exactly a tensor or a container (Sequence or dict).</span>
<span class="sd">        - dim (:obj:`int`): The dimension to be Squeezed.</span>
<span class="sd">    Returns:</span>
<span class="sd">        - output (:obj:`Any`): The output data.</span>

<span class="sd">    Examples (tensor):</span>
<span class="sd">        &gt;&gt;&gt; t = torch.randn(1, 3, 3)</span>
<span class="sd">        &gt;&gt;&gt; tt = squeeze(t, dim=0)</span>
<span class="sd">        &gt;&gt;&gt; assert tt.shape == torch.Shape([3, 3])</span>

<span class="sd">    Examples (list):</span>
<span class="sd">        &gt;&gt;&gt; t = [torch.randn(1, 3, 3)]</span>
<span class="sd">        &gt;&gt;&gt; tt = squeeze(t, dim=0)</span>
<span class="sd">        &gt;&gt;&gt; assert tt[0].shape == torch.Shape([3, 3])</span>

<span class="sd">    Examples (dict):</span>
<span class="sd">        &gt;&gt;&gt; t = {&quot;t&quot;: torch.randn(1, 3, 3)}</span>
<span class="sd">        &gt;&gt;&gt; tt = squeeze(t, dim=0)</span>
<span class="sd">        &gt;&gt;&gt; assert tt[&quot;t&quot;].shape == torch.Shape([3, 3])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">squeeze</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;not support type in squeeze: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span></div>


<div class="viewcode-block" id="get_null_data"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.get_null_data">[docs]</a><span class="k">def</span> <span class="nf">get_null_data</span><span class="p">(</span><span class="n">template</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">num</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Get null data given an input template.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        - template (:obj:`Any`): The template data.</span>
<span class="sd">        - num (:obj:`int`): The number of null data items to generate.</span>
<span class="sd">    Returns:</span>
<span class="sd">        - output (:obj:`List[Any]`): The generated null data.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; temp = {&#39;obs&#39;: [1, 2, 3], &#39;action&#39;: 1, &#39;done&#39;: False, &#39;reward&#39;: torch.tensor(1.)}</span>
<span class="sd">        &gt;&gt;&gt; null_data = get_null_data(temp, 2)</span>
<span class="sd">        &gt;&gt;&gt; assert len(null_data) ==2</span>
<span class="sd">        &gt;&gt;&gt; assert null_data[0][&#39;null&#39;] and null_data[0][&#39;done&#39;]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;null&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;done&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;reward&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ret</span></div>


<div class="viewcode-block" id="zeros_like"><a class="viewcode-back" href="../../../05_api_doc/torch_utils.html#ding.torch_utils.data_helper.zeros_like">[docs]</a><span class="k">def</span> <span class="nf">zeros_like</span><span class="p">(</span><span class="n">h</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overview:</span>
<span class="sd">        Generate zero-tensors like the input data.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        - h (:obj:`Any`): The original data. It can be exactly a tensor or a container (Sequence or dict).</span>
<span class="sd">    Returns:</span>
<span class="sd">        - output (:obj:`Any`): The output zero-tensors.</span>

<span class="sd">    Examples (tensor):</span>
<span class="sd">        &gt;&gt;&gt; t = torch.randn(3, 3)</span>
<span class="sd">        &gt;&gt;&gt; tt = zeros_like(t)</span>
<span class="sd">        &gt;&gt;&gt; assert tt.shape == torch.Shape([3, 3])</span>
<span class="sd">        &gt;&gt;&gt; assert torch.sum(torch.abs(tt)) &lt; 1e-8</span>

<span class="sd">    Examples (list):</span>
<span class="sd">        &gt;&gt;&gt; t = [torch.randn(3, 3)]</span>
<span class="sd">        &gt;&gt;&gt; tt = zeros_like(t)</span>
<span class="sd">        &gt;&gt;&gt; assert tt[0].shape == torch.Shape([3, 3])</span>
<span class="sd">        &gt;&gt;&gt; assert torch.sum(torch.abs(tt[0])) &lt; 1e-8</span>

<span class="sd">    Examples (dict):</span>
<span class="sd">        &gt;&gt;&gt; t = {&quot;t&quot;: torch.randn(3, 3)}</span>
<span class="sd">        &gt;&gt;&gt; tt = zeros_like(t)</span>
<span class="sd">        &gt;&gt;&gt; assert tt[&quot;t&quot;].shape == torch.Shape([3, 3])</span>
<span class="sd">        &gt;&gt;&gt; assert torch.sum(torch.abs(tt[&quot;t&quot;])) &lt; 1e-8</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">h</span><span class="p">]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">zeros_like</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">h</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;not support type: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">h</span><span class="p">))</span></div>
</pre></div>

              </article>
              
            </div>
            <footer>
  

  <hr>

  <div role="contentinfo">
    <p>
      &copy; Copyright 2021, OpenDILab Contributors.

    </p>
  </div>
  
  <div>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a
      href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the
      Docs</a>.
  </div>
   

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="../../../"
    src="../../../_static/documentation_options.js"></script>
  <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
  <script src="../../../_static/doctools.js"></script>
  <script src="../../../_static/sphinx_highlight.js"></script>
  

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  </div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/" aria-label="OpenMMLab"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/DI-engine" target="_blank">GitHub</a>
          </li>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>