


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>GTrXL &mdash; DI-engine 0.1.0 documentation</title>
  

  <link rel="shortcut icon" href="../_static/images/favicon.ico" />
  
  

  

  
  
  

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/style.css" type="text/css" />
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="next" title="QMIX" href="qmix.html" />
  <link rel="prev" title="R2D2" href="r2d2.html" />
    <link href="../_static/css/style.css" rel="stylesheet" type="text/css">


  
  <script src="../_static/js/modernizr.min.js"></script>
  <script>
    MathJax = {
        chtml: {
            scale: 1,
            minScale: 1,
        },
        svg: {
            scale: 1,
            minScale: 1,
        }
    }
</script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/"
        aria-label="OpenMMLab"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/DI-engine" target="_blank">GitHub</a>
          </li>
          <li >
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a
                class="resource-option with-down-arrow">
                OpenDILab
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-engine" target="_blank">
                  <span class="dropdown-title">DI-engine </span>
                  <p>OpenDILab Decision AI Engine</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-star" target="_blank">
                  <span class="dropdown-title">DI-star </span>
                  <p>OpenDILab Decision AI in StarCraftII</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-drive" target="_blank">
                  <span class="dropdown-title">DI-drive </span>
                  <p>OpenDILab Auto-driving platform</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/GoBigger" target="_blank">
                  <span class="dropdown-title">GoBigger </span>
                  <p>OpenDILab Multi-Agent Environment</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-smartcross" target="_blank">
                  <span class="dropdown-title">DI-smartcross </span>
                  <p>Decision Intelligence Platform for Traffic Crossing Signal Control</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-treetensor" target="_blank">
                  <span class="dropdown-title">DI-treetensor </span>
                  <p>Tree Nested PyTorch Tensor Lib</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-model-based-RL" target="_blank">
                  <span class="dropdown-title">awesome-model-based-RL </span>
                  <p>A curated list of awesome model based RL resources (continually updated)</p>
                </a>
              </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../00_intro/index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_quickstart/index.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_algo/index.html">RL Algorithm Taxonomy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03_system/index.html">System Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05_api_doc/index.html">API Doc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06_faq/index.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reinforcement Learning Tutorial</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../10_concepts/index.html">Introduction to RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11_dizoo/index.html">Learn From DI-zoo</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">RL Algorithms Cheat Sheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../13_envs/index.html">RL Env Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../20_spec/index.html">Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../21_code_style/index.html">Code Style Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../22_test/index.html">Unit Test Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../23_visual/index.html">Diagrams and Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../24_cooperation/index.html">Github Cooperation</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
            Docs
        </a> &gt;
      </li>

        
          <li><a href="index.html">RL Algorithms Cheat Sheet</a> &gt;</li>
        
      <li>GTrXL</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/12_policies/gtrxl.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
  <section id="gtrxl">
<h1>GTrXL<a class="headerlink" href="#gtrxl" title="Permalink to this headline">¶</a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>Gated Transformer-XL, or GTrXL, first proposed in <a class="reference external" href="https://arxiv.org/pdf/1910.06764.pdf">Stabilizing Transformers for Reinforcement Learning</a>,
is a novel framework for reinforcement learning adapted from the Transformer-XL architecture.
It mainly introduces two architectural modifications that improve the stability and learning speed of Transformer including:
placing the layer normalization on only the input stream of the submodules, and replacing residual connections with gating layers.
The proposed architecture, surpasses LSTMs on challenging memory environments and achieves state-of-the-art
results on the several memory benchmarks, exceeding the performance of an external memory architecture.</p>
</section>
<section id="quick-facts">
<h2>Quick Facts<a class="headerlink" href="#quick-facts" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>GTrXL can serve as a <strong>backbone</strong> for many RL algorithms.</p></li>
<li><p>GTrXL only supports <strong>sequential</strong> observations.</p></li>
<li><p>GTrXL is based on <strong>Transformer-XL</strong> with <strong>Gating connections</strong>.</p></li>
<li><p>The DI-engine implementation of GTrXL is based on the R2D2 algorithm. In the original paper, it is based on the algorithm <a class="reference external" href="https://arxiv.org/abs/1909.12238">V-MPO</a>.</p></li>
</ol>
</section>
<section id="key-equations-or-key-graphs">
<h2>Key Equations or Key Graphs<a class="headerlink" href="#key-equations-or-key-graphs" title="Permalink to this headline">¶</a></h2>
<p><strong>Transformer-XL</strong>: to address the context fragmentation problem, Transformer-XL introduces the notion of recurrence to the deep self-attention network.
Instead of computing the hidden states from scratch for each new segment, Transformer-XL reuses the hidden states obtained in previous segments.
The reused hidden states serve as memory for the current segment, which builds up a recurrent connection between the segments.
As a result, modeling very long-term dependency becomes possible because information can be propagated through the recurrent connections.
In order to enable state reuse without causing temporal confusion, Transformer-XL proposes a new relative positional encoding formulation that generalizes to attention lengths longer than the one observed during training.</p>
<img alt="../_images/transformerXL_train_eval.png" class="align-center" src="../_images/transformerXL_train_eval.png" />
<p><strong>Identity Map Reordering</strong>: move the layer normalization to the input stream of the submodules.
A key benefit to this reordering is that it now enables an identity map from the input of the transformer at the first layer to the output of the transformer after the last layer.
This is in contrast to the canonical transformer, where there are a series of layer normalization operations that non-linearly transform the state encoding.
One hypothesis as to why the Identity Map Reordering improves results is as follows: assuming that the submodules at initialization produce values that are in expectation near
zero, the state encoding is passed un-transformed to the policy and value heads, enabling the agent to learn a Markovian policy at the start of training
(i.e., the network is initialized such that <span class="math notranslate nohighlight">\(\pi(·|st,...,s1) ≈ \pi(·|st)\)</span> and <span class="math notranslate nohighlight">\(V^\pi(s_t|s_{t-1},...,s_1) ≈ V^\pi(s_t|s_{t-1})\)</span>),
thus ignoring the contribution of past observations coming from the memory of the attention-XL.
In many environments, reactive behaviours need to be learned before memory-based ones can be effectively utilized.
For example, an agent needs to learn how to walk before it can learn how to remember where it has walked.
With identity map reordering the forward pass of the model can be computed as:</p>
<img alt="../_images/identity_map_reordering.png" class="align-center" src="../_images/identity_map_reordering.png" />
<a class="reference internal image-reference" href="../_images/gtrxl.png"><img alt="../_images/gtrxl.png" class="align-center" src="../_images/gtrxl.png" style="height: 300px;" /></a>
<p><strong>Gating layers</strong>: replace the residual connections with gating layers. Among several studied gating functions, Gated Recurrent Unit (GRU) is the one that performs the best.
Its adapted powerful gating mechanism can be expressed as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
r &amp;= \sigma(W_r^{(l)} y + U_r^{(l)} x) \\
z &amp;= \sigma(W_z^{(l)} y + U_z^{(l)} x - b_g^{(l)}) \\
\hat{h} &amp;= \tanh(W_g^{(l)} y + U_g^{(l)} (r \odot x)) \\
g^{(l)}(x, y) &amp;= (1-z)\odot x + z\odot \hat{h}
\end{aligned}\end{split}\]</div>
<p><strong>Gated Identity Initialization</strong>: the authors claimed that the Identity Map Reordering aids policy optimization because it initializes the agent close to a Markovian policy or value function.
If this is indeed the cause of improved stability, we can explicitly initialize the various gating mechanisms to be close to the identity map.
This is the purpose of the bias <span class="math notranslate nohighlight">\(b_g^{(l)}\)</span> in the applicable gating layers. The authors demonstrate in an ablation that initially setting <span class="math notranslate nohighlight">\(b_g^{(l)}&gt;0\)</span> produces the best results.</p>
</section>
<section id="extensions">
<h2>Extensions<a class="headerlink" href="#extensions" title="Permalink to this headline">¶</a></h2>
<p>GTrXL can be combined with:</p>
<blockquote>
<div><ul>
<li><p>CoBERL (<a class="reference external" href="https://arxiv.org/pdf/2107.05431.pdf">CoBERL: Contrastive BERT for Reinforcement Learning</a>):</p>
<blockquote>
<div><p>Contrastive BERT (CoBERL) is a reinforcement learning agent that combines a new contrastive loss and a hybrid LSTM-transformer
architecture to tackle the challenge of improving data efficiency for RL. It uses bidirectional masked prediction in combination
with a generalization of recent contrastive methods to learn better representations for transformers in RL, without the need of hand engineered data augmentations.</p>
</div></blockquote>
</li>
<li><p>R2D2 (<a class="reference external" href="https://openreview.net/pdf?id=r1lyTjAqYX">Recurrent Experience Replay in Distributed Reinforcement Learning</a>):</p>
<p>Recurrent Replay Distributed DQN (R2D2) demonstrates how replay and the RL learning objective can be adapted to work well for agents with recurrent
architectures. The LSTM can be replaced or combined with gated transformer so that we can leverage the benefits of distributed experience collection, storing
the recurrent agent state in the replay buffer, and “burning in” a portion of the unrolled network with replayed sequences during training.</p>
</li>
</ul>
</div></blockquote>
</section>
<section id="implementations">
<h2>Implementations<a class="headerlink" href="#implementations" title="Permalink to this headline">¶</a></h2>
<p>The network interface GTrXL used is defined as follows:</p>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.torch_utils.network.gtrxl.</span></span><span class="sig-name descname"><span class="pre">GTrXL</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">head_dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">head_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory_len</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_ratio</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.nn.modules.module.Module</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">ReLU()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gru_gating</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gru_bias</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_embedding_layer</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/torch_utils/network/gtrxl.html#GTrXL"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>GTrXL Transformer implementation.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For details refer to Stabilizing Transformer for Reinforcement Learning: <a class="reference external" href="https://arxiv.org/abs/1910.06764">https://arxiv.org/abs/1910.06764</a></p>
</div>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_first</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_mem</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/torch_utils/network/gtrxl.html#GTrXL.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>GTrXL forward pass.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>): input tensor. Shape (seq_len, bs, input_size).</p></li>
<li><p>batch_first (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): if the input data has shape (bs, seq_len, input_size), set this param to                 <code class="docutils literal notranslate"><span class="pre">True</span></code> in order to transpose along the first and second dimension and obtain shape                 (seq_len, bs, input_size). This param doesn’t affects the output memory.</p></li>
<li><p>return_mem (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): if this param is False, return only the output tensor without dict.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">torch.Tensor]</span></code>): dict containing transformer output of shape              (seq_len, bs, embedding_size) and memory of shape (layer_num, seq_len, bs, embedding_size)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">get_memory</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/torch_utils/network/gtrxl.html#GTrXL.get_memory"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Returns memory of GTrXL.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>memory: (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Optional[torch.Tensor]</span></code>): output memory or None if memory has not been initialized.                 Shape is (layer_num, memory_len, bs, embedding_dim).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">reset_memory</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/torch_utils/network/gtrxl.html#GTrXL.reset_memory"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Clear or set the memory of GTrXL.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>batch_size (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Optional[int]</span></code>): batch size</p></li>
<li><p>state (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Optional[torch.Tensor]</span></code>): input memory. Shape is (layer_num, memory_len, bs, embedding_dim).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<p>The default implementation of our R2D2-based GTrXL is defined as follows:</p>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.r2d2_gtrxl.</span></span><span class="sig-name descname"><span class="pre">R2D2GTrXLPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/r2d2_gtrxl.html#R2D2GTrXLPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Policy class of R2D2 adopting the Transformer architecture GTrXL as backbone.</p>
</dd>
<dt>Config:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 2%" />
<col style="width: 19%" />
<col style="width: 7%" />
<col style="width: 13%" />
<col style="width: 37%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Symbol</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Other(Shape)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">type</span></code></p></td>
<td><p>str</p></td>
<td><p>r2d2_gtrxl</p></td>
<td><div class="line-block">
<div class="line">RL policy register name, refer to</div>
<div class="line">registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line">This arg is optional,</div>
<div class="line">a placeholder</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cuda</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to use cuda for network</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This arg can be diff-</div>
<div class="line">erent from modes</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">on_policy</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether the RL algorithm is on-policy</div>
<div class="line">or off-policy</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">priority</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use priority(PER)</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Priority sample,</div>
<div class="line">update priority</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">priority_IS</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_weight</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use Importance Sampling Weight</div>
<div class="line">to correct biased update. If True,</div>
<div class="line">priority must be True.</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">discount_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">factor</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.99,
[0.95, 0.999]</p></td>
<td><div class="line-block">
<div class="line">Reward’s future discount factor, aka.</div>
<div class="line">gamma</div>
</div>
</td>
<td><div class="line-block">
<div class="line">May be 1 when sparse</div>
<div class="line">reward env</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">nstep</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>5,
[3, 5]</p></td>
<td><div class="line-block">
<div class="line">N-step reward discount sum for target</div>
<div class="line">q_value estimation</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">burnin_step</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>1</p></td>
<td><div class="line-block">
<div class="line">The timestep of burnin operation,</div>
<div class="line">which is designed to warm-up GTrXL</div>
<div class="line">memory difference caused by off-policy</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.update</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">per_collect</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>1</p></td>
<td><div class="line-block">
<div class="line">How many updates(iterations) to train</div>
<div class="line">after collector’s one collection. Only</div>
<div class="line">valid in serial training</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This args can be vary</div>
<div class="line">from envs. Bigger val</div>
<div class="line">means more off-policy</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.batch_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">size</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>64</p></td>
<td><div class="line-block">
<div class="line">The number of samples of an iteration</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>11</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.001</p></td>
<td><div class="line-block">
<div class="line">Gradient step length of an iteration.</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>12</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.value_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">rescale</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>True</p></td>
<td><div class="line-block">
<div class="line">Whether use value_rescale function for</div>
<div class="line">predicted value</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>13</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.target_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">update_freq</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>100</p></td>
<td><div class="line-block">
<div class="line">Frequence of target network update.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Hard(assign) update</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>14</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.ignore_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">done</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether ignore done for target value</div>
<div class="line">calculation.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Enable it for some</div>
<div class="line">fake termination env</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>15</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">collect.n_sample</span></code></p></td>
<td><p>int</p></td>
<td><p>[8, 128]</p></td>
<td><div class="line-block">
<div class="line">The number of training samples of a</div>
<div class="line">call of collector.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">It varies from</div>
<div class="line">different envs</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>16</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect.unroll</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_len</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>25</p></td>
<td><div class="line-block">
<div class="line">unroll length of an iteration</div>
</div>
</td>
<td><div class="line-block">
<div class="line">unroll_len&gt;1</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>17</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect.seq</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_len</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>20</p></td>
<td><div class="line-block">
<div class="line">Training sequence length</div>
</div>
</td>
<td><div class="line-block">
<div class="line">unroll_len&gt;=seq_len&gt;1</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>18</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.init_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">memory</span></code></div>
</div>
</td>
<td><p>str</p></td>
<td><p>zero</p></td>
<td><div class="line-block">
<div class="line">‘zero’ or ‘old’, how to initialize the</div>
<div class="line">memory before each training iteration.</div>
</div>
</td>
<td><div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
</tr>
</tbody>
</table>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">_data_preprocess_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../_modules/ding/policy/r2d2_gtrxl.html#R2D2GTrXLPolicy._data_preprocess_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Preprocess the data to fit the required data format for learning</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[Dict[str,</span> <span class="pre">Any]]</span></code>): the data collected from collect function</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): the processed data, including at least </dt><dd><p>[‘main_obs’, ‘target_obs’, ‘burnin_obs’, ‘action’, ‘reward’, ‘done’, ‘weight’]</p>
</dd>
</dl>
</li>
<li><p>data_info (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): the data info, such as replay_buffer_idx, replay_unique_id</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/r2d2_gtrxl.html#R2D2GTrXLPolicy._forward_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward and backward function of learn mode.
Acquire the data, calculate the loss and optimize learner model.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type data, including at least </dt><dd><p>[‘main_obs’, ‘target_obs’, ‘burnin_obs’, ‘action’, ‘reward’, ‘done’, ‘weight’]</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Including cur_lr and total_loss</dt><dd><ul>
<li><p>cur_lr (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): Current learning rate</p></li>
<li><p>total_loss (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The calculated loss</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/r2d2_gtrxl.html#R2D2GTrXLPolicy._init_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Init the learner model of GTrXLR2D2Policy.             Target model has 2 wrappers: ‘target’ for weights update and ‘transformer_segment’ to split trajectories             in segments. Learn model has 2 wrappers: ‘argmax’ to select the best action and ‘transformer_segment’.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>learning_rate (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The learning rate fo the optimizer</p></li>
<li><p>gamma (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The discount factor</p></li>
<li><p>nstep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The num of n step return</p></li>
<li><p>value_rescale (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use value rescaled loss in algorithm</p></li>
<li><p>burnin_step (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The num of step of burnin</p></li>
<li><p>seq_len (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): Training sequence length</p></li>
<li><p>init_memory (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): ‘zero’ or ‘old’, how to initialize the memory before each training iteration.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">_init_learn</span></code> method takes the argument from the self._cfg.learn in the config file</p>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="benchmark">
<h2>Benchmark<a class="headerlink" href="#benchmark" title="Permalink to this headline">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 12%" />
<col style="width: 38%" />
<col style="width: 19%" />
<col style="width: 16%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>environment</p></th>
<th class="head"><p>best mean reward</p></th>
<th class="head"><p>evaluation results</p></th>
<th class="head"><p>config link</p></th>
<th class="head"><p>comparison</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Pong</p>
<p>(PongNoFrameskip-v4)</p>
</td>
<td><p>20</p></td>
<td><img alt="../_images/pong_gtrxl_r2d2.png" src="../_images/pong_gtrxl_r2d2.png" />
</td>
<td><p><a class="reference external" href="https://github.com/opendilab/DI-engine/tree/main/dizoo/atari/config/serial/pong/pong_r2d2_gtrxl_config.py">config_link_p</a></p></td>
<td></td>
</tr>
</tbody>
</table>
<p>P.S.：</p>
<ol class="arabic simple">
<li><p>The above results are obtained by running the same configuration on five different random seeds (0, 1, 2, 3, 4)</p></li>
<li><p>For the discrete action space algorithm like DQN, the Atari environment set is generally used for testing (including sub-environments Pong), and Atari environment is generally evaluated by the highest mean reward training 10M <code class="docutils literal notranslate"><span class="pre">env_step</span></code>. For more details about Atari, please refer to <a class="reference external" href="../env_tutorial/atari.html">Atari Env Tutorial</a> .</p></li>
</ol>
</section>
<section id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Parisotto, Emilio, et al. “Stabilizing Transformers for Reinforcement Learning.”, 2019; [<a class="reference external" href="http://arxiv.org/abs/1910.06764">http://arxiv.org/abs/1910.06764</a> arXiv:1910.06764]</p></li>
<li><p>Dai, Zihang , et al. “Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context.”, 2019; [<a class="reference external" href="http://arxiv.org/abs/1901.02860">http://arxiv.org/abs/1901.02860</a> arXiv:1901.02860]</p></li>
</ul>
</section>
</section>


              </article>
              
            </div>
            <footer>
  
  <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
    
    <a href="qmix.html" class="btn btn-neutral float-right" title="QMIX" accesskey="n"
      rel="next">Next <img src="../_static/images/chevron-right-blue.svg"
        class="next-page"></a>
    
    
    <a href="r2d2.html" class="btn btn-neutral" title="R2D2" accesskey="p"
      rel="prev"><img src="../_static/images/chevron-right-blue.svg" class="previous-page"> Previous</a>
    
  </div>
  

  <hr>

  <div role="contentinfo">
    <p>
      &copy; Copyright 2021, OpenDILab Contributors.

    </p>
  </div>
  
  <div>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a
      href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the
      Docs</a>.
  </div>
   

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">GTrXL</a><ul>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#quick-facts">Quick Facts</a></li>
<li><a class="reference internal" href="#key-equations-or-key-graphs">Key Equations or Key Graphs</a></li>
<li><a class="reference internal" href="#extensions">Extensions</a></li>
<li><a class="reference internal" href="#implementations">Implementations</a></li>
<li><a class="reference internal" href="#benchmark">Benchmark</a></li>
<li><a class="reference internal" href="#reference">Reference</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="../"
    src="../_static/documentation_options.js"></script>
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
  <script src="../_static/jquery.js"></script>
  <script src="../_static/underscore.js"></script>
  <script src="../_static/doctools.js"></script>
  <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  </div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/" aria-label="OpenMMLab"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/DI-engine" target="_blank">GitHub</a>
          </li>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>