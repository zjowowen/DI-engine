

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>D4PG &mdash; DI-engine 0.1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="TD3" href="td3.html" />
    <link rel="prev" title="DDPG" href="ddpg.html" />
    <link href="../_static/css/style.css" rel="stylesheet" type="text/css">

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> DI-engine
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/index.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../key_concept/index.html">Key Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro_rl/index.html">Introduction to RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html">RL Algorithm Cheat Sheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../env_tutorial/index.html">RL Environments Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed/index.html">Distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../best_practice/index.html">Best Practice</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_doc/index.html">API Doc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/index.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../feature/index.html">Feature</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../guide/index.html">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial_dev/index.html">Tutorial-Developer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../architecture/index.html">Architecture Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../specification/index.html">Middleware code specification</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DI-engine</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">RL Algorithm Cheat Sheet</a> &raquo;</li>
        
      <li>D4PG</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/hands_on/d4pg.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="d4pg">
<h1>D4PG<a class="headerlink" href="#d4pg" title="Permalink to this headline">¶</a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>D4PG, proposed in the paper <a class="reference external" href="https://arxiv.org/abs/1804.08617v1">Distributed Distributional Deterministic Policy Gradients</a>,
is an actor-critic, model-free policy gradient algorithm that extends upon <a class="reference external" href="https://arxiv.org/abs/1509.02971">DDPG</a>.
Improvements over DDPG include the use of N-step returns, prioritized experience replay and distributional value function.
Moreover, training is parallelized with multiple distributed workers all writing into the same replay table.
The authors found that these simple modifications contribute to the overall performance of the algorithm with N-step
returns brining the biggest performance gain and priority buffer being the less crucial one.</p>
</section>
<section id="quick-facts">
<h2>Quick Facts<a class="headerlink" href="#quick-facts" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>D4PG is only used for environments with <strong>continuous action spaces</strong>.(i.e. MuJoCo)</p></li>
<li><p>D4PG is an <strong>off-policy</strong> algorithm.</p></li>
<li><p>D4PG uses a <strong>distributional</strong> critic.</p></li>
<li><p>D4PG is a <strong>model-free</strong> and <strong>actor-critic</strong> RL algorithm, which optimizes actor network and critic network, respectively.</p></li>
<li><p>Usually, D4PG uses <strong>Ornstein-Uhlenbeck process</strong> or <strong>Gaussian process</strong> (default in our implementation) for exploration.</p></li>
</ol>
</section>
<section id="key-equations-or-key-graphs">
<h2>Key Equations or Key Graphs<a class="headerlink" href="#key-equations-or-key-graphs" title="Permalink to this headline">¶</a></h2>
<p>The D4PG algorithm maintains a distributional critic <span class="math notranslate nohighlight">\(Z_\pi(s, a)\)</span> which estimates the expected Q value as a
random variable such that <span class="math notranslate nohighlight">\(Q(s, a)=\mathbb{E}Z_\pi(s, a)\)</span>. <span class="math notranslate nohighlight">\(Z\)</span> is usually a Categorical distribution over Q with 51 supports.</p>
<p>Accordingly, the distributional Bellman operator can be defined as:</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
(\mathcal{T}_{\pi} Z)(s, a)=r(s, a)+\gamma\mathbb{E}[Z(s',\pi(s'))|(s, a)]
\end{aligned}\]</div>
<p>The distributional variant of the operator takes functions which map from state-action pairs to distributions, and returns a function of the same form.
The loss used to learn the <strong>critic distribution</strong> parameters is defined as <span class="math notranslate nohighlight">\(L(\pi) = \mathbb{E}[d(\mathcal{T}_{\pi_{\theta'}}, Z_{w'}(s, a), Z_{w}(s, a)]\)</span>
for some metric <span class="math notranslate nohighlight">\(d\)</span> that measures the distance between two distributions.</p>
<p>Finally, the actor update is done by taking the expectation with respect to the <strong>action-value distribution</strong>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\nabla_\theta J(\theta)
&amp;\approx \mathbb{E}_{\rho^\pi} [\nabla_a Q_w(s, a) \nabla_\theta \pi_{\theta}(s) \rvert_{a=\pi\theta(s)}] \\
&amp;= \mathbb{E}_{\rho^\pi} [\mathbb{E}[\nabla_a Z_w(s, a)] \nabla_\theta \pi_{\theta}(s) \rvert_{a=\pi\theta(s)}]
\end{aligned}\end{split}\]</div>
<p>When calculating the TD error, D4PG computes <strong>N-step</strong> in the TD target to incorporate rewards in more future steps:</p>
<div class="math notranslate nohighlight">
\[r(s_0, a_0) + \mathbb{E}[\sum_{n=1}^{N-1} \gamma^n r(s_n, a_n) + \gamma^N Q(s_N, \mu_\theta(s_N)) \vert s_0, a_0 ]\]</div>
<p>D4PG samples from a <strong>prioritized replay buffer</strong> with a non-uniform probability <span class="math notranslate nohighlight">\(p_i\)</span>.
This requires the use of importance sampling, implemented by weighting the critic update by a factor of <span class="math notranslate nohighlight">\(R_{p_i}^{-1}\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>D4PG utilizes multiple <strong>parallel independent actors</strong>, gathering experience and feeding data into the same replay buffer.
However, our implementation only makes use of a single actor.</p>
</div>
</section>
<section id="pseudocode">
<h2>Pseudocode<a class="headerlink" href="#pseudocode" title="Permalink to this headline">¶</a></h2>
<figure class="align-center" id="id1">
<a class="reference internal image-reference" href="../_images/D4PG_algo.png"><img alt="../_images/D4PG_algo.png" src="../_images/D4PG_algo.png" style="width: 1048.5px; height: 810.0px;" /></a>
<figcaption>
<p><span class="caption-text">source: <a class="reference external" href="https://lilianweng.github.io/posts/2018-04-08-policy-gradient/#d4pg">https://lilianweng.github.io/posts/2018-04-08-policy-gradient/#d4pg</a></span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="implementations">
<h2>Implementations<a class="headerlink" href="#implementations" title="Permalink to this headline">¶</a></h2>
<p>The default config is defined as follows:</p>
<section id="model">
<h3>Model<a class="headerlink" href="#model" title="Permalink to this headline">¶</a></h3>
<p>Here we provide examples of <cite>QACDIST</cite> model as default model for <cite>D4PG</cite>.</p>
</section>
</section>
<section id="benchmark">
<h2>Benchmark<a class="headerlink" href="#benchmark" title="Permalink to this headline">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 12%" />
<col style="width: 38%" />
<col style="width: 19%" />
<col style="width: 16%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>environment</p></th>
<th class="head"><p>best mean reward</p></th>
<th class="head"><p>evaluation results</p></th>
<th class="head"><p>config link</p></th>
<th class="head"><p>comparison</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Halfcheetah</p>
<p>(Halfcheetah-v3)</p>
</td>
<td><p>13000</p></td>
<td><img alt="../_images/halfcheetah_d4pg.png" src="../_images/halfcheetah_d4pg.png" />
</td>
<td><p><a class="reference external" href="https://github.com/opendilab/DI-engine/blob/main/dizoo/mujoco/config/halfcheetah_d4pg_default_config.py">config_link_ha</a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Walker2d</p>
<p>(Walker2d-v2)</p>
</td>
<td><p>5300</p></td>
<td><img alt="../_images/walker2d_d4pg.png" src="../_images/walker2d_d4pg.png" />
</td>
<td><p><a class="reference external" href="https://github.com/opendilab/DI-engine/blob/main/dizoo/mujoco/config/walker2d_d4pg_default_config.py">config_link_w</a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>Hopper</p>
<p>(Hopper-v2)</p>
</td>
<td><p>3500</p></td>
<td><img alt="../_images/hopper_d4pg.png" src="../_images/hopper_d4pg.png" />
</td>
<td><p><a class="reference external" href="https://github.com/opendilab/DI-engine/blob/main/dizoo/mujoco/config/hopper_d4pg_default_config.py">config_link_ho</a></p></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="other-public-implementations">
<h2>Other Public Implementations<a class="headerlink" href="#other-public-implementations" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/schatty/d4pg-pytorch">D4PG Pytorch</a></p></li>
</ul>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Gabriel Barth-Maron, Matthew W. Hoffman, David Budden, Will Dabney, Dan Horgan, Dhruva TB, Alistair Muldal, Nicolas Heess, Timothy Lillicrap: “Distributed Distributional Deterministic Policy Gradients”, 2018; [<a class="reference external" href="https://arxiv.org/abs/1804.08617v1">https://arxiv.org/abs/1804.08617v1</a> arXiv:1804.08617v1].</p></li>
</ul>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="td3.html" class="btn btn-neutral float-right" title="TD3" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="ddpg.html" class="btn btn-neutral float-left" title="DDPG" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, OpenDILab Contributors

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>