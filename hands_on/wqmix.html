

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>WQMIX &mdash; DI-engine 0.1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="CollaQ" href="collaq.html" />
    <link rel="prev" title="COMA" href="coma.html" />
    <link href="../_static/css/style.css" rel="stylesheet" type="text/css">

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> DI-engine
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/index.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../key_concept/index.html">Key Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro_rl/index.html">Introduction to RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html">RL Algorithm Cheat Sheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../env_tutorial/index.html">RL Environments Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed/index.html">Distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../best_practice/index.html">Best Practice</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_doc/index.html">API Doc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/index.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../feature/index.html">Feature</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../guide/index.html">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial_dev/index.html">Tutorial-Developer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../architecture/index.html">Architecture Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../specification/index.html">Middleware code specification</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DI-engine</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">RL Algorithm Cheat Sheet</a> &raquo;</li>
        
      <li>WQMIX</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/hands_on/wqmix.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="wqmix">
<h1>WQMIX<a class="headerlink" href="#wqmix" title="Permalink to this headline">¶</a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>WQMIX was first proposed in <a class="reference external" href="https://arxiv.org/abs/2006.10800">Weighted QMIX: Expanding Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning</a>.
Their focus of study is the unique properties of the particular function space represented by monotonic structure of Q functions in QMIX,
and the tradeoffs in representation quality across different joint actions induced by projection into that space.
They show that the projection in QMIX can fail to recover the optimal policy,
which primarily stems from the equal weighting placed on each joint action.
WQMIX rectify this by introducing a weighting into the projection, in order to place more importance on the better joint actions.</p>
<p>WQMIX propose two weighting schemes and prove that they recover the correct maximal action for any joint action Q-values.</p>
<p>WQMIX introduce two scalable versions:
Centrally-Weighted (CW) QMIX and Optimistically-Weighted (OW) QMIX and demonstrate improved performance on both predator-prey and challenging multi-agent StarCraft benchmark tasks.</p>
</section>
<section id="quick-facts">
<h2>Quick Facts<a class="headerlink" href="#quick-facts" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>WQMIX is an <strong>off-policy model-free value-based multi-agent</strong> RL algorithm using the paradigm of <strong>centralized training with decentralized execution</strong>.
And only support <strong>discrete</strong> action spaces.</p></li>
<li><p>WQMIX considers a <strong>partially observable</strong> scenario in which each agent only obtains individual observations.</p></li>
<li><p>WQMIX accepts <strong>DRQN</strong> as individual value network.</p></li>
<li><p>WQMIX represents the joint value function using an architecture consisting of agent networks and a <strong>mixing network</strong>.
The mixing network is a feed-forward neural network that takes the agent network outputs as input and mixes them monotonically, producing joint action values.</p></li>
</ol>
</section>
<section id="key-equations-or-key-graphs">
<h2>Key Equations or Key Graphs<a class="headerlink" href="#key-equations-or-key-graphs" title="Permalink to this headline">¶</a></h2>
<p>The overall WQMIX architecture including individual agent networks and the mixing network structure:</p>
<a class="reference internal image-reference" href="../_images/wqmix_setup.png"><img alt="../_images/wqmix_setup.png" class="align-center" src="../_images/wqmix_setup.png" style="width: 735.6px; height: 232.79999999999998px;" /></a>
<p>First, WQMIX examine an operator that represents an idealised version of QMIX in a tabular setting.
The purpose of this analysis is primarily to understand the fundamental limitations of QMIX that stem from its training objective and the restricted function class it uses.
This is the space of all <span class="math notranslate nohighlight">\(Q_{tot}\)</span> that can be represented by monotonic funtions of tabular <span class="math notranslate nohighlight">\(Q_{a}(s,u)\)</span> :</p>
<div class="math notranslate nohighlight">
\[\mathcal{Q}^{m i x}:=\left\{Q_{t o t} \mid Q_{t o t}(s, \mathbf{u})=f_{s}\left(Q_{1}\left(s, u_{1}\right), \ldots Q_{n}\left(s, u_{n}\right)\right), \frac{\partial f_{s}}{\partial Q_{a}} \geq 0, Q_{a}(s, u) \in \mathbb{R}\right\}\]</div>
<p>At each iteration of our idealised QMIX algorithm, we constrain <span class="math notranslate nohighlight">\(Q_{tot}\)</span> to lie in the above space by solving the following optimisation problem:</p>
<div class="math notranslate nohighlight">
\[\underset{q \in \mathcal{Q}^{m i x}}{\operatorname{argmin}} \sum_{\mathbf{u} \in \mathbf{U}}\left(\mathcal{T}^{*} Q_{t o t}(s, \mathbf{u})-q(s, \mathbf{u})\right)^{2}\]</div>
<p>where, the Bellman optimality operator is defined by:</p>
<div class="math notranslate nohighlight">
\[\mathcal{T}^{*} Q(s, \mathbf{u}):=\mathbb{E}\left[r+\gamma \max _{\mathbf{u}^{\prime}} Q\left(s^{\prime}, \mathbf{u}^{\prime}\right)\right]\]</div>
<p>Then define the corresponding projection operator <span class="math notranslate nohighlight">\(T^{Qmix}\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[\Pi_{\mathrm{Qmix}} Q:=\underset{q \in \mathcal{Q}^{\text {mix }}}{\operatorname{argmin}} \sum_{\mathbf{u} \in \mathbf{U}}(Q(s, \mathbf{u})-q(s, \mathbf{u}))^{2}\]</div>
<p>Properties of <span class="math notranslate nohighlight">\(T_{*}^{Qmix}\)</span> :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(T_{*}^{Qmix}\)</span> is not a contraction.</p></li>
<li><p>QMIX’s argmax is not always correct.</p></li>
<li><p>QMIX can underestimate the value of the optimal joint action.</p></li>
</ul>
<p>The WQMIX paper argues that this equal weighting over joint actions when performing the optimisation in QMIX.
is responsible for the possibly incorrect argmax of the objective minimising solution.
To prioritise estimating <span class="math notranslate nohighlight">\(T_{tot}(u^{*})\)</span> well, while still anchoring down the value estimates for other joint actions,
we can add a suitable weighting function w into the projection operator of QMIX:</p>
<div class="math notranslate nohighlight">
\[\Pi_{w} Q:=\underset{q \in \mathcal{Q}^{\text {mix }}}{\operatorname{argmin}} \sum_{\mathbf{u} \in \mathbf{U}} w(s, \mathbf{u})(Q(s, \mathbf{u})-q(s, \mathbf{u}))^{2}\]</div>
<p>The choice of weighting is crucial to ensure that WQMIX can overcome the limitations of QMIX.
WQMIX considers two different weightings and proved that
these choices of w ensure that the <span class="math notranslate nohighlight">\(Q_{tot}\)</span> returned from the projection has the correct argmax.</p>
<p><strong>Idealised Central Weighting</strong>:
It implies down-weight every suboptimal action. However, this weighting requires computing the maximum across the joint action space, which is often infeasible.
In implementation WQMIX takes an approximation to this weighting in the deep RL setting.</p>
<div class="math notranslate nohighlight">
\[\begin{split}w(s, \mathbf{u})=\left\{\begin{array}{ll} 1 &amp; \mathbf{u}=\mathbf{u}^{*}=\operatorname{argmax}_{\mathbf{u}} Q(s, \mathbf{u}) \\ \alpha &amp; \text { otherwise } \end{array}\right.\end{split}\]</div>
<p><strong>Optimistic Weighting</strong>:
This weighting assigns a higher weighting to those joint actions that are underestimated relative to Q,
and hence could be the true optimal actions (in an optimistic outlook).</p>
<div class="math notranslate nohighlight">
\[\begin{split}w(s, \mathbf{u})=\left\{\begin{array}{ll} 1 &amp; Q_{t o t}(s, \mathbf{u})&lt;Q(s, \mathbf{u}) \\ \alpha &amp; \text { otherwise } \end{array}\right.\end{split}\]</div>
<p>For the details analysis, please refer to the  <a class="reference external" href="https://arxiv.org/abs/2006.10800">WQMIX paper</a>.</p>
</section>
<section id="implementations">
<h2>Implementations<a class="headerlink" href="#implementations" title="Permalink to this headline">¶</a></h2>
<p>The default config is defined as follows:</p>
<p>The network interface WQMIX used is defined as follows:</p>
</section>
<section id="benchmark">
<h2>Benchmark<a class="headerlink" href="#benchmark" title="Permalink to this headline">¶</a></h2>
<p>The Benchmark result of WQMIX in SMAC (Samvelyan et al. 2019), for StarCraft micromanagement problems, implemented in DI-engine is shown.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 12%" />
<col style="width: 37%" />
<col style="width: 18%" />
<col style="width: 18%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>smac map</p></th>
<th class="head"><p>best mean reward</p></th>
<th class="head"><p>evaluation results</p></th>
<th class="head"><p>config link</p></th>
<th class="head"><p>comparison</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>MMM</p></td>
<td><p>1.00</p></td>
<td><img alt="../_images/WQMIX_MMM.png" src="../_images/WQMIX_MMM.png" />
</td>
<td><p><a class="reference external" href="https://github.com/opendilab/DI-engine/tree/main/dizoo/smac/config/smac_MMM_wqmix_config.py">config_link_M</a></p></td>
<td><p><a class="reference external" href="https://github.com/oxwhirl/wqmix">wqmix(Tabish)</a>
(1.0)</p></td>
</tr>
<tr class="row-odd"><td><p>3s5z</p></td>
<td><p>0.72</p></td>
<td><img alt="../_images/WQMIX_3s5z.png" src="../_images/WQMIX_3s5z.png" />
</td>
<td><p><a class="reference external" href="https://github.com/opendilab/DI-engine/tree/main/dizoo/smac/config/smac_3s5z_wqmix_config.py">config_link_3</a></p></td>
<td><p><a class="reference external" href="https://github.com/oxwhirl/wqmix">wqmix(Tabish)</a>
(0.94)</p></td>
</tr>
<tr class="row-even"><td><p>5m6m</p></td>
<td><p>0.45</p></td>
<td><img alt="../_images/WQMIX_5m6m.png" src="../_images/WQMIX_5m6m.png" />
</td>
<td><p><a class="reference external" href="https://github.com/opendilab/DI-engine/tree/main/dizoo/smac/config/smac_3s5z_wqmix_config.py">config_link_5</a></p></td>
<td><p><a class="reference external" href="https://github.com/oxwhirl/wqmix">wqmix(Tabish)</a>
(0.9)</p></td>
</tr>
</tbody>
</table>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Rashid, Tabish, et al. “Weighted qmix: Expanding monotonic value function factorisation for deep multi-agent reinforcement learning.” arXiv preprint arXiv:2006.10800 (2020).</p></li>
<li><p>Tabish Rashid, Mikayel Samvelyan, Christian Schroeder de Witt, Gregory Farquhar, Jakob Foerster, Shimon Whiteson. Qmix: Monotonic value function factorisation for deep multi-agent reinforcement learning. International Conference on Machine Learning. PMLR, 2018.</p></li>
<li><p>Peter Sunehag, Guy Lever, Audrunas Gruslys, Wojciech Marian Czarnecki, Vinicius Zambaldi, Max Jaderberg, Marc Lanctot, Nicolas Sonnerat, Joel Z. Leibo, Karl Tuyls, Thore Graepel. Value-decomposition networks for cooperative multi-agent learning. arXiv preprint arXiv:1706.05296, 2017.</p></li>
<li><p>Kyunghwan Son, Daewoo Kim, Wan Ju Kang, David Earl Hostallero, Yung Yi. QTRAN: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement Learning. International Conference on Machine Learning. PMLR, 2019.</p></li>
<li><p>Mikayel Samvelyan, Tabish Rashid, Christian Schroeder de Witt, Gregory Farquhar, Nantas Nardelli, Tim G. J. Rudner, Chia-Man Hung, Philip H. S. Torr, Jakob Foerster, Shimon Whiteson. The StarCraft Multi-Agent Challenge. arXiv preprint arXiv:1902.04043, 2019.</p></li>
</ul>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="collaq.html" class="btn btn-neutral float-right" title="CollaQ" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="coma.html" class="btn btn-neutral float-left" title="COMA" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, OpenDILab Contributors

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>