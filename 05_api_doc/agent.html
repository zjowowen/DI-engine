


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ding.agent &mdash; DI-engine 0.1.0 documentation</title>
  

  <link rel="shortcut icon" href="../_static/images/favicon.ico" />
  
  

  

  
  
  

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/style.css" type="text/css" />
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="next" title="ding.config" href="config.html" />
  <link rel="prev" title="API Doc" href="index.html" />
    <link href="../_static/css/style.css" rel="stylesheet" type="text/css">


  
  <script src="../_static/js/modernizr.min.js"></script>
  <script>
    MathJax = {
        chtml: {
            scale: 1,
            minScale: 1,
        },
        svg: {
            scale: 1,
            minScale: 1,
        }
    }
</script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/"
        aria-label="OpenMMLab"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/DI-engine" target="_blank">GitHub</a>
          </li>
          <li >
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a
                class="resource-option with-down-arrow">
                OpenDILab
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-engine" target="_blank">
                  <span class="dropdown-title">DI-engine </span>
                  <p>OpenDILab Decision AI Engine</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-star" target="_blank">
                  <span class="dropdown-title">DI-star </span>
                  <p>OpenDILab Decision AI in StarCraftII</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-drive" target="_blank">
                  <span class="dropdown-title">DI-drive </span>
                  <p>OpenDILab Auto-driving platform</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/GoBigger" target="_blank">
                  <span class="dropdown-title">GoBigger </span>
                  <p>OpenDILab Multi-Agent Environment</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-smartcross" target="_blank">
                  <span class="dropdown-title">DI-smartcross </span>
                  <p>Decision Intelligence Platform for Traffic Crossing Signal Control</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-treetensor" target="_blank">
                  <span class="dropdown-title">DI-treetensor </span>
                  <p>Tree Nested PyTorch Tensor Lib</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-sheep" target="_blank">
                  <span class="dropdown-title">DI-sheep </span>
                  <p>Deep Reinforcement Learning + 3 Tiles Game</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-model-based-RL" target="_blank">
                  <span class="dropdown-title">awesome-model-based-RL </span>
                  <p>A curated list of awesome model based RL resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-decision-transformer" target="_blank">
                  <span class="dropdown-title">awesome-decision-transformer </span>
                  <p>A curated list of Decision Transformer resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-exploration-rl" target="_blank">
                  <span class="dropdown-title">awesome-exploration-rl </span>
                  <p>A curated list of awesome exploration RL resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-multi-modal-reinforcement-learning" target="_blank">
                  <span class="dropdown-title">awesome-multi-modal-reinforcement-learning </span>
                  <p>A curated list of Multi-Modal Reinforcement Learning resources (continually updated)</p>
                </a>
              </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../00_intro/index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_quickstart/index.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_algo/index.html">RL Algorithm Taxonomy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03_system/index.html">System Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04_best_practice/index.html">Best Practice</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">API Doc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06_faq/index.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reinforcement Learning Tutorial</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../10_concepts/index.html">Introduction to RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11_dizoo/index.html">Learn From DI-zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../12_policies/index.html">RL Algorithms Cheat Sheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../13_envs/index.html">RL Env Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../20_spec/index.html">Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../21_code_style/index.html">Code Style Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../22_test/index.html">Unit Test Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../23_visual/index.html">Diagrams and Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../24_cooperation/index.html">Github Cooperation</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
            Docs
        </a> &gt;
      </li>

        
          <li><a href="index.html">API Doc</a> &gt;</li>
        
      <li>ding.agent</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/05_api_doc/agent.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
  <section id="ding-agent">
<h1>ding.agent<a class="headerlink" href="#ding-agent" title="Permalink to this headline">¶</a></h1>
<section id="a2c">
<h2>a2c<a class="headerlink" href="#a2c" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/bonus/a2c.py</span></code> for more details.</p>
<section id="a2cagent">
<h3>A2CAgent<a class="headerlink" href="#a2cagent" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.bonus.a2c.A2CAgent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.bonus.a2c.</span></span><span class="sig-name descname"><span class="pre">A2CAgent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/bonus/a2c.html#A2CAgent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.a2c.A2CAgent" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Class of agent for training, evaluation and deployment of Reinforcement learning algorithm         Advantage Actor Critic(A2C).
For more information about the system design of RL agent, please refer to         &lt;<a class="reference external" href="https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html">https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html</a>&gt;.</p>
</dd>
<dt>Interface:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">deploy</span></code>, <code class="docutils literal notranslate"><span class="pre">collect_data</span></code>, <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code>, <code class="docutils literal notranslate"><span class="pre">best</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.a2c.A2CAgent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/a2c.html#A2CAgent.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.a2c.A2CAgent.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize agent for A2C algorithm.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_id (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The environment id, which is a registered environment name in gym or gymnasium.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is not specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> must be specified.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> will be ignored.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> should be one of the supported envs, which can be found in <code class="docutils literal notranslate"><span class="pre">supported_env_list</span></code>.</p></li>
<li><p>env (<code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseEnv</span></code>): The environment instance for training and evaluation.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is not specified, <cite>env_id`</cite> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> must be specified.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be used to create environment instance.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> and <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be ignored.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The random seed, which is set before running the program.                 Default to 0.</p></li>
<li><p>exp_name (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The name of this experiment, which will be used to create the folder to save                 log data. Default to None. If not specified, the folder name will be <code class="docutils literal notranslate"><span class="pre">env_id</span></code>-<code class="docutils literal notranslate"><span class="pre">algorithm</span></code>.</p></li>
<li><p>model (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>): The model of A2C algorithm, which should be an instance of class                 <a class="reference internal" href="model.html#ding.model.VAC" title="ding.model.VAC"><code class="xref py py-class docutils literal notranslate"><span class="pre">ding.model.VAC</span></code></a>.                 If not specified, a default model will be generated according to the configuration.</p></li>
<li><p>cfg (:obj:Union[EasyDict, dict]): The configuration of A2C algorithm, which is a dict.                 Default to None. If not specified, the default configuration will be used.                 The default configuration can be found in <code class="docutils literal notranslate"><span class="pre">ding/config/example/A2C/gym_lunarlander_v2.py</span></code>.</p></li>
<li><p>policy_state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path of policy state dict saved by PyTorch a in local file.                 If specified, the policy will be loaded from this file. Default to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<dl>
<dt>An RL Agent Instance can be initialized in two basic ways.             For example, we have an environment with id <code class="docutils literal notranslate"><span class="pre">LunarLanderContinuous-v2</span></code> registered in gym,             and we want to train an agent with A2C algorithm with default configuration.             Then we can initialize the agent in the following ways:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">A2CAgent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want can specify the env_id in the configuration:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cfg</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;env&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;env_id&#39;</span><span class="p">:</span> <span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">},</span> <span class="s1">&#39;policy&#39;</span><span class="p">:</span> <span class="o">......</span> <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">A2CAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>There are also other arguments to specify the agent when initializing.
For example, if we want to specify the environment instance:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">CustomizedEnv</span><span class="p">(</span><span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">A2CAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>or, if we want to specify the model:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">VAC</span><span class="p">(</span><span class="o">**</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">A2CAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want to reload the policy from a saved policy state dict:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">A2CAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy_state_dict</span><span class="o">=</span><span class="s1">&#39;LunarLanderContinuous-v2.pth.tar&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>Make sure that the configuration is consistent with the saved policy state dict.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.a2c.A2CAgent.batch_evaluate">
<span class="sig-name descname"><span class="pre">batch_evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_evaluator_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/a2c.html#A2CAgent.batch_evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.a2c.A2CAgent.batch_evaluate" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate the agent with A2C algorithm for <code class="docutils literal notranslate"><span class="pre">n_evaluator_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> evaluator             environments. The evaluation result will be returned.
The difference between methods <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> and <code class="docutils literal notranslate"><span class="pre">deploy</span></code> is that <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> will create             multiple evaluator environments to evaluate the agent to get an average performance, while <code class="docutils literal notranslate"><span class="pre">deploy</span></code>             will only create one evaluator environment to evaluate the agent and save the replay video.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of evaluator environments. Default to 4.</p></li>
<li><p>n_evaluator_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to evaluate. Default to 4.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="ding.bonus.a2c.A2CAgent.best">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">best</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="#ding.bonus.a2c.A2CAgent" title="ding.bonus.a2c.A2CAgent"><span class="pre">ding.bonus.a2c.A2CAgent</span></a></em><a class="headerlink" href="#ding.bonus.a2c.A2CAgent.best" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Load the best model from the checkpoint directory,             which is by default in folder <code class="docutils literal notranslate"><span class="pre">exp_name/ckpt/eval.pth.tar</span></code>.             The return value is the agent with the best model.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(<a class="reference internal" href="#ding.bonus.a2c.A2CAgent" title="ding.bonus.a2c.A2CAgent"><code class="xref py py-obj docutils literal notranslate"><span class="pre">A2CAgent</span></code></a>): The agent with the best model.</p></li>
</ul>
</dd>
<dt>Examples:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">A2CAgent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">best</span>
</pre></div>
</div>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The best model is the model with the highest evaluation return. If this method is called, the current             model will be replaced by the best model.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.a2c.A2CAgent.collect_data">
<span class="sig-name descname"><span class="pre">collect_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_data_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_sample</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/a2c.html#A2CAgent.collect_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.a2c.A2CAgent.collect_data" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect data with A2C algorithm for <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> collector environments.             The collected data will be saved in <code class="docutils literal notranslate"><span class="pre">save_data_path</span></code> if specified, otherwise it will be saved in             <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of collector environments. Default to 8.</p></li>
<li><p>save_data_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the collected data. Default to None.                 If not specified, the data will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p></li>
<li><p>n_sample (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of samples to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> must be specified.</p></li>
<li><p>n_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_sample</span></code> must be specified.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.a2c.A2CAgent.deploy">
<span class="sig-name descname"><span class="pre">deploy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">enable_save_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concatenate_all_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_save_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/a2c.html#A2CAgent.deploy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.a2c.A2CAgent.deploy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Deploy the agent with A2C algorithm by interacting with the environment, during which the replay video             can be saved if <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True. The evaluation result will be returned.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>enable_save_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to save the replay video. Default to False.</p></li>
<li><p>concatenate_all_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to concatenate all replay videos into one video.                 Default to False. If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is False, this argument will be ignored.                 If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True and <code class="docutils literal notranslate"><span class="pre">concatenate_all_replay</span></code> is False,                 the replay video of each episode will be saved separately.</p></li>
<li><p>replay_save_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the replay video. Default to None.                 If not specified, the video will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/videos</span></code>.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[int,</span> <span class="pre">List]</span></code>): The random seed, which is set before running the program.                 Default to None. If not specified, <code class="docutils literal notranslate"><span class="pre">self.seed</span></code> will be used.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is an integer, the agent will be deployed once.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is a list of integers, the agent will be deployed once for each seed in the list.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.a2c.A2CAgent.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">10000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collector_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluator_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter_log_show</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter_save_ckpt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wandb_sweep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.TrainingReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/a2c.html#A2CAgent.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.a2c.A2CAgent.train" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Train the agent with A2C algorithm for <code class="docutils literal notranslate"><span class="pre">step</span></code> iterations with <code class="docutils literal notranslate"><span class="pre">collector_env_num</span></code> collector             environments and <code class="docutils literal notranslate"><span class="pre">evaluator_env_num</span></code> evaluator environments. Information during training will be             recorded and saved by wandb.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>step (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The total training environment steps of all collector environments. Default to 1e7.</p></li>
<li><p>collector_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The collector environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>evaluator_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The evaluator environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>n_iter_save_ckpt (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The frequency of saving checkpoint every training iteration.                 Default to 1000.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
<li><p>wandb_sweep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use wandb sweep,                 which is a hyper-parameter optimization process for seeking the best configurations.                 Default to False. If True, the wandb sweep id will be used as the experiment name.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">TrainingReturn</span></code>): The training result, of which the attributions are:</dt><dd><ul>
<li><p>wandb_url (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The weight &amp; biases (wandb) project url of the trainning experiment.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="c51">
<h2>c51<a class="headerlink" href="#c51" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/bonus/c51.py</span></code> for more details.</p>
<section id="c51agent">
<h3>C51Agent<a class="headerlink" href="#c51agent" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.bonus.c51.C51Agent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.bonus.c51.</span></span><span class="sig-name descname"><span class="pre">C51Agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/bonus/c51.html#C51Agent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.c51.C51Agent" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Class of agent for training, evaluation and deployment of Reinforcement learning algorithm C51.
For more information about the system design of RL agent, please refer to         &lt;<a class="reference external" href="https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html">https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html</a>&gt;.</p>
</dd>
<dt>Interface:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">deploy</span></code>, <code class="docutils literal notranslate"><span class="pre">collect_data</span></code>, <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code>, <code class="docutils literal notranslate"><span class="pre">best</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.c51.C51Agent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/c51.html#C51Agent.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.c51.C51Agent.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize agent for C51 algorithm.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_id (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The environment id, which is a registered environment name in gym or gymnasium.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is not specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> must be specified.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> will be ignored.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> should be one of the supported envs, which can be found in <code class="docutils literal notranslate"><span class="pre">supported_env_list</span></code>.</p></li>
<li><p>env (<code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseEnv</span></code>): The environment instance for training and evaluation.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is not specified, <cite>env_id`</cite> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> must be specified.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be used to create environment instance.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> and <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be ignored.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The random seed, which is set before running the program.                 Default to 0.</p></li>
<li><p>exp_name (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The name of this experiment, which will be used to create the folder to save                 log data. Default to None. If not specified, the folder name will be <code class="docutils literal notranslate"><span class="pre">env_id</span></code>-<code class="docutils literal notranslate"><span class="pre">algorithm</span></code>.</p></li>
<li><p>model (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>): The model of C51 algorithm, which should be an instance of class                 <a class="reference internal" href="model.html#ding.model.C51DQN" title="ding.model.C51DQN"><code class="xref py py-class docutils literal notranslate"><span class="pre">ding.model.C51DQN</span></code></a>.                 If not specified, a default model will be generated according to the configuration.</p></li>
<li><p>cfg (:obj:Union[EasyDict, dict]): The configuration of C51 algorithm, which is a dict.                 Default to None. If not specified, the default configuration will be used.                 The default configuration can be found in <code class="docutils literal notranslate"><span class="pre">ding/config/example/C51/gym_lunarlander_v2.py</span></code>.</p></li>
<li><p>policy_state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path of policy state dict saved by PyTorch a in local file.                 If specified, the policy will be loaded from this file. Default to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<dl>
<dt>An RL Agent Instance can be initialized in two basic ways.             For example, we have an environment with id <code class="docutils literal notranslate"><span class="pre">LunarLander-v2</span></code> registered in gym,             and we want to train an agent with C51 algorithm with default configuration.             Then we can initialize the agent in the following ways:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">C51Agent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want can specify the env_id in the configuration:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cfg</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;env&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;env_id&#39;</span><span class="p">:</span> <span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">},</span> <span class="s1">&#39;policy&#39;</span><span class="p">:</span> <span class="o">......</span> <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">C51Agent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>There are also other arguments to specify the agent when initializing.
For example, if we want to specify the environment instance:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">CustomizedEnv</span><span class="p">(</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">C51Agent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>or, if we want to specify the model:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">C51DQN</span><span class="p">(</span><span class="o">**</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">C51Agent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want to reload the policy from a saved policy state dict:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">C51Agent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy_state_dict</span><span class="o">=</span><span class="s1">&#39;LunarLander-v2.pth.tar&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>Make sure that the configuration is consistent with the saved policy state dict.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.c51.C51Agent.batch_evaluate">
<span class="sig-name descname"><span class="pre">batch_evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_evaluator_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/c51.html#C51Agent.batch_evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.c51.C51Agent.batch_evaluate" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate the agent with C51 algorithm for <code class="docutils literal notranslate"><span class="pre">n_evaluator_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> evaluator             environments. The evaluation result will be returned.
The difference between methods <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> and <code class="docutils literal notranslate"><span class="pre">deploy</span></code> is that <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> will create             multiple evaluator environments to evaluate the agent to get an average performance, while <code class="docutils literal notranslate"><span class="pre">deploy</span></code>             will only create one evaluator environment to evaluate the agent and save the replay video.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of evaluator environments. Default to 4.</p></li>
<li><p>n_evaluator_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to evaluate. Default to 4.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="ding.bonus.c51.C51Agent.best">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">best</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="#ding.bonus.c51.C51Agent" title="ding.bonus.c51.C51Agent"><span class="pre">ding.bonus.c51.C51Agent</span></a></em><a class="headerlink" href="#ding.bonus.c51.C51Agent.best" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Load the best model from the checkpoint directory,             which is by default in folder <code class="docutils literal notranslate"><span class="pre">exp_name/ckpt/eval.pth.tar</span></code>.             The return value is the agent with the best model.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(<a class="reference internal" href="#ding.bonus.c51.C51Agent" title="ding.bonus.c51.C51Agent"><code class="xref py py-obj docutils literal notranslate"><span class="pre">C51Agent</span></code></a>): The agent with the best model.</p></li>
</ul>
</dd>
<dt>Examples:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">C51Agent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">best</span>
</pre></div>
</div>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The best model is the model with the highest evaluation return. If this method is called, the current             model will be replaced by the best model.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.c51.C51Agent.collect_data">
<span class="sig-name descname"><span class="pre">collect_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_data_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_sample</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/c51.html#C51Agent.collect_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.c51.C51Agent.collect_data" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect data with C51 algorithm for <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> collector environments.             The collected data will be saved in <code class="docutils literal notranslate"><span class="pre">save_data_path</span></code> if specified, otherwise it will be saved in             <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of collector environments. Default to 8.</p></li>
<li><p>save_data_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the collected data. Default to None.                 If not specified, the data will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p></li>
<li><p>n_sample (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of samples to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> must be specified.</p></li>
<li><p>n_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_sample</span></code> must be specified.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.c51.C51Agent.deploy">
<span class="sig-name descname"><span class="pre">deploy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">enable_save_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concatenate_all_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_save_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/c51.html#C51Agent.deploy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.c51.C51Agent.deploy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Deploy the agent with C51 algorithm by interacting with the environment, during which the replay video             can be saved if <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True. The evaluation result will be returned.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>enable_save_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to save the replay video. Default to False.</p></li>
<li><p>concatenate_all_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to concatenate all replay videos into one video.                 Default to False. If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is False, this argument will be ignored.                 If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True and <code class="docutils literal notranslate"><span class="pre">concatenate_all_replay</span></code> is False,                 the replay video of each episode will be saved separately.</p></li>
<li><p>replay_save_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the replay video. Default to None.                 If not specified, the video will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/videos</span></code>.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[int,</span> <span class="pre">List]</span></code>): The random seed, which is set before running the program.                 Default to None. If not specified, <code class="docutils literal notranslate"><span class="pre">self.seed</span></code> will be used.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is an integer, the agent will be deployed once.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is a list of integers, the agent will be deployed once for each seed in the list.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.c51.C51Agent.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">10000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collector_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluator_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter_save_ckpt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wandb_sweep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.TrainingReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/c51.html#C51Agent.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.c51.C51Agent.train" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Train the agent with C51 algorithm for <code class="docutils literal notranslate"><span class="pre">step</span></code> iterations with <code class="docutils literal notranslate"><span class="pre">collector_env_num</span></code> collector             environments and <code class="docutils literal notranslate"><span class="pre">evaluator_env_num</span></code> evaluator environments. Information during training will be             recorded and saved by wandb.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>step (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The total training environment steps of all collector environments. Default to 1e7.</p></li>
<li><p>collector_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The collector environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>evaluator_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The evaluator environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>n_iter_save_ckpt (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The frequency of saving checkpoint every training iteration.                 Default to 1000.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
<li><p>wandb_sweep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use wandb sweep,                 which is a hyper-parameter optimization process for seeking the best configurations.                 Default to False. If True, the wandb sweep id will be used as the experiment name.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">TrainingReturn</span></code>): The training result, of which the attributions are:</dt><dd><ul>
<li><p>wandb_url (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The weight &amp; biases (wandb) project url of the trainning experiment.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="ddpg">
<h2>ddpg<a class="headerlink" href="#ddpg" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/bonus/ddpg.py</span></code> for more details.</p>
<section id="ddpgagent">
<h3>DDPGAgent<a class="headerlink" href="#ddpgagent" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.bonus.ddpg.DDPGAgent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.bonus.ddpg.</span></span><span class="sig-name descname"><span class="pre">DDPGAgent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/bonus/ddpg.html#DDPGAgent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ddpg.DDPGAgent" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Class of agent for training, evaluation and deployment of Reinforcement learning algorithm         Deep Deterministic Policy Gradient(DDPG).
For more information about the system design of RL agent, please refer to         &lt;<a class="reference external" href="https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html">https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html</a>&gt;.</p>
</dd>
<dt>Interface:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">deploy</span></code>, <code class="docutils literal notranslate"><span class="pre">collect_data</span></code>, <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code>, <code class="docutils literal notranslate"><span class="pre">best</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.ddpg.DDPGAgent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/ddpg.html#DDPGAgent.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ddpg.DDPGAgent.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize agent for DDPG algorithm.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_id (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The environment id, which is a registered environment name in gym or gymnasium.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is not specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> must be specified.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> will be ignored.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> should be one of the supported envs, which can be found in <code class="docutils literal notranslate"><span class="pre">supported_env_list</span></code>.</p></li>
<li><p>env (<code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseEnv</span></code>): The environment instance for training and evaluation.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is not specified, <cite>env_id`</cite> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> must be specified.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be used to create environment instance.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> and <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be ignored.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The random seed, which is set before running the program.                 Default to 0.</p></li>
<li><p>exp_name (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The name of this experiment, which will be used to create the folder to save                 log data. Default to None. If not specified, the folder name will be <code class="docutils literal notranslate"><span class="pre">env_id</span></code>-<code class="docutils literal notranslate"><span class="pre">algorithm</span></code>.</p></li>
<li><p>model (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>): The model of DDPG algorithm, which should be an instance of class                 <a class="reference internal" href="model.html#ding.model.ContinuousQAC" title="ding.model.ContinuousQAC"><code class="xref py py-class docutils literal notranslate"><span class="pre">ding.model.ContinuousQAC</span></code></a>.                 If not specified, a default model will be generated according to the configuration.</p></li>
<li><p>cfg (:obj:Union[EasyDict, dict]): The configuration of DDPG algorithm, which is a dict.                 Default to None. If not specified, the default configuration will be used.                 The default configuration can be found in <code class="docutils literal notranslate"><span class="pre">ding/config/example/DDPG/gym_lunarlander_v2.py</span></code>.</p></li>
<li><p>policy_state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path of policy state dict saved by PyTorch a in local file.                 If specified, the policy will be loaded from this file. Default to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<dl>
<dt>An RL Agent Instance can be initialized in two basic ways.             For example, we have an environment with id <code class="docutils literal notranslate"><span class="pre">LunarLanderContinuous-v2</span></code> registered in gym,             and we want to train an agent with DDPG algorithm with default configuration.             Then we can initialize the agent in the following ways:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">DDPGAgent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want can specify the env_id in the configuration:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cfg</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;env&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;env_id&#39;</span><span class="p">:</span> <span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">},</span> <span class="s1">&#39;policy&#39;</span><span class="p">:</span> <span class="o">......</span> <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">DDPGAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>There are also other arguments to specify the agent when initializing.
For example, if we want to specify the environment instance:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">CustomizedEnv</span><span class="p">(</span><span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">DDPGAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>or, if we want to specify the model:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ContinuousQAC</span><span class="p">(</span><span class="o">**</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">DDPGAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want to reload the policy from a saved policy state dict:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">DDPGAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy_state_dict</span><span class="o">=</span><span class="s1">&#39;LunarLanderContinuous-v2.pth.tar&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>Make sure that the configuration is consistent with the saved policy state dict.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.ddpg.DDPGAgent.batch_evaluate">
<span class="sig-name descname"><span class="pre">batch_evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_evaluator_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/ddpg.html#DDPGAgent.batch_evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ddpg.DDPGAgent.batch_evaluate" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate the agent with DDPG algorithm for <code class="docutils literal notranslate"><span class="pre">n_evaluator_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> evaluator             environments. The evaluation result will be returned.
The difference between methods <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> and <code class="docutils literal notranslate"><span class="pre">deploy</span></code> is that <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> will create             multiple evaluator environments to evaluate the agent to get an average performance, while <code class="docutils literal notranslate"><span class="pre">deploy</span></code>             will only create one evaluator environment to evaluate the agent and save the replay video.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of evaluator environments. Default to 4.</p></li>
<li><p>n_evaluator_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to evaluate. Default to 4.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="ding.bonus.ddpg.DDPGAgent.best">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">best</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="#ding.bonus.ddpg.DDPGAgent" title="ding.bonus.ddpg.DDPGAgent"><span class="pre">ding.bonus.ddpg.DDPGAgent</span></a></em><a class="headerlink" href="#ding.bonus.ddpg.DDPGAgent.best" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Load the best model from the checkpoint directory,             which is by default in folder <code class="docutils literal notranslate"><span class="pre">exp_name/ckpt/eval.pth.tar</span></code>.             The return value is the agent with the best model.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(<a class="reference internal" href="#ding.bonus.ddpg.DDPGAgent" title="ding.bonus.ddpg.DDPGAgent"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DDPGAgent</span></code></a>): The agent with the best model.</p></li>
</ul>
</dd>
<dt>Examples:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">DDPGAgent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">best</span>
</pre></div>
</div>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The best model is the model with the highest evaluation return. If this method is called, the current             model will be replaced by the best model.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.ddpg.DDPGAgent.collect_data">
<span class="sig-name descname"><span class="pre">collect_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_data_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_sample</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/ddpg.html#DDPGAgent.collect_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ddpg.DDPGAgent.collect_data" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect data with DDPG algorithm for <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> collector environments.             The collected data will be saved in <code class="docutils literal notranslate"><span class="pre">save_data_path</span></code> if specified, otherwise it will be saved in             <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of collector environments. Default to 8.</p></li>
<li><p>save_data_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the collected data. Default to None.                 If not specified, the data will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p></li>
<li><p>n_sample (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of samples to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> must be specified.</p></li>
<li><p>n_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_sample</span></code> must be specified.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.ddpg.DDPGAgent.deploy">
<span class="sig-name descname"><span class="pre">deploy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">enable_save_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concatenate_all_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_save_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/ddpg.html#DDPGAgent.deploy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ddpg.DDPGAgent.deploy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Deploy the agent with DDPG algorithm by interacting with the environment, during which the replay video             can be saved if <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True. The evaluation result will be returned.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>enable_save_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to save the replay video. Default to False.</p></li>
<li><p>concatenate_all_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to concatenate all replay videos into one video.                 Default to False. If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is False, this argument will be ignored.                 If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True and <code class="docutils literal notranslate"><span class="pre">concatenate_all_replay</span></code> is False,                 the replay video of each episode will be saved separately.</p></li>
<li><p>replay_save_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the replay video. Default to None.                 If not specified, the video will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/videos</span></code>.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[int,</span> <span class="pre">List]</span></code>): The random seed, which is set before running the program.                 Default to None. If not specified, <code class="docutils literal notranslate"><span class="pre">self.seed</span></code> will be used.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is an integer, the agent will be deployed once.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is a list of integers, the agent will be deployed once for each seed in the list.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.ddpg.DDPGAgent.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">10000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collector_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluator_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter_log_show</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter_save_ckpt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wandb_sweep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.TrainingReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/ddpg.html#DDPGAgent.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ddpg.DDPGAgent.train" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Train the agent with DDPG algorithm for <code class="docutils literal notranslate"><span class="pre">step</span></code> iterations with <code class="docutils literal notranslate"><span class="pre">collector_env_num</span></code> collector             environments and <code class="docutils literal notranslate"><span class="pre">evaluator_env_num</span></code> evaluator environments. Information during training will be             recorded and saved by wandb.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>step (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The total training environment steps of all collector environments. Default to 1e7.</p></li>
<li><p>collector_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The collector environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>evaluator_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The evaluator environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>n_iter_save_ckpt (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The frequency of saving checkpoint every training iteration.                 Default to 1000.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
<li><p>wandb_sweep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use wandb sweep,                 which is a hyper-parameter optimization process for seeking the best configurations.                 Default to False. If True, the wandb sweep id will be used as the experiment name.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">TrainingReturn</span></code>): The training result, of which the attributions are:</dt><dd><ul>
<li><p>wandb_url (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The weight &amp; biases (wandb) project url of the trainning experiment.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="dqn">
<h2>dqn<a class="headerlink" href="#dqn" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/bonus/dqn.py</span></code> for more details.</p>
<section id="dqnagent">
<h3>DQNAgent<a class="headerlink" href="#dqnagent" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.bonus.dqn.DQNAgent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.bonus.dqn.</span></span><span class="sig-name descname"><span class="pre">DQNAgent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/bonus/dqn.html#DQNAgent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.dqn.DQNAgent" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Class of agent for training, evaluation and deployment of Reinforcement learning algorithm Deep Q-Learning(DQN).
For more information about the system design of RL agent, please refer to         &lt;<a class="reference external" href="https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html">https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html</a>&gt;.</p>
</dd>
<dt>Interface:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">deploy</span></code>, <code class="docutils literal notranslate"><span class="pre">collect_data</span></code>, <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code>, <code class="docutils literal notranslate"><span class="pre">best</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.dqn.DQNAgent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/dqn.html#DQNAgent.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.dqn.DQNAgent.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize agent for DQN algorithm.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_id (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The environment id, which is a registered environment name in gym or gymnasium.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is not specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> must be specified.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> will be ignored.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> should be one of the supported envs, which can be found in <code class="docutils literal notranslate"><span class="pre">supported_env_list</span></code>.</p></li>
<li><p>env (<code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseEnv</span></code>): The environment instance for training and evaluation.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is not specified, <cite>env_id`</cite> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> must be specified.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be used to create environment instance.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> and <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be ignored.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The random seed, which is set before running the program.                 Default to 0.</p></li>
<li><p>exp_name (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The name of this experiment, which will be used to create the folder to save                 log data. Default to None. If not specified, the folder name will be <code class="docutils literal notranslate"><span class="pre">env_id</span></code>-<code class="docutils literal notranslate"><span class="pre">algorithm</span></code>.</p></li>
<li><p>model (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>): The model of DQN algorithm, which should be an instance of class                 <a class="reference internal" href="model.html#ding.model.DQN" title="ding.model.DQN"><code class="xref py py-class docutils literal notranslate"><span class="pre">ding.model.DQN</span></code></a>.                 If not specified, a default model will be generated according to the configuration.</p></li>
<li><p>cfg (:obj:Union[EasyDict, dict]): The configuration of DQN algorithm, which is a dict.                 Default to None. If not specified, the default configuration will be used.                 The default configuration can be found in <code class="docutils literal notranslate"><span class="pre">ding/config/example/DQN/gym_lunarlander_v2.py</span></code>.</p></li>
<li><p>policy_state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path of policy state dict saved by PyTorch a in local file.                 If specified, the policy will be loaded from this file. Default to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<dl>
<dt>An RL Agent Instance can be initialized in two basic ways.             For example, we have an environment with id <code class="docutils literal notranslate"><span class="pre">LunarLander-v2</span></code> registered in gym,             and we want to train an agent with DQN algorithm with default configuration.             Then we can initialize the agent in the following ways:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">DQNAgent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want can specify the env_id in the configuration:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cfg</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;env&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;env_id&#39;</span><span class="p">:</span> <span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">},</span> <span class="s1">&#39;policy&#39;</span><span class="p">:</span> <span class="o">......</span> <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">DQNAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>There are also other arguments to specify the agent when initializing.
For example, if we want to specify the environment instance:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">CustomizedEnv</span><span class="p">(</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">DQNAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>or, if we want to specify the model:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">DQN</span><span class="p">(</span><span class="o">**</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">DQNAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want to reload the policy from a saved policy state dict:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">DQNAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy_state_dict</span><span class="o">=</span><span class="s1">&#39;LunarLander-v2.pth.tar&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>Make sure that the configuration is consistent with the saved policy state dict.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.dqn.DQNAgent.batch_evaluate">
<span class="sig-name descname"><span class="pre">batch_evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_evaluator_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/dqn.html#DQNAgent.batch_evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.dqn.DQNAgent.batch_evaluate" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate the agent with DQN algorithm for <code class="docutils literal notranslate"><span class="pre">n_evaluator_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> evaluator             environments. The evaluation result will be returned.
The difference between methods <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> and <code class="docutils literal notranslate"><span class="pre">deploy</span></code> is that <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> will create             multiple evaluator environments to evaluate the agent to get an average performance, while <code class="docutils literal notranslate"><span class="pre">deploy</span></code>             will only create one evaluator environment to evaluate the agent and save the replay video.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of evaluator environments. Default to 4.</p></li>
<li><p>n_evaluator_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to evaluate. Default to 4.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="ding.bonus.dqn.DQNAgent.best">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">best</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="#ding.bonus.dqn.DQNAgent" title="ding.bonus.dqn.DQNAgent"><span class="pre">ding.bonus.dqn.DQNAgent</span></a></em><a class="headerlink" href="#ding.bonus.dqn.DQNAgent.best" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Load the best model from the checkpoint directory,             which is by default in folder <code class="docutils literal notranslate"><span class="pre">exp_name/ckpt/eval.pth.tar</span></code>.             The return value is the agent with the best model.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(<a class="reference internal" href="#ding.bonus.dqn.DQNAgent" title="ding.bonus.dqn.DQNAgent"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DQNAgent</span></code></a>): The agent with the best model.</p></li>
</ul>
</dd>
<dt>Examples:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">DQNAgent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">best</span>
</pre></div>
</div>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The best model is the model with the highest evaluation return. If this method is called, the current             model will be replaced by the best model.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.dqn.DQNAgent.collect_data">
<span class="sig-name descname"><span class="pre">collect_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_data_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_sample</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/dqn.html#DQNAgent.collect_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.dqn.DQNAgent.collect_data" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect data with DQN algorithm for <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> collector environments.             The collected data will be saved in <code class="docutils literal notranslate"><span class="pre">save_data_path</span></code> if specified, otherwise it will be saved in             <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of collector environments. Default to 8.</p></li>
<li><p>save_data_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the collected data. Default to None.                 If not specified, the data will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p></li>
<li><p>n_sample (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of samples to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> must be specified.</p></li>
<li><p>n_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_sample</span></code> must be specified.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.dqn.DQNAgent.deploy">
<span class="sig-name descname"><span class="pre">deploy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">enable_save_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concatenate_all_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_save_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/dqn.html#DQNAgent.deploy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.dqn.DQNAgent.deploy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Deploy the agent with DQN algorithm by interacting with the environment, during which the replay video             can be saved if <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True. The evaluation result will be returned.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>enable_save_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to save the replay video. Default to False.</p></li>
<li><p>concatenate_all_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to concatenate all replay videos into one video.                 Default to False. If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is False, this argument will be ignored.                 If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True and <code class="docutils literal notranslate"><span class="pre">concatenate_all_replay</span></code> is False,                 the replay video of each episode will be saved separately.</p></li>
<li><p>replay_save_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the replay video. Default to None.                 If not specified, the video will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/videos</span></code>.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[int,</span> <span class="pre">List]</span></code>): The random seed, which is set before running the program.                 Default to None. If not specified, <code class="docutils literal notranslate"><span class="pre">self.seed</span></code> will be used.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is an integer, the agent will be deployed once.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is a list of integers, the agent will be deployed once for each seed in the list.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.dqn.DQNAgent.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">10000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collector_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluator_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter_save_ckpt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wandb_sweep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.TrainingReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/dqn.html#DQNAgent.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.dqn.DQNAgent.train" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Train the agent with DQN algorithm for <code class="docutils literal notranslate"><span class="pre">step</span></code> iterations with <code class="docutils literal notranslate"><span class="pre">collector_env_num</span></code> collector             environments and <code class="docutils literal notranslate"><span class="pre">evaluator_env_num</span></code> evaluator environments. Information during training will be             recorded and saved by wandb.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>step (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The total training environment steps of all collector environments. Default to 1e7.</p></li>
<li><p>collector_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The collector environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>evaluator_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The evaluator environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>n_iter_save_ckpt (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The frequency of saving checkpoint every training iteration.                 Default to 1000.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
<li><p>wandb_sweep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use wandb sweep,                 which is a hyper-parameter optimization process for seeking the best configurations.                 Default to False. If True, the wandb sweep id will be used as the experiment name.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">TrainingReturn</span></code>): The training result, of which the attributions are:</dt><dd><ul>
<li><p>wandb_url (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The weight &amp; biases (wandb) project url of the trainning experiment.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="pg">
<h2>pg<a class="headerlink" href="#pg" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/bonus/pg.py</span></code> for more details.</p>
<section id="pgagent">
<h3>PGAgent<a class="headerlink" href="#pgagent" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.bonus.pg.PGAgent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.bonus.pg.</span></span><span class="sig-name descname"><span class="pre">PGAgent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/bonus/pg.html#PGAgent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.pg.PGAgent" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Class of agent for training, evaluation and deployment of Reinforcement learning algorithm Policy Gradient(PG).
For more information about the system design of RL agent, please refer to         &lt;<a class="reference external" href="https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html">https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html</a>&gt;.</p>
</dd>
<dt>Interface:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">deploy</span></code>, <code class="docutils literal notranslate"><span class="pre">collect_data</span></code>, <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code>, <code class="docutils literal notranslate"><span class="pre">best</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.pg.PGAgent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/pg.html#PGAgent.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.pg.PGAgent.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize agent for PG algorithm.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_id (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The environment id, which is a registered environment name in gym or gymnasium.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is not specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> must be specified.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> will be ignored.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> should be one of the supported envs, which can be found in <code class="docutils literal notranslate"><span class="pre">supported_env_list</span></code>.</p></li>
<li><p>env (<code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseEnv</span></code>): The environment instance for training and evaluation.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is not specified, <cite>env_id`</cite> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> must be specified.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be used to create environment instance.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> and <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be ignored.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The random seed, which is set before running the program.                 Default to 0.</p></li>
<li><p>exp_name (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The name of this experiment, which will be used to create the folder to save                 log data. Default to None. If not specified, the folder name will be <code class="docutils literal notranslate"><span class="pre">env_id</span></code>-<code class="docutils literal notranslate"><span class="pre">algorithm</span></code>.</p></li>
<li><p>model (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>): The model of PG algorithm, which should be an instance of class                 <a class="reference internal" href="model.html#ding.model.PG" title="ding.model.PG"><code class="xref py py-class docutils literal notranslate"><span class="pre">ding.model.PG</span></code></a>.                 If not specified, a default model will be generated according to the configuration.</p></li>
<li><p>cfg (:obj:Union[EasyDict, dict]): The configuration of PG algorithm, which is a dict.                 Default to None. If not specified, the default configuration will be used.                 The default configuration can be found in <code class="docutils literal notranslate"><span class="pre">ding/config/example/PG/gym_lunarlander_v2.py</span></code>.</p></li>
<li><p>policy_state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path of policy state dict saved by PyTorch a in local file.                 If specified, the policy will be loaded from this file. Default to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<dl>
<dt>An RL Agent Instance can be initialized in two basic ways.             For example, we have an environment with id <code class="docutils literal notranslate"><span class="pre">LunarLanderContinuous-v2</span></code> registered in gym,             and we want to train an agent with PG algorithm with default configuration.             Then we can initialize the agent in the following ways:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PGAgent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want can specify the env_id in the configuration:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cfg</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;env&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;env_id&#39;</span><span class="p">:</span> <span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">},</span> <span class="s1">&#39;policy&#39;</span><span class="p">:</span> <span class="o">......</span> <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PGAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>There are also other arguments to specify the agent when initializing.
For example, if we want to specify the environment instance:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">CustomizedEnv</span><span class="p">(</span><span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PGAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>or, if we want to specify the model:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">PG</span><span class="p">(</span><span class="o">**</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PGAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want to reload the policy from a saved policy state dict:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PGAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy_state_dict</span><span class="o">=</span><span class="s1">&#39;LunarLanderContinuous-v2.pth.tar&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>Make sure that the configuration is consistent with the saved policy state dict.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.pg.PGAgent.batch_evaluate">
<span class="sig-name descname"><span class="pre">batch_evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_evaluator_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/pg.html#PGAgent.batch_evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.pg.PGAgent.batch_evaluate" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate the agent with PG algorithm for <code class="docutils literal notranslate"><span class="pre">n_evaluator_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> evaluator             environments. The evaluation result will be returned.
The difference between methods <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> and <code class="docutils literal notranslate"><span class="pre">deploy</span></code> is that <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> will create             multiple evaluator environments to evaluate the agent to get an average performance, while <code class="docutils literal notranslate"><span class="pre">deploy</span></code>             will only create one evaluator environment to evaluate the agent and save the replay video.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of evaluator environments. Default to 4.</p></li>
<li><p>n_evaluator_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to evaluate. Default to 4.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="ding.bonus.pg.PGAgent.best">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">best</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="#ding.bonus.pg.PGAgent" title="ding.bonus.pg.PGAgent"><span class="pre">ding.bonus.pg.PGAgent</span></a></em><a class="headerlink" href="#ding.bonus.pg.PGAgent.best" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Load the best model from the checkpoint directory,             which is by default in folder <code class="docutils literal notranslate"><span class="pre">exp_name/ckpt/eval.pth.tar</span></code>.             The return value is the agent with the best model.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(<a class="reference internal" href="#ding.bonus.pg.PGAgent" title="ding.bonus.pg.PGAgent"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PGAgent</span></code></a>): The agent with the best model.</p></li>
</ul>
</dd>
<dt>Examples:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PGAgent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">best</span>
</pre></div>
</div>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The best model is the model with the highest evaluation return. If this method is called, the current             model will be replaced by the best model.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.pg.PGAgent.collect_data">
<span class="sig-name descname"><span class="pre">collect_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_data_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_sample</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/pg.html#PGAgent.collect_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.pg.PGAgent.collect_data" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect data with PG algorithm for <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> collector environments.             The collected data will be saved in <code class="docutils literal notranslate"><span class="pre">save_data_path</span></code> if specified, otherwise it will be saved in             <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of collector environments. Default to 8.</p></li>
<li><p>save_data_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the collected data. Default to None.                 If not specified, the data will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p></li>
<li><p>n_sample (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of samples to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> must be specified.</p></li>
<li><p>n_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_sample</span></code> must be specified.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.pg.PGAgent.deploy">
<span class="sig-name descname"><span class="pre">deploy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">enable_save_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concatenate_all_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_save_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/pg.html#PGAgent.deploy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.pg.PGAgent.deploy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Deploy the agent with PG algorithm by interacting with the environment, during which the replay video             can be saved if <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True. The evaluation result will be returned.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>enable_save_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to save the replay video. Default to False.</p></li>
<li><p>concatenate_all_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to concatenate all replay videos into one video.                 Default to False. If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is False, this argument will be ignored.                 If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True and <code class="docutils literal notranslate"><span class="pre">concatenate_all_replay</span></code> is False,                 the replay video of each episode will be saved separately.</p></li>
<li><p>replay_save_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the replay video. Default to None.                 If not specified, the video will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/videos</span></code>.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[int,</span> <span class="pre">List]</span></code>): The random seed, which is set before running the program.                 Default to None. If not specified, <code class="docutils literal notranslate"><span class="pre">self.seed</span></code> will be used.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is an integer, the agent will be deployed once.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is a list of integers, the agent will be deployed once for each seed in the list.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.pg.PGAgent.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">10000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collector_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluator_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter_save_ckpt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wandb_sweep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.TrainingReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/pg.html#PGAgent.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.pg.PGAgent.train" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Train the agent with PG algorithm for <code class="docutils literal notranslate"><span class="pre">step</span></code> iterations with <code class="docutils literal notranslate"><span class="pre">collector_env_num</span></code> collector             environments and <code class="docutils literal notranslate"><span class="pre">evaluator_env_num</span></code> evaluator environments. Information during training will be             recorded and saved by wandb.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>step (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The total training environment steps of all collector environments. Default to 1e7.</p></li>
<li><p>collector_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The collector environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>evaluator_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The evaluator environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>n_iter_save_ckpt (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The frequency of saving checkpoint every training iteration.                 Default to 1000.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
<li><p>wandb_sweep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use wandb sweep,                 which is a hyper-parameter optimization process for seeking the best configurations.                 Default to False. If True, the wandb sweep id will be used as the experiment name.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">TrainingReturn</span></code>): The training result, of which the attributions are:</dt><dd><ul>
<li><p>wandb_url (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The weight &amp; biases (wandb) project url of the trainning experiment.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="ppo-offpolicy">
<h2>ppo_offpolicy<a class="headerlink" href="#ppo-offpolicy" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/bonus/ppo_offpolicy.py</span></code> for more details.</p>
<section id="ppooffpolicyagent">
<h3>PPOOffPolicyAgent<a class="headerlink" href="#ppooffpolicyagent" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.bonus.ppo_offpolicy.PPOOffPolicyAgent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.bonus.ppo_offpolicy.</span></span><span class="sig-name descname"><span class="pre">PPOOffPolicyAgent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/bonus/ppo_offpolicy.html#PPOOffPolicyAgent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ppo_offpolicy.PPOOffPolicyAgent" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Class of agent for training, evaluation and deployment of Reinforcement learning algorithm         Proximal Policy Optimization(PPO) in an off-policy style.
For more information about the system design of RL agent, please refer to         &lt;<a class="reference external" href="https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html">https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html</a>&gt;.</p>
</dd>
<dt>Interface:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">deploy</span></code>, <code class="docutils literal notranslate"><span class="pre">collect_data</span></code>, <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code>, <code class="docutils literal notranslate"><span class="pre">best</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.ppo_offpolicy.PPOOffPolicyAgent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/ppo_offpolicy.html#PPOOffPolicyAgent.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ppo_offpolicy.PPOOffPolicyAgent.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize agent for PPO (offpolicy) algorithm.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_id (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The environment id, which is a registered environment name in gym or gymnasium.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is not specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> must be specified.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> will be ignored.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> should be one of the supported envs, which can be found in <code class="docutils literal notranslate"><span class="pre">supported_env_list</span></code>.</p></li>
<li><p>env (<code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseEnv</span></code>): The environment instance for training and evaluation.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is not specified, <cite>env_id`</cite> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> must be specified.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be used to create environment instance.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> and <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be ignored.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The random seed, which is set before running the program.                 Default to 0.</p></li>
<li><p>exp_name (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The name of this experiment, which will be used to create the folder to save                 log data. Default to None. If not specified, the folder name will be <code class="docutils literal notranslate"><span class="pre">env_id</span></code>-<code class="docutils literal notranslate"><span class="pre">algorithm</span></code>.</p></li>
<li><p>model (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>): The model of PPO (offpolicy) algorithm,                 which should be an instance of class <a class="reference internal" href="model.html#ding.model.VAC" title="ding.model.VAC"><code class="xref py py-class docutils literal notranslate"><span class="pre">ding.model.VAC</span></code></a>.                 If not specified, a default model will be generated according to the configuration.</p></li>
<li><p>cfg (:obj:Union[EasyDict, dict]): The configuration of PPO (offpolicy) algorithm, which is a dict.                 Default to None. If not specified, the default configuration will be used.                 The default configuration can be found in <code class="docutils literal notranslate"><span class="pre">ding/config/example/PPO</span> <span class="pre">(offpolicy)/gym_lunarlander_v2.py</span></code>.</p></li>
<li><p>policy_state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path of policy state dict saved by PyTorch a in local file.                 If specified, the policy will be loaded from this file. Default to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<dl>
<dt>An RL Agent Instance can be initialized in two basic ways.             For example, we have an environment with id <code class="docutils literal notranslate"><span class="pre">LunarLander-v2</span></code> registered in gym,             and we want to train an agent with PPO (offpolicy) algorithm with default configuration.             Then we can initialize the agent in the following ways:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PPOOffPolicyAgent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want can specify the env_id in the configuration:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cfg</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;env&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;env_id&#39;</span><span class="p">:</span> <span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">},</span> <span class="s1">&#39;policy&#39;</span><span class="p">:</span> <span class="o">......</span> <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PPOOffPolicyAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>There are also other arguments to specify the agent when initializing.
For example, if we want to specify the environment instance:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">CustomizedEnv</span><span class="p">(</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PPOOffPolicyAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>or, if we want to specify the model:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">VAC</span><span class="p">(</span><span class="o">**</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PPOOffPolicyAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want to reload the policy from a saved policy state dict:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PPOOffPolicyAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy_state_dict</span><span class="o">=</span><span class="s1">&#39;LunarLander-v2.pth.tar&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>Make sure that the configuration is consistent with the saved policy state dict.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.ppo_offpolicy.PPOOffPolicyAgent.batch_evaluate">
<span class="sig-name descname"><span class="pre">batch_evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_evaluator_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/ppo_offpolicy.html#PPOOffPolicyAgent.batch_evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ppo_offpolicy.PPOOffPolicyAgent.batch_evaluate" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate the agent with PPO (offpolicy) algorithm for <code class="docutils literal notranslate"><span class="pre">n_evaluator_episode</span></code> episodes             with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> evaluator environments. The evaluation result will be returned.
The difference between methods <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> and <code class="docutils literal notranslate"><span class="pre">deploy</span></code> is that <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> will create             multiple evaluator environments to evaluate the agent to get an average performance, while <code class="docutils literal notranslate"><span class="pre">deploy</span></code>             will only create one evaluator environment to evaluate the agent and save the replay video.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of evaluator environments. Default to 4.</p></li>
<li><p>n_evaluator_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to evaluate. Default to 4.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="ding.bonus.ppo_offpolicy.PPOOffPolicyAgent.best">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">best</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="#ding.bonus.ppo_offpolicy.PPOOffPolicyAgent" title="ding.bonus.ppo_offpolicy.PPOOffPolicyAgent"><span class="pre">ding.bonus.ppo_offpolicy.PPOOffPolicyAgent</span></a></em><a class="headerlink" href="#ding.bonus.ppo_offpolicy.PPOOffPolicyAgent.best" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Load the best model from the checkpoint directory,             which is by default in folder <code class="docutils literal notranslate"><span class="pre">exp_name/ckpt/eval.pth.tar</span></code>.             The return value is the agent with the best model.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(<a class="reference internal" href="#ding.bonus.ppo_offpolicy.PPOOffPolicyAgent" title="ding.bonus.ppo_offpolicy.PPOOffPolicyAgent"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PPOOffPolicyAgent</span></code></a>): The agent with the best model.</p></li>
</ul>
</dd>
<dt>Examples:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PPOOffPolicyAgent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span><span class="o">.</span><span class="n">best</span>
</pre></div>
</div>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The best model is the model with the highest evaluation return. If this method is called, the current             model will be replaced by the best model.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.ppo_offpolicy.PPOOffPolicyAgent.collect_data">
<span class="sig-name descname"><span class="pre">collect_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_data_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_sample</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/ppo_offpolicy.html#PPOOffPolicyAgent.collect_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ppo_offpolicy.PPOOffPolicyAgent.collect_data" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect data with PPO (offpolicy) algorithm for <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> episodes             with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> collector environments.             The collected data will be saved in <code class="docutils literal notranslate"><span class="pre">save_data_path</span></code> if specified, otherwise it will be saved in             <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of collector environments. Default to 8.</p></li>
<li><p>save_data_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the collected data. Default to None.                 If not specified, the data will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p></li>
<li><p>n_sample (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of samples to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> must be specified.</p></li>
<li><p>n_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_sample</span></code> must be specified.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.ppo_offpolicy.PPOOffPolicyAgent.deploy">
<span class="sig-name descname"><span class="pre">deploy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">enable_save_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concatenate_all_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_save_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/ppo_offpolicy.html#PPOOffPolicyAgent.deploy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ppo_offpolicy.PPOOffPolicyAgent.deploy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Deploy the agent with PPO (offpolicy) algorithm by interacting with the environment,             during which the replay video can be saved if <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True.             The evaluation result will be returned.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>enable_save_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to save the replay video. Default to False.</p></li>
<li><p>concatenate_all_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to concatenate all replay videos into one video.                 Default to False. If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is False, this argument will be ignored.                 If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True and <code class="docutils literal notranslate"><span class="pre">concatenate_all_replay</span></code> is False,                 the replay video of each episode will be saved separately.</p></li>
<li><p>replay_save_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the replay video. Default to None.                 If not specified, the video will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/videos</span></code>.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[int,</span> <span class="pre">List]</span></code>): The random seed, which is set before running the program.                 Default to None. If not specified, <code class="docutils literal notranslate"><span class="pre">self.seed</span></code> will be used.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is an integer, the agent will be deployed once.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is a list of integers, the agent will be deployed once for each seed in the list.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.ppo_offpolicy.PPOOffPolicyAgent.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">10000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collector_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluator_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter_save_ckpt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wandb_sweep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.TrainingReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/ppo_offpolicy.html#PPOOffPolicyAgent.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ppo_offpolicy.PPOOffPolicyAgent.train" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Train the agent with PPO (offpolicy) algorithm for <code class="docutils literal notranslate"><span class="pre">step</span></code> iterations with <code class="docutils literal notranslate"><span class="pre">collector_env_num</span></code>             collector environments and <code class="docutils literal notranslate"><span class="pre">evaluator_env_num</span></code> evaluator environments.             Information during training will be recorded and saved by wandb.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>step (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The total training environment steps of all collector environments. Default to 1e7.</p></li>
<li><p>collector_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The collector environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>evaluator_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The evaluator environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>n_iter_save_ckpt (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The frequency of saving checkpoint every training iteration.                 Default to 1000.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
<li><p>wandb_sweep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use wandb sweep,                 which is a hyper-parameter optimization process for seeking the best configurations.                 Default to False. If True, the wandb sweep id will be used as the experiment name.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">TrainingReturn</span></code>): The training result, of which the attributions are:</dt><dd><ul>
<li><p>wandb_url (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The weight &amp; biases (wandb) project url of the trainning experiment.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="ppof">
<h2>ppof<a class="headerlink" href="#ppof" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/bonus/ppof.py</span></code> for more details.</p>
<section id="id1">
<h3>PPOF<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.bonus.ppof.PPOF">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.bonus.ppof.</span></span><span class="sig-name descname"><span class="pre">PPOF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/bonus/ppof.html#PPOF"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ppof.PPOF" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Class of agent for training, evaluation and deployment of Reinforcement learning algorithm         Proximal Policy Optimization(PPO).
For more information about the system design of RL agent, please refer to         &lt;<a class="reference external" href="https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html">https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html</a>&gt;.</p>
</dd>
<dt>Interface:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">deploy</span></code>, <code class="docutils literal notranslate"><span class="pre">collect_data</span></code>, <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code>, <code class="docutils literal notranslate"><span class="pre">best</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.ppof.PPOF.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/ppof.html#PPOF.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ppof.PPOF.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize agent for PPO algorithm.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_id (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The environment id, which is a registered environment name in gym or gymnasium.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is not specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg</span></code> must be specified.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg</span></code> will be ignored.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> should be one of the supported envs, which can be found in <code class="docutils literal notranslate"><span class="pre">PPOF.supported_env_list</span></code>.</p></li>
<li><p>env (<code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseEnv</span></code>): The environment instance for training and evaluation.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is not specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> or <code class="docutils literal notranslate"><span class="pre">cfg.env_id</span></code> must be specified.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> or <code class="docutils literal notranslate"><span class="pre">cfg.env_id</span></code> will be used to create environment instance.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> and <code class="docutils literal notranslate"><span class="pre">cfg.env_id</span></code> will be ignored.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The random seed, which is set before running the program.                 Default to 0.</p></li>
<li><p>exp_name (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The name of this experiment, which will be used to create the folder to save                 log data. Default to None. If not specified, the folder name will be <code class="docutils literal notranslate"><span class="pre">env_id</span></code>-<code class="docutils literal notranslate"><span class="pre">algorithm</span></code>.</p></li>
<li><p>model (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>): The model of PPO algorithm, which should be an instance of class                 <code class="docutils literal notranslate"><span class="pre">ding.model.PPOFModel</span></code>.                 If not specified, a default model will be generated according to the configuration.</p></li>
<li><p>cfg (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[EasyDict,</span> <span class="pre">dict]</span></code>): The configuration of PPO algorithm, which is a dict.                 Default to None. If not specified, the default configuration will be used.</p></li>
<li><p>policy_state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path of policy state dict saved by PyTorch a in local file.                 If specified, the policy will be loaded from this file. Default to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<dl>
<dt>An RL Agent Instance can be initialized in two basic ways.             For example, we have an environment with id <code class="docutils literal notranslate"><span class="pre">LunarLander-v2</span></code> registered in gym,             and we want to train an agent with PPO algorithm with default configuration.             Then we can initialize the agent in the following ways:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PPOF</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want can specify the env_id in the configuration:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cfg</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;env&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;env_id&#39;</span><span class="p">:</span> <span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">},</span> <span class="s1">&#39;policy&#39;</span><span class="p">:</span> <span class="o">......</span> <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PPOF</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>There are also other arguments to specify the agent when initializing.
For example, if we want to specify the environment instance:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">CustomizedEnv</span><span class="p">(</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PPOF</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>or, if we want to specify the model:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">VAC</span><span class="p">(</span><span class="o">**</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PPOF</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want to reload the policy from a saved policy state dict:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PPOF</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy_state_dict</span><span class="o">=</span><span class="s1">&#39;LunarLander-v2.pth.tar&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>Make sure that the configuration is consistent with the saved policy state dict.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.ppof.PPOF.batch_evaluate">
<span class="sig-name descname"><span class="pre">batch_evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_evaluator_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/ppof.html#PPOF.batch_evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ppof.PPOF.batch_evaluate" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate the agent with PPO algorithm for <code class="docutils literal notranslate"><span class="pre">n_evaluator_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> evaluator             environments. The evaluation result will be returned.
The difference between methods <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> and <code class="docutils literal notranslate"><span class="pre">deploy</span></code> is that <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> will create             multiple evaluator environments to evaluate the agent to get an average performance, while <code class="docutils literal notranslate"><span class="pre">deploy</span></code>             will only create one evaluator environment to evaluate the agent and save the replay video.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of evaluator environments. Default to 4.</p></li>
<li><p>n_evaluator_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to evaluate. Default to 4.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="ding.bonus.ppof.PPOF.best">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">best</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="#ding.bonus.ppof.PPOF" title="ding.bonus.ppof.PPOF"><span class="pre">ding.bonus.ppof.PPOF</span></a></em><a class="headerlink" href="#ding.bonus.ppof.PPOF.best" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Load the best model from the checkpoint directory,             which is by default in folder <code class="docutils literal notranslate"><span class="pre">exp_name/ckpt/eval.pth.tar</span></code>.             The return value is the agent with the best model.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(<a class="reference internal" href="#ding.bonus.ppof.PPOF" title="ding.bonus.ppof.PPOF"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PPOF</span></code></a>): The agent with the best model.</p></li>
</ul>
</dd>
<dt>Examples:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">PPOF</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">best</span><span class="p">()</span>
</pre></div>
</div>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The best model is the model with the highest evaluation return. If this method is called, the current             model will be replaced by the best model.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.ppof.PPOF.collect_data">
<span class="sig-name descname"><span class="pre">collect_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_data_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_sample</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/ppof.html#PPOF.collect_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ppof.PPOF.collect_data" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect data with PPO algorithm for <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> collector environments.             The collected data will be saved in <code class="docutils literal notranslate"><span class="pre">save_data_path</span></code> if specified, otherwise it will be saved in             <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of collector environments. Default to 8.</p></li>
<li><p>save_data_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the collected data. Default to None.                 If not specified, the data will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p></li>
<li><p>n_sample (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of samples to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> must be specified.</p></li>
<li><p>n_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_sample</span></code> must be specified.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.ppof.PPOF.deploy">
<span class="sig-name descname"><span class="pre">deploy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">enable_save_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concatenate_all_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_save_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/ppof.html#PPOF.deploy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ppof.PPOF.deploy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Deploy the agent with PPO algorithm by interacting with the environment, during which the replay video             can be saved if <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True. The evaluation result will be returned.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>enable_save_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to save the replay video. Default to False.</p></li>
<li><p>concatenate_all_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to concatenate all replay videos into one video.                 Default to False. If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is False, this argument will be ignored.                 If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True and <code class="docutils literal notranslate"><span class="pre">concatenate_all_replay</span></code> is False,                 the replay video of each episode will be saved separately.</p></li>
<li><p>replay_save_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the replay video. Default to None.                 If not specified, the video will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/videos</span></code>.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[int,</span> <span class="pre">List]</span></code>): The random seed, which is set before running the program.                 Default to None. If not specified, <code class="docutils literal notranslate"><span class="pre">self.seed</span></code> will be used.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is an integer, the agent will be deployed once.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is a list of integers, the agent will be deployed once for each seed in the list.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.ppof.PPOF.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">10000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collector_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluator_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter_log_show</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter_save_ckpt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wandb_sweep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.TrainingReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/ppof.html#PPOF.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.ppof.PPOF.train" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Train the agent with PPO algorithm for <code class="docutils literal notranslate"><span class="pre">step</span></code> iterations with <code class="docutils literal notranslate"><span class="pre">collector_env_num</span></code> collector             environments and <code class="docutils literal notranslate"><span class="pre">evaluator_env_num</span></code> evaluator environments. Information during training will be             recorded and saved by wandb.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>step (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The total training environment steps of all collector environments. Default to 1e7.</p></li>
<li><p>collector_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of collector environments. Default to 4.</p></li>
<li><p>evaluator_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of evaluator environments. Default to 4.</p></li>
<li><p>n_iter_log_show (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The frequency of logging every training iteration. Default to 500.</p></li>
<li><p>n_iter_save_ckpt (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The frequency of saving checkpoint every training iteration.                 Default to 1000.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>reward_model (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The reward model name. Default to None. This argument is not supported yet.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
<li><p>wandb_sweep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use wandb sweep,                 which is a hyper-parameter optimization process for seeking the best configurations.                 Default to False. If True, the wandb sweep id will be used as the experiment name.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">TrainingReturn</span></code>): The training result, of which the attributions are:</dt><dd><ul>
<li><p>wandb_url (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The weight &amp; biases (wandb) project url of the trainning experiment.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="sac">
<h2>sac<a class="headerlink" href="#sac" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/bonus/sac.py</span></code> for more details.</p>
<section id="sacagent">
<h3>SACAgent<a class="headerlink" href="#sacagent" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.bonus.sac.SACAgent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.bonus.sac.</span></span><span class="sig-name descname"><span class="pre">SACAgent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/bonus/sac.html#SACAgent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.sac.SACAgent" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Class of agent for training, evaluation and deployment of Reinforcement learning algorithm         Soft Actor-Critic(SAC).
For more information about the system design of RL agent, please refer to         &lt;<a class="reference external" href="https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html">https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html</a>&gt;.</p>
</dd>
<dt>Interface:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">deploy</span></code>, <code class="docutils literal notranslate"><span class="pre">collect_data</span></code>, <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code>, <code class="docutils literal notranslate"><span class="pre">best</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.sac.SACAgent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/sac.html#SACAgent.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.sac.SACAgent.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize agent for SAC algorithm.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_id (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The environment id, which is a registered environment name in gym or gymnasium.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is not specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> must be specified.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> will be ignored.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> should be one of the supported envs, which can be found in <code class="docutils literal notranslate"><span class="pre">supported_env_list</span></code>.</p></li>
<li><p>env (<code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseEnv</span></code>): The environment instance for training and evaluation.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is not specified, <cite>env_id`</cite> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> must be specified.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be used to create environment instance.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> and <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be ignored.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The random seed, which is set before running the program.                 Default to 0.</p></li>
<li><p>exp_name (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The name of this experiment, which will be used to create the folder to save                 log data. Default to None. If not specified, the folder name will be <code class="docutils literal notranslate"><span class="pre">env_id</span></code>-<code class="docutils literal notranslate"><span class="pre">algorithm</span></code>.</p></li>
<li><p>model (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>): The model of SAC algorithm, which should be an instance of class                 <a class="reference internal" href="model.html#ding.model.ContinuousQAC" title="ding.model.ContinuousQAC"><code class="xref py py-class docutils literal notranslate"><span class="pre">ding.model.ContinuousQAC</span></code></a>.                 If not specified, a default model will be generated according to the configuration.</p></li>
<li><p>cfg (:obj:Union[EasyDict, dict]): The configuration of SAC algorithm, which is a dict.                 Default to None. If not specified, the default configuration will be used.                 The default configuration can be found in <code class="docutils literal notranslate"><span class="pre">ding/config/example/SAC/gym_lunarlander_v2.py</span></code>.</p></li>
<li><p>policy_state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path of policy state dict saved by PyTorch a in local file.                 If specified, the policy will be loaded from this file. Default to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<dl>
<dt>An RL Agent Instance can be initialized in two basic ways.             For example, we have an environment with id <code class="docutils literal notranslate"><span class="pre">LunarLanderContinuous-v2</span></code> registered in gym,             and we want to train an agent with SAC algorithm with default configuration.             Then we can initialize the agent in the following ways:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">SACAgent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want can specify the env_id in the configuration:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cfg</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;env&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;env_id&#39;</span><span class="p">:</span> <span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">},</span> <span class="s1">&#39;policy&#39;</span><span class="p">:</span> <span class="o">......</span> <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">SACAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>There are also other arguments to specify the agent when initializing.
For example, if we want to specify the environment instance:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">CustomizedEnv</span><span class="p">(</span><span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">SACAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>or, if we want to specify the model:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ContinuousQAC</span><span class="p">(</span><span class="o">**</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">SACAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want to reload the policy from a saved policy state dict:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">SACAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy_state_dict</span><span class="o">=</span><span class="s1">&#39;LunarLanderContinuous-v2.pth.tar&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>Make sure that the configuration is consistent with the saved policy state dict.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.sac.SACAgent.batch_evaluate">
<span class="sig-name descname"><span class="pre">batch_evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_evaluator_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/sac.html#SACAgent.batch_evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.sac.SACAgent.batch_evaluate" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate the agent with SAC algorithm for <code class="docutils literal notranslate"><span class="pre">n_evaluator_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> evaluator             environments. The evaluation result will be returned.
The difference between methods <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> and <code class="docutils literal notranslate"><span class="pre">deploy</span></code> is that <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> will create             multiple evaluator environments to evaluate the agent to get an average performance, while <code class="docutils literal notranslate"><span class="pre">deploy</span></code>             will only create one evaluator environment to evaluate the agent and save the replay video.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of evaluator environments. Default to 4.</p></li>
<li><p>n_evaluator_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to evaluate. Default to 4.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="ding.bonus.sac.SACAgent.best">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">best</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="#ding.bonus.sac.SACAgent" title="ding.bonus.sac.SACAgent"><span class="pre">ding.bonus.sac.SACAgent</span></a></em><a class="headerlink" href="#ding.bonus.sac.SACAgent.best" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Load the best model from the checkpoint directory,             which is by default in folder <code class="docutils literal notranslate"><span class="pre">exp_name/ckpt/eval.pth.tar</span></code>.             The return value is the agent with the best model.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(<a class="reference internal" href="#ding.bonus.sac.SACAgent" title="ding.bonus.sac.SACAgent"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SACAgent</span></code></a>): The agent with the best model.</p></li>
</ul>
</dd>
<dt>Examples:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">SACAgent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">best</span>
</pre></div>
</div>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The best model is the model with the highest evaluation return. If this method is called, the current             model will be replaced by the best model.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.sac.SACAgent.collect_data">
<span class="sig-name descname"><span class="pre">collect_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_data_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_sample</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/sac.html#SACAgent.collect_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.sac.SACAgent.collect_data" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect data with SAC algorithm for <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> collector environments.             The collected data will be saved in <code class="docutils literal notranslate"><span class="pre">save_data_path</span></code> if specified, otherwise it will be saved in             <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of collector environments. Default to 8.</p></li>
<li><p>save_data_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the collected data. Default to None.                 If not specified, the data will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p></li>
<li><p>n_sample (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of samples to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> must be specified.</p></li>
<li><p>n_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_sample</span></code> must be specified.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.sac.SACAgent.deploy">
<span class="sig-name descname"><span class="pre">deploy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">enable_save_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concatenate_all_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_save_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/sac.html#SACAgent.deploy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.sac.SACAgent.deploy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Deploy the agent with SAC algorithm by interacting with the environment, during which the replay video             can be saved if <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True. The evaluation result will be returned.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>enable_save_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to save the replay video. Default to False.</p></li>
<li><p>concatenate_all_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to concatenate all replay videos into one video.                 Default to False. If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is False, this argument will be ignored.                 If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True and <code class="docutils literal notranslate"><span class="pre">concatenate_all_replay</span></code> is False,                 the replay video of each episode will be saved separately.</p></li>
<li><p>replay_save_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the replay video. Default to None.                 If not specified, the video will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/videos</span></code>.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[int,</span> <span class="pre">List]</span></code>): The random seed, which is set before running the program.                 Default to None. If not specified, <code class="docutils literal notranslate"><span class="pre">self.seed</span></code> will be used.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is an integer, the agent will be deployed once.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is a list of integers, the agent will be deployed once for each seed in the list.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.sac.SACAgent.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">10000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collector_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluator_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter_save_ckpt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wandb_sweep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.TrainingReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/sac.html#SACAgent.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.sac.SACAgent.train" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Train the agent with SAC algorithm for <code class="docutils literal notranslate"><span class="pre">step</span></code> iterations with <code class="docutils literal notranslate"><span class="pre">collector_env_num</span></code> collector             environments and <code class="docutils literal notranslate"><span class="pre">evaluator_env_num</span></code> evaluator environments. Information during training will be             recorded and saved by wandb.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>step (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The total training environment steps of all collector environments. Default to 1e7.</p></li>
<li><p>collector_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The collector environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>evaluator_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The evaluator environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>n_iter_save_ckpt (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The frequency of saving checkpoint every training iteration.                 Default to 1000.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
<li><p>wandb_sweep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use wandb sweep,                 which is a hyper-parameter optimization process for seeking the best configurations.                 Default to False. If True, the wandb sweep id will be used as the experiment name.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">TrainingReturn</span></code>): The training result, of which the attributions are:</dt><dd><ul>
<li><p>wandb_url (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The weight &amp; biases (wandb) project url of the trainning experiment.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="sql">
<h2>sql<a class="headerlink" href="#sql" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/bonus/sql.py</span></code> for more details.</p>
<section id="sqlagent">
<h3>SQLAgent<a class="headerlink" href="#sqlagent" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.bonus.sql.SQLAgent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.bonus.sql.</span></span><span class="sig-name descname"><span class="pre">SQLAgent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/bonus/sql.html#SQLAgent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.sql.SQLAgent" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Class of agent for training, evaluation and deployment of Reinforcement learning algorithm         Soft Q-Learning(SQL).
For more information about the system design of RL agent, please refer to         &lt;<a class="reference external" href="https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html">https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html</a>&gt;.</p>
</dd>
<dt>Interface:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">deploy</span></code>, <code class="docutils literal notranslate"><span class="pre">collect_data</span></code>, <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code>, <code class="docutils literal notranslate"><span class="pre">best</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.sql.SQLAgent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/sql.html#SQLAgent.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.sql.SQLAgent.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize agent for SQL algorithm.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_id (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The environment id, which is a registered environment name in gym or gymnasium.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is not specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> must be specified.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> will be ignored.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> should be one of the supported envs, which can be found in <code class="docutils literal notranslate"><span class="pre">supported_env_list</span></code>.</p></li>
<li><p>env (<code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseEnv</span></code>): The environment instance for training and evaluation.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is not specified, <cite>env_id`</cite> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> must be specified.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be used to create environment instance.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> and <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be ignored.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The random seed, which is set before running the program.                 Default to 0.</p></li>
<li><p>exp_name (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The name of this experiment, which will be used to create the folder to save                 log data. Default to None. If not specified, the folder name will be <code class="docutils literal notranslate"><span class="pre">env_id</span></code>-<code class="docutils literal notranslate"><span class="pre">algorithm</span></code>.</p></li>
<li><p>model (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>): The model of SQL algorithm, which should be an instance of class                 <a class="reference internal" href="model.html#ding.model.DQN" title="ding.model.DQN"><code class="xref py py-class docutils literal notranslate"><span class="pre">ding.model.DQN</span></code></a>.                 If not specified, a default model will be generated according to the configuration.</p></li>
<li><p>cfg (:obj:Union[EasyDict, dict]): The configuration of SQL algorithm, which is a dict.                 Default to None. If not specified, the default configuration will be used.                 The default configuration can be found in <code class="docutils literal notranslate"><span class="pre">ding/config/example/SQL/gym_lunarlander_v2.py</span></code>.</p></li>
<li><p>policy_state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path of policy state dict saved by PyTorch a in local file.                 If specified, the policy will be loaded from this file. Default to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<dl>
<dt>An RL Agent Instance can be initialized in two basic ways.             For example, we have an environment with id <code class="docutils literal notranslate"><span class="pre">LunarLander-v2</span></code> registered in gym,             and we want to train an agent with SQL algorithm with default configuration.             Then we can initialize the agent in the following ways:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">SQLAgent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want can specify the env_id in the configuration:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cfg</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;env&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;env_id&#39;</span><span class="p">:</span> <span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">},</span> <span class="s1">&#39;policy&#39;</span><span class="p">:</span> <span class="o">......</span> <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">SQLAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>There are also other arguments to specify the agent when initializing.
For example, if we want to specify the environment instance:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">CustomizedEnv</span><span class="p">(</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">SQLAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>or, if we want to specify the model:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">DQN</span><span class="p">(</span><span class="o">**</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">SQLAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want to reload the policy from a saved policy state dict:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">SQLAgent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy_state_dict</span><span class="o">=</span><span class="s1">&#39;LunarLander-v2.pth.tar&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>Make sure that the configuration is consistent with the saved policy state dict.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.sql.SQLAgent.batch_evaluate">
<span class="sig-name descname"><span class="pre">batch_evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_evaluator_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/sql.html#SQLAgent.batch_evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.sql.SQLAgent.batch_evaluate" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate the agent with SQL algorithm for <code class="docutils literal notranslate"><span class="pre">n_evaluator_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> evaluator             environments. The evaluation result will be returned.
The difference between methods <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> and <code class="docutils literal notranslate"><span class="pre">deploy</span></code> is that <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> will create             multiple evaluator environments to evaluate the agent to get an average performance, while <code class="docutils literal notranslate"><span class="pre">deploy</span></code>             will only create one evaluator environment to evaluate the agent and save the replay video.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of evaluator environments. Default to 4.</p></li>
<li><p>n_evaluator_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to evaluate. Default to 4.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="ding.bonus.sql.SQLAgent.best">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">best</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="#ding.bonus.sql.SQLAgent" title="ding.bonus.sql.SQLAgent"><span class="pre">ding.bonus.sql.SQLAgent</span></a></em><a class="headerlink" href="#ding.bonus.sql.SQLAgent.best" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Load the best model from the checkpoint directory,             which is by default in folder <code class="docutils literal notranslate"><span class="pre">exp_name/ckpt/eval.pth.tar</span></code>.             The return value is the agent with the best model.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(<a class="reference internal" href="#ding.bonus.sql.SQLAgent" title="ding.bonus.sql.SQLAgent"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SQLAgent</span></code></a>): The agent with the best model.</p></li>
</ul>
</dd>
<dt>Examples:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">SQLAgent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">best</span>
</pre></div>
</div>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The best model is the model with the highest evaluation return. If this method is called, the current             model will be replaced by the best model.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.sql.SQLAgent.collect_data">
<span class="sig-name descname"><span class="pre">collect_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_data_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_sample</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/sql.html#SQLAgent.collect_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.sql.SQLAgent.collect_data" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect data with SQL algorithm for <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> collector environments.             The collected data will be saved in <code class="docutils literal notranslate"><span class="pre">save_data_path</span></code> if specified, otherwise it will be saved in             <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of collector environments. Default to 8.</p></li>
<li><p>save_data_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the collected data. Default to None.                 If not specified, the data will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p></li>
<li><p>n_sample (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of samples to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> must be specified.</p></li>
<li><p>n_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_sample</span></code> must be specified.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.sql.SQLAgent.deploy">
<span class="sig-name descname"><span class="pre">deploy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">enable_save_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concatenate_all_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_save_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/sql.html#SQLAgent.deploy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.sql.SQLAgent.deploy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Deploy the agent with SQL algorithm by interacting with the environment, during which the replay video             can be saved if <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True. The evaluation result will be returned.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>enable_save_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to save the replay video. Default to False.</p></li>
<li><p>concatenate_all_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to concatenate all replay videos into one video.                 Default to False. If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is False, this argument will be ignored.                 If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True and <code class="docutils literal notranslate"><span class="pre">concatenate_all_replay</span></code> is False,                 the replay video of each episode will be saved separately.</p></li>
<li><p>replay_save_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the replay video. Default to None.                 If not specified, the video will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/videos</span></code>.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[int,</span> <span class="pre">List]</span></code>): The random seed, which is set before running the program.                 Default to None. If not specified, <code class="docutils literal notranslate"><span class="pre">self.seed</span></code> will be used.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is an integer, the agent will be deployed once.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is a list of integers, the agent will be deployed once for each seed in the list.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.sql.SQLAgent.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">10000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collector_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluator_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter_save_ckpt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wandb_sweep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.TrainingReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/sql.html#SQLAgent.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.sql.SQLAgent.train" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Train the agent with SQL algorithm for <code class="docutils literal notranslate"><span class="pre">step</span></code> iterations with <code class="docutils literal notranslate"><span class="pre">collector_env_num</span></code> collector             environments and <code class="docutils literal notranslate"><span class="pre">evaluator_env_num</span></code> evaluator environments. Information during training will be             recorded and saved by wandb.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>step (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The total training environment steps of all collector environments. Default to 1e7.</p></li>
<li><p>collector_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The collector environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>evaluator_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The evaluator environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>n_iter_save_ckpt (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The frequency of saving checkpoint every training iteration.                 Default to 1000.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
<li><p>wandb_sweep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use wandb sweep,                 which is a hyper-parameter optimization process for seeking the best configurations.                 Default to False. If True, the wandb sweep id will be used as the experiment name.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">TrainingReturn</span></code>): The training result, of which the attributions are:</dt><dd><ul>
<li><p>wandb_url (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The weight &amp; biases (wandb) project url of the trainning experiment.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="td3">
<h2>td3<a class="headerlink" href="#td3" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/bonus/td3.py</span></code> for more details.</p>
<section id="td3agent">
<h3>TD3Agent<a class="headerlink" href="#td3agent" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.bonus.td3.TD3Agent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.bonus.td3.</span></span><span class="sig-name descname"><span class="pre">TD3Agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/bonus/td3.html#TD3Agent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.td3.TD3Agent" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Class of agent for training, evaluation and deployment of Reinforcement learning algorithm         Twin Delayed Deep Deterministic Policy Gradient(TD3).
For more information about the system design of RL agent, please refer to         &lt;<a class="reference external" href="https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html">https://di-engine-docs.readthedocs.io/en/latest/03_system/agent.html</a>&gt;.</p>
</dd>
<dt>Interface:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">deploy</span></code>, <code class="docutils literal notranslate"><span class="pre">collect_data</span></code>, <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code>, <code class="docutils literal notranslate"><span class="pre">best</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.td3.TD3Agent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="env.html#ding.envs.BaseEnv" title="ding.envs.env.base_env.BaseEnv"><span class="pre">ding.envs.env.base_env.BaseEnv</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">easydict.EasyDict</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/td3.html#TD3Agent.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.td3.TD3Agent.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize agent for TD3 algorithm.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_id (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The environment id, which is a registered environment name in gym or gymnasium.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is not specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> must be specified.                 If <code class="docutils literal notranslate"><span class="pre">env_id</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> in <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> will be ignored.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> should be one of the supported envs, which can be found in <code class="docutils literal notranslate"><span class="pre">supported_env_list</span></code>.</p></li>
<li><p>env (<code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseEnv</span></code>): The environment instance for training and evaluation.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is not specified, <cite>env_id`</cite> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> must be specified.                 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> or <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be used to create environment instance.                 If <code class="docutils literal notranslate"><span class="pre">env</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">env_id</span></code> and <code class="docutils literal notranslate"><span class="pre">cfg.env.env_id</span></code> will be ignored.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The random seed, which is set before running the program.                 Default to 0.</p></li>
<li><p>exp_name (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The name of this experiment, which will be used to create the folder to save                 log data. Default to None. If not specified, the folder name will be <code class="docutils literal notranslate"><span class="pre">env_id</span></code>-<code class="docutils literal notranslate"><span class="pre">algorithm</span></code>.</p></li>
<li><p>model (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>): The model of TD3 algorithm, which should be an instance of class                 <a class="reference internal" href="model.html#ding.model.ContinuousQAC" title="ding.model.ContinuousQAC"><code class="xref py py-class docutils literal notranslate"><span class="pre">ding.model.ContinuousQAC</span></code></a>.                 If not specified, a default model will be generated according to the configuration.</p></li>
<li><p>cfg (:obj:Union[EasyDict, dict]): The configuration of TD3 algorithm, which is a dict.                 Default to None. If not specified, the default configuration will be used.                 The default configuration can be found in <code class="docutils literal notranslate"><span class="pre">ding/config/example/TD3/gym_lunarlander_v2.py</span></code>.</p></li>
<li><p>policy_state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path of policy state dict saved by PyTorch a in local file.                 If specified, the policy will be loaded from this file. Default to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<dl>
<dt>An RL Agent Instance can be initialized in two basic ways.             For example, we have an environment with id <code class="docutils literal notranslate"><span class="pre">LunarLanderContinuous-v2</span></code> registered in gym,             and we want to train an agent with TD3 algorithm with default configuration.             Then we can initialize the agent in the following ways:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">TD3Agent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want can specify the env_id in the configuration:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cfg</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;env&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;env_id&#39;</span><span class="p">:</span> <span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">},</span> <span class="s1">&#39;policy&#39;</span><span class="p">:</span> <span class="o">......</span> <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">TD3Agent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>There are also other arguments to specify the agent when initializing.
For example, if we want to specify the environment instance:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">env</span> <span class="o">=</span> <span class="n">CustomizedEnv</span><span class="p">(</span><span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">TD3Agent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>or, if we want to specify the model:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ContinuousQAC</span><span class="p">(</span><span class="o">**</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">TD3Agent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>or, if we want to reload the policy from a saved policy state dict:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">TD3Agent</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span> <span class="n">policy_state_dict</span><span class="o">=</span><span class="s1">&#39;LunarLanderContinuous-v2.pth.tar&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>Make sure that the configuration is consistent with the saved policy state dict.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.td3.TD3Agent.batch_evaluate">
<span class="sig-name descname"><span class="pre">batch_evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_evaluator_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/td3.html#TD3Agent.batch_evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.td3.TD3Agent.batch_evaluate" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate the agent with TD3 algorithm for <code class="docutils literal notranslate"><span class="pre">n_evaluator_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> evaluator             environments. The evaluation result will be returned.
The difference between methods <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> and <code class="docutils literal notranslate"><span class="pre">deploy</span></code> is that <code class="docutils literal notranslate"><span class="pre">batch_evaluate</span></code> will create             multiple evaluator environments to evaluate the agent to get an average performance, while <code class="docutils literal notranslate"><span class="pre">deploy</span></code>             will only create one evaluator environment to evaluate the agent and save the replay video.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of evaluator environments. Default to 4.</p></li>
<li><p>n_evaluator_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to evaluate. Default to 4.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="ding.bonus.td3.TD3Agent.best">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">best</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="#ding.bonus.td3.TD3Agent" title="ding.bonus.td3.TD3Agent"><span class="pre">ding.bonus.td3.TD3Agent</span></a></em><a class="headerlink" href="#ding.bonus.td3.TD3Agent.best" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Load the best model from the checkpoint directory,             which is by default in folder <code class="docutils literal notranslate"><span class="pre">exp_name/ckpt/eval.pth.tar</span></code>.             The return value is the agent with the best model.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(<a class="reference internal" href="#ding.bonus.td3.TD3Agent" title="ding.bonus.td3.TD3Agent"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TD3Agent</span></code></a>): The agent with the best model.</p></li>
</ul>
</dd>
<dt>Examples:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">TD3Agent</span><span class="p">(</span><span class="n">env_id</span><span class="o">=</span><span class="s1">&#39;LunarLanderContinuous-v2&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span><span class="o">.</span><span class="n">best</span>
</pre></div>
</div>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The best model is the model with the highest evaluation return. If this method is called, the current             model will be replaced by the best model.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.td3.TD3Agent.collect_data">
<span class="sig-name descname"><span class="pre">collect_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_data_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_sample</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_episode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/bonus/td3.html#TD3Agent.collect_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.td3.TD3Agent.collect_data" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect data with TD3 algorithm for <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> episodes with <code class="docutils literal notranslate"><span class="pre">env_num</span></code> collector environments.             The collected data will be saved in <code class="docutils literal notranslate"><span class="pre">save_data_path</span></code> if specified, otherwise it will be saved in             <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of collector environments. Default to 8.</p></li>
<li><p>save_data_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the collected data. Default to None.                 If not specified, the data will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/demo_data</span></code>.</p></li>
<li><p>n_sample (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of samples to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_episode</span></code> must be specified.</p></li>
<li><p>n_episode (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of episodes to collect. Default to None.                 If not specified, <code class="docutils literal notranslate"><span class="pre">n_sample</span></code> must be specified.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.td3.TD3Agent.deploy">
<span class="sig-name descname"><span class="pre">deploy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">enable_save_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concatenate_all_replay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_save_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.EvalReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/td3.html#TD3Agent.deploy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.td3.TD3Agent.deploy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Deploy the agent with TD3 algorithm by interacting with the environment, during which the replay video             can be saved if <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True. The evaluation result will be returned.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>enable_save_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to save the replay video. Default to False.</p></li>
<li><p>concatenate_all_replay (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to concatenate all replay videos into one video.                 Default to False. If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is False, this argument will be ignored.                 If <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> is True and <code class="docutils literal notranslate"><span class="pre">concatenate_all_replay</span></code> is False,                 the replay video of each episode will be saved separately.</p></li>
<li><p>replay_save_path (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The path to save the replay video. Default to None.                 If not specified, the video will be saved in <code class="docutils literal notranslate"><span class="pre">exp_name/videos</span></code>.</p></li>
<li><p>seed (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[int,</span> <span class="pre">List]</span></code>): The random seed, which is set before running the program.                 Default to None. If not specified, <code class="docutils literal notranslate"><span class="pre">self.seed</span></code> will be used.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is an integer, the agent will be deployed once.                 If <code class="docutils literal notranslate"><span class="pre">seed</span></code> is a list of integers, the agent will be deployed once for each seed in the list.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">EvalReturn</span></code>): The evaluation result, of which the attributions are:</dt><dd><ul>
<li><p>eval_value (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The mean of evaluation return.</p></li>
<li><p>eval_value_std (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.float32</span></code>): The standard deviation of evaluation return.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.bonus.td3.TD3Agent.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">10000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collector_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluator_env_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter_save_ckpt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wandb_sweep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ding.bonus.common.TrainingReturn</span></span></span><a class="reference internal" href="../_modules/ding/bonus/td3.html#TD3Agent.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.bonus.td3.TD3Agent.train" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Train the agent with TD3 algorithm for <code class="docutils literal notranslate"><span class="pre">step</span></code> iterations with <code class="docutils literal notranslate"><span class="pre">collector_env_num</span></code> collector             environments and <code class="docutils literal notranslate"><span class="pre">evaluator_env_num</span></code> evaluator environments. Information during training will be             recorded and saved by wandb.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>step (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The total training environment steps of all collector environments. Default to 1e7.</p></li>
<li><p>collector_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The collector environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>evaluator_env_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The evaluator environment number. Default to None.                 If not specified, it will be set according to the configuration.</p></li>
<li><p>n_iter_save_ckpt (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The frequency of saving checkpoint every training iteration.                 Default to 1000.</p></li>
<li><p>context (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The multi-process context of the environment manager. Default to None.                 It can be specified as <code class="docutils literal notranslate"><span class="pre">spawn</span></code>, <code class="docutils literal notranslate"><span class="pre">fork</span></code> or <code class="docutils literal notranslate"><span class="pre">forkserver</span></code>.</p></li>
<li><p>debug (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use debug mode in the environment manager. Default to False.                 If set True, base environment manager will be used for easy debugging. Otherwise,                 subprocess environment manager will be used.</p></li>
<li><p>wandb_sweep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use wandb sweep,                 which is a hyper-parameter optimization process for seeking the best configurations.                 Default to False. If True, the wandb sweep id will be used as the experiment name.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">TrainingReturn</span></code>): The training result, of which the attributions are:</dt><dd><ul>
<li><p>wandb_url (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>): The weight &amp; biases (wandb) project url of the trainning experiment.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
</section>


              </article>
              
            </div>
            <footer>
  
  <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
    
    <a href="config.html" class="btn btn-neutral float-right" title="ding.config" accesskey="n"
      rel="next">Next <img src="../_static/images/chevron-right-blue.svg"
        class="next-page"></a>
    
    
    <a href="index.html" class="btn btn-neutral" title="API Doc" accesskey="p"
      rel="prev"><img src="../_static/images/chevron-right-blue.svg" class="previous-page"> Previous</a>
    
  </div>
  

  <hr>

  <div role="contentinfo">
    <p>
      &copy; Copyright 2021, OpenDILab Contributors.

    </p>
  </div>
  
  <div>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a
      href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the
      Docs</a>.
  </div>
   

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">ding.agent</a><ul>
<li><a class="reference internal" href="#a2c">a2c</a><ul>
<li><a class="reference internal" href="#a2cagent">A2CAgent</a></li>
</ul>
</li>
<li><a class="reference internal" href="#c51">c51</a><ul>
<li><a class="reference internal" href="#c51agent">C51Agent</a></li>
</ul>
</li>
<li><a class="reference internal" href="#ddpg">ddpg</a><ul>
<li><a class="reference internal" href="#ddpgagent">DDPGAgent</a></li>
</ul>
</li>
<li><a class="reference internal" href="#dqn">dqn</a><ul>
<li><a class="reference internal" href="#dqnagent">DQNAgent</a></li>
</ul>
</li>
<li><a class="reference internal" href="#pg">pg</a><ul>
<li><a class="reference internal" href="#pgagent">PGAgent</a></li>
</ul>
</li>
<li><a class="reference internal" href="#ppo-offpolicy">ppo_offpolicy</a><ul>
<li><a class="reference internal" href="#ppooffpolicyagent">PPOOffPolicyAgent</a></li>
</ul>
</li>
<li><a class="reference internal" href="#ppof">ppof</a><ul>
<li><a class="reference internal" href="#id1">PPOF</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sac">sac</a><ul>
<li><a class="reference internal" href="#sacagent">SACAgent</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sql">sql</a><ul>
<li><a class="reference internal" href="#sqlagent">SQLAgent</a></li>
</ul>
</li>
<li><a class="reference internal" href="#td3">td3</a><ul>
<li><a class="reference internal" href="#td3agent">TD3Agent</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="../"
    src="../_static/documentation_options.js"></script>
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
  <script src="../_static/jquery.js"></script>
  <script src="../_static/underscore.js"></script>
  <script src="../_static/doctools.js"></script>
  

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  </div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/" aria-label="OpenMMLab"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/DI-engine" target="_blank">GitHub</a>
          </li>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>