


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ding.policy &mdash; DI-engine 0.1.0 documentation</title>
  

  <link rel="shortcut icon" href="../_static/images/favicon.ico" />
  
  

  

  
  
  

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/style.css" type="text/css" />
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="next" title="Framework" href="framework/index.html" />
  <link rel="prev" title="ding.model" href="model.html" />
    <link href="../_static/css/style.css" rel="stylesheet" type="text/css">


  
  <script src="../_static/js/modernizr.min.js"></script>
  <script>
    MathJax = {
        chtml: {
            scale: 1,
            minScale: 1,
        },
        svg: {
            scale: 1,
            minScale: 1,
        }
    }
</script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/"
        aria-label="OpenMMLab"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/DI-engine" target="_blank">GitHub</a>
          </li>
          <li >
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a
                class="resource-option with-down-arrow">
                OpenDILab
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-engine" target="_blank">
                  <span class="dropdown-title">DI-engine </span>
                  <p>OpenDILab Decision AI Engine</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-star" target="_blank">
                  <span class="dropdown-title">DI-star </span>
                  <p>OpenDILab Decision AI in StarCraftII</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-drive" target="_blank">
                  <span class="dropdown-title">DI-drive </span>
                  <p>OpenDILab Auto-driving platform</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/GoBigger" target="_blank">
                  <span class="dropdown-title">GoBigger </span>
                  <p>OpenDILab Multi-Agent Environment</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-smartcross" target="_blank">
                  <span class="dropdown-title">DI-smartcross </span>
                  <p>Decision Intelligence Platform for Traffic Crossing Signal Control</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-treetensor" target="_blank">
                  <span class="dropdown-title">DI-treetensor </span>
                  <p>Tree Nested PyTorch Tensor Lib</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-sheep" target="_blank">
                  <span class="dropdown-title">DI-sheep </span>
                  <p>Deep Reinforcement Learning + 3 Tiles Game</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-model-based-RL" target="_blank">
                  <span class="dropdown-title">awesome-model-based-RL </span>
                  <p>A curated list of awesome model based RL resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-decision-transformer" target="_blank">
                  <span class="dropdown-title">awesome-decision-transformer </span>
                  <p>A curated list of Decision Transformer resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-exploration-rl" target="_blank">
                  <span class="dropdown-title">awesome-exploration-rl </span>
                  <p>A curated list of awesome exploration RL resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-multi-modal-reinforcement-learning" target="_blank">
                  <span class="dropdown-title">awesome-multi-modal-reinforcement-learning </span>
                  <p>A curated list of Multi-Modal Reinforcement Learning resources (continually updated)</p>
                </a>
              </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../00_intro/index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_quickstart/index.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_algo/index.html">RL Algorithm Taxonomy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03_system/index.html">System Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04_best_practice/index.html">Best Practice</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">API Doc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06_faq/index.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reinforcement Learning Tutorial</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../10_concepts/index.html">Introduction to RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11_dizoo/index.html">Learn From DI-zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../12_policies/index.html">RL Algorithms Cheat Sheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../13_envs/index.html">RL Env Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../20_spec/index.html">Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../21_code_style/index.html">Code Style Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../22_test/index.html">Unit Test Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../23_visual/index.html">Diagrams and Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../24_cooperation/index.html">Github Cooperation</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
            Docs
        </a> &gt;
      </li>

        
          <li><a href="index.html">API Doc</a> &gt;</li>
        
      <li>ding.policy</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/05_api_doc/policy.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
  <section id="ding-policy">
<h1>ding.policy<a class="headerlink" href="#ding-policy" title="Permalink to this headline">¶</a></h1>
<section id="base-policy">
<h2>Base Policy<a class="headerlink" href="#base-policy" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/policy/base_policy.py</span></code> for more details.</p>
<section id="policy">
<h3>Policy<a class="headerlink" href="#policy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.Policy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">Policy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/base_policy.html#Policy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.Policy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="ding.policy.Policy.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/base_policy.html#Policy.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.Policy.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.Policy.__repr__">
<span class="sig-name descname"><span class="pre">__repr__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference internal" href="../_modules/ding/policy/base_policy.html#Policy.__repr__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.Policy.__repr__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return repr(self).</p>
</dd></dl>

</dd></dl>

</section>
<section id="commandmodepolicy">
<h3>CommandModePolicy<a class="headerlink" href="#commandmodepolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.CommandModePolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">CommandModePolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/base_policy.html#CommandModePolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.CommandModePolicy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="create-policy">
<h3>create_policy<a class="headerlink" href="#create-policy" title="Permalink to this headline">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="ding.policy.create_policy">
<span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">create_policy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#ding.policy.Policy" title="ding.policy.base_policy.Policy"><span class="pre">ding.policy.base_policy.Policy</span></a></span></span><a class="reference internal" href="../_modules/ding/policy/base_policy.html#create_policy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.create_policy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="get-policy-cls">
<h3>get_policy_cls<a class="headerlink" href="#get-policy-cls" title="Permalink to this headline">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="ding.policy.get_policy_cls">
<span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">get_policy_cls</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">easydict.EasyDict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">type</span></span></span><a class="reference internal" href="../_modules/ding/policy/base_policy.html#get_policy_cls"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.get_policy_cls" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
</section>
<section id="dqn">
<h2>DQN<a class="headerlink" href="#dqn" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/policy/dqn.py</span></code> for more details.</p>
<section id="dqnpolicy">
<h3>DQNPolicy<a class="headerlink" href="#dqnpolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.DQNPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">DQNPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Policy class of DQN algorithm, extended by Double DQN/Dueling DQN/PER/multi-step TD.</p>
</dd>
<dt>Config:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 2%" />
<col style="width: 20%" />
<col style="width: 7%" />
<col style="width: 13%" />
<col style="width: 36%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Symbol</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Other(Shape)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">type</span></code></p></td>
<td><p>str</p></td>
<td><p>dqn</p></td>
<td><div class="line-block">
<div class="line">RL policy register name, refer to</div>
<div class="line">registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line">This arg is optional,</div>
<div class="line">a placeholder</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cuda</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to use cuda for network</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This arg can be diff-</div>
<div class="line">erent from modes</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">on_policy</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether the RL algorithm is on-policy</div>
<div class="line">or off-policy</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">priority</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use priority(PER)</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Priority sample,</div>
<div class="line">update priority</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">priority_IS</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_weight</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use Importance Sampling</div>
<div class="line">Weight to correct biased update. If</div>
<div class="line">True, priority must be True.</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">discount_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">factor</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.97,
[0.95, 0.999]</p></td>
<td><div class="line-block">
<div class="line">Reward’s future discount factor, aka.</div>
<div class="line">gamma</div>
</div>
</td>
<td><div class="line-block">
<div class="line">May be 1 when sparse</div>
<div class="line">reward env</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nstep</span></code></p></td>
<td><p>int</p></td>
<td><p>1,
[3, 5]</p></td>
<td><div class="line-block">
<div class="line">N-step reward discount sum for target</div>
<div class="line">q_value estimation</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">model.dueling</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>True</p></td>
<td><div class="line-block">
<div class="line">dueling head architecture</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">model.encoder</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_hidden</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_size_list</span></code></div>
</div>
</td>
<td><p>list
(int)</p></td>
<td><p>[32, 64,
64, 128]</p></td>
<td><div class="line-block">
<div class="line">Sequence of <code class="docutils literal notranslate"><span class="pre">hidden_size</span></code> of</div>
<div class="line">subsequent conv layers and the</div>
<div class="line">final dense layer.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">default kernel_size</div>
<div class="line">is [8, 4, 3]</div>
<div class="line">default stride is</div>
<div class="line">[4, 2 ,1]</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">model.dropout</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>None</p></td>
<td><div class="line-block">
<div class="line">Dropout rate for dropout layers.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[0,1]</div>
<div class="line">If set to <code class="docutils literal notranslate"><span class="pre">None</span></code></div>
<div class="line">means no dropout</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>11</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.update</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">per_collect</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>3</p></td>
<td><div class="line-block">
<div class="line">How many updates(iterations) to train</div>
<div class="line">after collector’s one collection.</div>
<div class="line">Only valid in serial training</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This args can be vary</div>
<div class="line">from envs. Bigger val</div>
<div class="line">means more off-policy</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>12</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.batch_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">size</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>64</p></td>
<td><div class="line-block">
<div class="line">The number of samples of an iteration</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>13</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.001</p></td>
<td><div class="line-block">
<div class="line">Gradient step length of an iteration.</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>14</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.target_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">update_freq</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>100</p></td>
<td><div class="line-block">
<div class="line">Frequence of target network update.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Hard(assign) update</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>15</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.target_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">theta</span></code></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.005</p></td>
<td><div class="line-block">
<div class="line">Frequence of target network update.</div>
<div class="line">Only one of [target_update_freq,</div>
<div class="line">target_theta] should be set</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Soft(assign) update</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>16</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.ignore_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">done</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether ignore done for target value</div>
<div class="line">calculation.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Enable it for some</div>
<div class="line">fake termination env</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>17</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">collect.n_sample</span></code></p></td>
<td><p>int</p></td>
<td><p>[8, 128]</p></td>
<td><div class="line-block">
<div class="line">The number of training samples of a</div>
<div class="line">call of collector.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">It varies from</div>
<div class="line">different envs</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>18</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">collect.n_episode</span></code></p></td>
<td><p>int</p></td>
<td><p>8</p></td>
<td><div class="line-block">
<div class="line">The number of training episodes of a</div>
<div class="line">call of collector</div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">only one of [n_sample</div>
<div class="line">,n_episode] should</div>
<div class="line">be set</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>19</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect.unroll</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_len</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>1</p></td>
<td><div class="line-block">
<div class="line">unroll length of an iteration</div>
</div>
</td>
<td><div class="line-block">
<div class="line">In RNN, unroll_len&gt;1</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>20</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">other.eps.type</span></code></div>
</div>
</td>
<td><p>str</p></td>
<td><p>exp</p></td>
<td><div class="line-block">
<div class="line">exploration rate decay type</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Support [‘exp’,</div>
<div class="line">‘linear’].</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>21</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">other.eps.</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">start</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.95</p></td>
<td><div class="line-block">
<div class="line">start value of exploration rate</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[0,1]</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>22</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">other.eps.</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">end</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.1</p></td>
<td><div class="line-block">
<div class="line">end value of exploration rate</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[0,1]</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>23</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">other.eps.</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">decay</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>10000</p></td>
<td><div class="line-block">
<div class="line">decay length of exploration</div>
</div>
</td>
<td><div class="line-block">
<div class="line">greater than 0. set</div>
<div class="line">decay=10000 means</div>
<div class="line">the exploration rate</div>
<div class="line">decay from start</div>
<div class="line">value to end value</div>
<div class="line">during decay length.</div>
</div>
</td>
</tr>
</tbody>
</table>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DQNPolicy._forward_collect">
<span class="sig-name descname"><span class="pre">_forward_collect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNPolicy._forward_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNPolicy._forward_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward computation graph of collect mode(collect training data), with eps_greedy for exploration.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action),                 values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p></li>
<li><p>eps (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): epsilon value for exploration, which is decayed by collected env step.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): The dict of predicting policy_output(action) for the interaction with                 env and the constructing of transition.</p></li>
</ul>
</dd>
<dt>ArgumentsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">obs</span></code></p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">logit</span></code>, <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DQNPolicy._forward_eval">
<span class="sig-name descname"><span class="pre">_forward_eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNPolicy._forward_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNPolicy._forward_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward computation graph of eval mode(evaluate policy performance), at most cases, it is similar to             <code class="docutils literal notranslate"><span class="pre">self._forward_collect</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action),                 values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): The dict of predicting action for the interaction with env.</p></li>
</ul>
</dd>
<dt>ArgumentsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">obs</span></code></p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DQNPolicy._forward_learn">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNPolicy._forward_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNPolicy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward computation graph of learn mode(updating policy).</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a batch of data for training, values are torch.Tensor or                 np.ndarray or dict/list combinations.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a info dict indicated training result, which will be                 recorded in text log and tensorboard, values are python scalar or a list of scalars.</p></li>
</ul>
</dd>
<dt>ArgumentsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">obs</span></code>, <code class="docutils literal notranslate"><span class="pre">action</span></code>, <code class="docutils literal notranslate"><span class="pre">reward</span></code>, <code class="docutils literal notranslate"><span class="pre">next_obs</span></code>, <code class="docutils literal notranslate"><span class="pre">done</span></code></p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">value_gamma</span></code></p></li>
</ul>
</dd>
<dt>ReturnsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">cur_lr</span></code>, <code class="docutils literal notranslate"><span class="pre">total_loss</span></code>, <code class="docutils literal notranslate"><span class="pre">priority</span></code></p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">action_distribution</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DQNPolicy._get_train_sample">
<span class="sig-name descname"><span class="pre">_get_train_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNPolicy._get_train_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNPolicy._get_train_sample" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>For a given trajectory(transitions, a list of transition) data, process it into a list of sample that             can be used for training directly. A train sample can be a processed transition(DQN with nstep TD)             or some continuous transitions(DRQN).</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[Dict[str,</span> <span class="pre">Any]</span></code>): The trajectory data(a list of transition), each element is the same                 format as the return value of <code class="docutils literal notranslate"><span class="pre">self._process_transition</span></code> method.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>samples (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): The list of training samples.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We will vectorize <code class="docutils literal notranslate"><span class="pre">process_transition</span></code> and <code class="docutils literal notranslate"><span class="pre">get_train_sample</span></code> method in the following release version.             And the user can customize the this data processing procecure by overriding this two methods and collector             itself.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DQNPolicy._init_collect">
<span class="sig-name descname"><span class="pre">_init_collect</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNPolicy._init_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNPolicy._init_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>, initialize algorithm arguments and collect_model,             enable the eps_greedy_sample for exploration.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DQNPolicy._init_eval">
<span class="sig-name descname"><span class="pre">_init_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNPolicy._init_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNPolicy._init_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>, initialize eval_model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DQNPolicy._init_learn">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNPolicy._init_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNPolicy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Learn mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>, initialize the optimizer, algorithm arguments, main             and target model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DQNPolicy._load_state_dict_learn">
<span class="sig-name descname"><span class="pre">_load_state_dict_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNPolicy._load_state_dict_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNPolicy._load_state_dict_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Load the state_dict variable into policy learn mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): the dict of policy learn state saved before.</p></li>
</ul>
</dd>
</dl>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If you want to only load some parts of model, you can simply set the <code class="docutils literal notranslate"><span class="pre">strict</span></code> argument in             load_state_dict to <code class="docutils literal notranslate"><span class="pre">False</span></code>, or refer to <code class="docutils literal notranslate"><span class="pre">ding.torch_utils.checkpoint_helper</span></code> for more             complicated operation.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DQNPolicy._process_transition">
<span class="sig-name descname"><span class="pre">_process_transition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_output</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timestep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">collections.namedtuple</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNPolicy._process_transition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNPolicy._process_transition" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Generate a transition(e.g.: &lt;s, a, s’, r, d&gt;) for this algorithm training.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>obs (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>): Env observation.</p></li>
<li><p>policy_output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): The output of policy collect mode(<code class="docutils literal notranslate"><span class="pre">self._forward_collect</span></code>),                including at least <code class="docutils literal notranslate"><span class="pre">action</span></code>.</p></li>
<li><p>timestep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">namedtuple</span></code>): The output after env step(execute policy output action), including at                 least <code class="docutils literal notranslate"><span class="pre">obs</span></code>, <code class="docutils literal notranslate"><span class="pre">reward</span></code>, <code class="docutils literal notranslate"><span class="pre">done</span></code>, (here obs indicates obs after env step).</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>transition (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type transition data.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DQNPolicy._state_dict_learn">
<span class="sig-name descname"><span class="pre">_state_dict_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNPolicy._state_dict_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNPolicy._state_dict_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return the state_dict of learn mode, usually including model and optimizer.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): the dict of current policy learn state, for saving and restoring.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DQNPolicy.default_model">
<span class="sig-name descname"><span class="pre">default_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNPolicy.default_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNPolicy.default_model" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return this algorithm default model setting for demonstration.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>model_info (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Tuple[str,</span> <span class="pre">List[str]]</span></code>): model name and mode import_names</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The user can define and use customized network model but must obey the same inferface definition indicated             by import_names path. For DQN, <code class="docutils literal notranslate"><span class="pre">ding.model.template.q_learning.DQN</span></code></p>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="dqnstdimpolicy">
<h3>DQNSTDIMPolicy<a class="headerlink" href="#dqnstdimpolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.DQNSTDIMPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">DQNSTDIMPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNSTDIMPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNSTDIMPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Policy class of DQN algorithm, extended by auxiliary objectives.</p>
</dd>
<dt>Config:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 2%" />
<col style="width: 19%" />
<col style="width: 7%" />
<col style="width: 13%" />
<col style="width: 37%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Symbol</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Other(Shape)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">type</span></code></p></td>
<td><p>str</p></td>
<td><p>dqn_stdim</p></td>
<td><div class="line-block">
<div class="line">RL policy register name, refer to</div>
<div class="line">registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line">This arg is optional,</div>
<div class="line">a placeholder</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cuda</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to use cuda for network</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This arg can be diff-</div>
<div class="line">erent from modes</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">on_policy</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether the RL algorithm is on-policy</div>
<div class="line">or off-policy</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">priority</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use priority(PER)</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Priority sample,</div>
<div class="line">update priority</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">priority_IS</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_weight</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use Importance Sampling Weight</div>
<div class="line">to correct biased update. If True,</div>
<div class="line">priority must be True.</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">discount_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">factor</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.97,
[0.95, 0.999]</p></td>
<td><div class="line-block">
<div class="line">Reward’s future discount factor, aka.</div>
<div class="line">gamma</div>
</div>
</td>
<td><div class="line-block">
<div class="line">May be 1 when sparse</div>
<div class="line">reward env</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nstep</span></code></p></td>
<td><p>int</p></td>
<td><p>1,
[3, 5]</p></td>
<td><div class="line-block">
<div class="line">N-step reward discount sum for target</div>
<div class="line">q_value estimation</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.update</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">per_collect</span></code></div>
</div>
<div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">_gpu</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>3</p></td>
<td><div class="line-block">
<div class="line">How many updates(iterations) to train</div>
<div class="line">after collector’s one collection. Only</div>
<div class="line">valid in serial training</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This args can be vary</div>
<div class="line">from envs. Bigger val</div>
<div class="line">means more off-policy</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>10</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.batch_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">size</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>64</p></td>
<td><div class="line-block">
<div class="line">The number of samples of an iteration</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>11</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.001</p></td>
<td><div class="line-block">
<div class="line">Gradient step length of an iteration.</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>12</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.target_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">update_freq</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>100</p></td>
<td><div class="line-block">
<div class="line">Frequence of target network update.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Hard(assign) update</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>13</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.ignore_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">done</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether ignore done for target value</div>
<div class="line">calculation.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Enable it for some</div>
<div class="line">fake termination env</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>14</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">collect.n_sample</span></code></p></td>
<td><p>int</p></td>
<td><p>[8, 128]</p></td>
<td><div class="line-block">
<div class="line">The number of training samples of a</div>
<div class="line">call of collector.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">It varies from</div>
<div class="line">different envs</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>15</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect.unroll</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_len</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>1</p></td>
<td><div class="line-block">
<div class="line">unroll length of an iteration</div>
</div>
</td>
<td><div class="line-block">
<div class="line">In RNN, unroll_len&gt;1</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>16</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">other.eps.type</span></code></div>
</div>
</td>
<td><p>str</p></td>
<td><p>exp</p></td>
<td><div class="line-block">
<div class="line">exploration rate decay type</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Support [‘exp’,</div>
<div class="line">‘linear’].</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>17</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">other.eps.</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">start</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.95</p></td>
<td><div class="line-block">
<div class="line">start value of exploration rate</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[0,1]</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>18</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">other.eps.</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">end</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.1</p></td>
<td><div class="line-block">
<div class="line">end value of exploration rate</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[0,1]</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>19</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">other.eps.</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">decay</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>10000</p></td>
<td><div class="line-block">
<div class="line">decay length of exploration</div>
</div>
</td>
<td><div class="line-block">
<div class="line">greater than 0. set</div>
<div class="line">decay=10000 means</div>
<div class="line">the exploration rate</div>
<div class="line">decay from start</div>
<div class="line">value to end value</div>
<div class="line">during decay length.</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>20</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">aux_loss</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_weight</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.001</p></td>
<td><div class="line-block">
<div class="line">the ratio of the auxiliary loss to</div>
<div class="line">the TD loss</div>
</div>
</td>
<td><div class="line-block">
<div class="line">any real value,</div>
<div class="line">typically in</div>
<div class="line">[-0.1, 0.1].</div>
</div>
</td>
</tr>
</tbody>
</table>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DQNSTDIMPolicy._forward_learn">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNSTDIMPolicy._forward_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNSTDIMPolicy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward computation graph of learn mode(updating policy).</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a batch of data for training, values are torch.Tensor or                 np.ndarray or dict/list combinations.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a info dict indicated training result, which will be                 recorded in text log and tensorboard, values are python scalar or a list of scalars.</p></li>
</ul>
</dd>
<dt>ArgumentsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">obs</span></code>, <code class="docutils literal notranslate"><span class="pre">action</span></code>, <code class="docutils literal notranslate"><span class="pre">reward</span></code>, <code class="docutils literal notranslate"><span class="pre">next_obs</span></code>, <code class="docutils literal notranslate"><span class="pre">done</span></code></p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">value_gamma</span></code>, <code class="docutils literal notranslate"><span class="pre">IS</span></code></p></li>
</ul>
</dd>
<dt>ReturnsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">cur_lr</span></code>, <code class="docutils literal notranslate"><span class="pre">total_loss</span></code>, <code class="docutils literal notranslate"><span class="pre">priority</span></code></p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">action_distribution</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DQNSTDIMPolicy._init_learn">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNSTDIMPolicy._init_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNSTDIMPolicy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Learn mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init the auxiliary model, its optimizer, and the axuliary loss weight to the main loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DQNSTDIMPolicy._load_state_dict_learn">
<span class="sig-name descname"><span class="pre">_load_state_dict_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNSTDIMPolicy._load_state_dict_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNSTDIMPolicy._load_state_dict_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Load the state_dict variable into policy learn mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): the dict of policy learn state saved before.</p></li>
</ul>
</dd>
</dl>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If you want to only load some parts of model, you can simply set the <code class="docutils literal notranslate"><span class="pre">strict</span></code> argument in             load_state_dict to <code class="docutils literal notranslate"><span class="pre">False</span></code>, or refer to <code class="docutils literal notranslate"><span class="pre">ding.torch_utils.checkpoint_helper</span></code> for more             complicated operation.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DQNSTDIMPolicy._model_encode">
<span class="sig-name descname"><span class="pre">_model_encode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNSTDIMPolicy._model_encode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNSTDIMPolicy._model_encode" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Get the encoding of the main model as input for the auxiliary model.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type data, same as the _forward_learn input.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">Tuple[Tensor]</span></code>): the tuple of two tensors to apply contrastive embedding learning.</dt><dd><p>In ST-DIM algorithm, these two variables are the dqn encoding of <cite>obs</cite> and <cite>next_obs</cite>                respectively.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DQNSTDIMPolicy._state_dict_learn">
<span class="sig-name descname"><span class="pre">_state_dict_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/dqn.html#DQNSTDIMPolicy._state_dict_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DQNSTDIMPolicy._state_dict_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return the state_dict of learn mode, usually including model and optimizer.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): the dict of current policy learn state, for saving and restoring.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="ppo">
<h2>PPO<a class="headerlink" href="#ppo" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/policy/ppo.py</span></code> for more details.</p>
<section id="ppopolicy">
<h3>PPOPolicy<a class="headerlink" href="#ppopolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.PPOPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">PPOPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Policy class of on policy version PPO algorithm.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOPolicy._forward_collect">
<span class="sig-name descname"><span class="pre">_forward_collect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOPolicy._forward_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOPolicy._forward_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward function of collect mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action), </dt><dd><p>values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): Dict type data, including at least inferred action according to input obs.</p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOPolicy._forward_eval">
<span class="sig-name descname"><span class="pre">_forward_eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOPolicy._forward_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOPolicy._forward_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward function of eval mode, similar to <code class="docutils literal notranslate"><span class="pre">self._forward_collect</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action), </dt><dd><p>values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): The dict of predicting action for the interaction with env.</p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOPolicy._forward_learn">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOPolicy._forward_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOPolicy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Forward and backward function of learn mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type data</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul>
<li><p>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>):
Including current lr, total_loss, policy_loss, value_loss, entropy_loss, </p>
<blockquote>
<div><p>adv_abs_max, approx_kl, clipfrac</p>
</div></blockquote>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOPolicy._get_train_sample">
<span class="sig-name descname"><span class="pre">_get_train_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOPolicy._get_train_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOPolicy._get_train_sample" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Get the trajectory and calculate GAE, return one data to cache for next time calculation</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code>): The trajectory’s cache</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>samples (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): The training samples generated</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOPolicy._init_collect">
<span class="sig-name descname"><span class="pre">_init_collect</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOPolicy._init_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOPolicy._init_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init traj and unroll length, collect model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOPolicy._init_eval">
<span class="sig-name descname"><span class="pre">_init_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOPolicy._init_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOPolicy._init_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init eval model with argmax strategy.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOPolicy._init_learn">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOPolicy._init_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOPolicy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Learn mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init the optimizer, algorithm config and the main model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOPolicy._process_transition">
<span class="sig-name descname"><span class="pre">_process_transition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_output</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timestep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">collections.namedtuple</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOPolicy._process_transition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOPolicy._process_transition" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Generate dict type transition data from inputs.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>obs (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>): Env observation</p></li>
<li><p>model_output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Output of collect model, including at least [‘action’]</p></li>
<li><p>timestep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">namedtuple</span></code>): Output after env step, including at least [‘obs’, ‘reward’, ‘done’]                       (here ‘obs’ indicates obs after env step).</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>transition (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type transition data.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="ppopgpolicy">
<h3>PPOPGPolicy<a class="headerlink" href="#ppopgpolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.PPOPGPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">PPOPGPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOPGPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOPGPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Policy class of on policy version PPO algorithm (pure policy gradient).</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="ppooffpolicy">
<h3>PPOOffPolicy<a class="headerlink" href="#ppooffpolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.PPOOffPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">PPOOffPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOOffPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOOffPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Policy class of PPO algorithm.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOOffPolicy._forward_collect">
<span class="sig-name descname"><span class="pre">_forward_collect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOOffPolicy._forward_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOOffPolicy._forward_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward function of collect mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action), </dt><dd><p>values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): Dict type data, including at least inferred action according to input obs.</p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOOffPolicy._forward_eval">
<span class="sig-name descname"><span class="pre">_forward_eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOOffPolicy._forward_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOOffPolicy._forward_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward function of eval mode, similar to <code class="docutils literal notranslate"><span class="pre">self._forward_collect</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action), </dt><dd><p>values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): The dict of predicting action for the interaction with env.</p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOOffPolicy._forward_learn">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOOffPolicy._forward_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOOffPolicy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Forward and backward function of learn mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type data</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul>
<li><p>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>):
Including current lr, total_loss, policy_loss, value_loss, entropy_loss, </p>
<blockquote>
<div><p>adv_abs_max, approx_kl, clipfrac</p>
</div></blockquote>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOOffPolicy._get_train_sample">
<span class="sig-name descname"><span class="pre">_get_train_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOOffPolicy._get_train_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOOffPolicy._get_train_sample" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Get the trajectory and calculate GAE, return one data to cache for next time calculation</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code>): The trajectory’s cache</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>samples (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): The training samples generated</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOOffPolicy._init_collect">
<span class="sig-name descname"><span class="pre">_init_collect</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOOffPolicy._init_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOOffPolicy._init_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init traj and unroll length, collect model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOOffPolicy._init_eval">
<span class="sig-name descname"><span class="pre">_init_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOOffPolicy._init_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOOffPolicy._init_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init eval model with argmax strategy.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOOffPolicy._init_learn">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOOffPolicy._init_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOOffPolicy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Learn mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init the optimizer, algorithm config and the main model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOOffPolicy._process_transition">
<span class="sig-name descname"><span class="pre">_process_transition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_output</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timestep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">collections.namedtuple</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOOffPolicy._process_transition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOOffPolicy._process_transition" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Generate dict type transition data from inputs.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>obs (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>): Env observation</p></li>
<li><p>model_output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Output of collect model, including at least [‘action’]</p></li>
<li><p>timestep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">namedtuple</span></code>): Output after env step, including at least [‘obs’, ‘reward’, ‘done’]                       (here ‘obs’ indicates obs after env step).</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>transition (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type transition data.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="ppostdimpolicy">
<h3>PPOSTDIMPolicy<a class="headerlink" href="#ppostdimpolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.PPOSTDIMPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">PPOSTDIMPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOSTDIMPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOSTDIMPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Policy class of on policy version PPO algorithm with ST-DIM auxiliary model.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOSTDIMPolicy._forward_learn">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOSTDIMPolicy._forward_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOSTDIMPolicy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward and backward function of learn mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type data</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>):
Including current lr, total_loss, policy_loss, value_loss, entropy_loss,                         adv_abs_max, approx_kl, clipfrac</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOSTDIMPolicy._init_learn">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOSTDIMPolicy._init_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOSTDIMPolicy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Learn mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init the auxiliary model, its optimizer, and the axuliary loss weight to the main loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PPOSTDIMPolicy._model_encode">
<span class="sig-name descname"><span class="pre">_model_encode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/ppo.html#PPOSTDIMPolicy._model_encode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PPOSTDIMPolicy._model_encode" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Get the encoding of the main model as input for the auxiliary model.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type data, same as the _forward_learn input.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>(<code class="xref py py-obj docutils literal notranslate"><span class="pre">Tuple[Tensor]</span></code>): the tuple of two tensors to apply contrastive embedding learning.</dt><dd><p>In ST-DIM algorithm, these two variables are the dqn encoding of <cite>obs</cite> and <cite>next_obs</cite>                respectively.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="bc">
<h2>BC<a class="headerlink" href="#bc" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/policy/bc.py</span></code> for more details.</p>
<section id="behaviourcloningpolicy">
<h3>BehaviourCloningPolicy<a class="headerlink" href="#behaviourcloningpolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.BehaviourCloningPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">BehaviourCloningPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/bc.html#BehaviourCloningPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.BehaviourCloningPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="ding.policy.BehaviourCloningPolicy._init_collect">
<span class="sig-name descname"><span class="pre">_init_collect</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/bc.html#BehaviourCloningPolicy._init_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.BehaviourCloningPolicy._init_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init traj and unroll length, collect model.
Enable the eps_greedy_sample</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="ddpg">
<h2>DDPG<a class="headerlink" href="#ddpg" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/policy/ddpg.py</span></code> for more details.</p>
<section id="ddpgpolicy">
<h3>DDPGPolicy<a class="headerlink" href="#ddpgpolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.DDPGPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">DDPGPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/ddpg.html#DDPGPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DDPGPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Policy class of DDPG algorithm.</p>
<p><a class="reference external" href="https://arxiv.org/pdf/1509.02971.pdf">https://arxiv.org/pdf/1509.02971.pdf</a></p>
</dd>
<dt>Property:</dt><dd><p>learn_mode, collect_mode, eval_mode</p>
</dd>
</dl>
<p>Config:</p>
<blockquote>
<div><table class="docutils align-default">
<colgroup>
<col style="width: 2%" />
<col style="width: 20%" />
<col style="width: 8%" />
<col style="width: 13%" />
<col style="width: 33%" />
<col style="width: 24%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Symbol</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Other(Shape)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">type</span></code></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>str</p></td>
<td><p>ddpg</p></td>
<td><div class="line-block">
<div class="line">RL policy register name, refer</div>
<div class="line">to registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line">this arg is optional,</div>
<div class="line">a placeholder</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">cuda</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to use cuda for network</div>
</div>
</td>
<td><div class="line-block">
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">random_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect_size</span></code></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>int</p></td>
<td><p>25000</p></td>
<td><div class="line-block">
<div class="line">Number of randomly collected</div>
<div class="line">training samples in replay</div>
<div class="line">buffer when training starts.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Default to 25000 for</div>
<div class="line">DDPG/TD3, 10000 for</div>
<div class="line">sac.</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">model.twin_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">critic</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to use two critic</div>
<div class="line">networks or only one.</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">Default False for</div>
<div class="line">DDPG, Clipped Double</div>
<div class="line">Q-learning method in</div>
<div class="line">TD3 paper.</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate_actor</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>1e-3</p></td>
<td><div class="line-block">
<div class="line">Learning rate for actor</div>
<div class="line">network(aka. policy).</div>
</div>
</td>
<td><div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate_critic</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>1e-3</p></td>
<td><div class="line-block">
<div class="line">Learning rates for critic</div>
<div class="line">network (aka. Q-network).</div>
</div>
</td>
<td><div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.actor_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">update_freq</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>int</p></td>
<td><p>2</p></td>
<td><div class="line-block">
<div class="line">When critic network updates</div>
<div class="line">once, how many times will actor</div>
<div class="line">network update.</div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">Default 1 for DDPG,</div>
<div class="line">2 for TD3. Delayed</div>
<div class="line">Policy Updates method</div>
<div class="line">in TD3 paper.</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.noise</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to add noise on target</div>
<div class="line">network’s action.</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">Default False for</div>
<div class="line">DDPG, True for TD3.</div>
<div class="line">Target Policy Smoo-</div>
<div class="line">thing Regularization</div>
<div class="line">in TD3 paper.</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.-</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">ignore_done</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Determine whether to ignore</div>
<div class="line">done flag.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Use ignore_done only</div>
<div class="line">in halfcheetah env.</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.-</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">target_theta</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.005</p></td>
<td><div class="line-block">
<div class="line">Used for soft update of the</div>
<div class="line">target network.</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">aka. Interpolation</div>
<div class="line">factor in polyak aver-</div>
<div class="line">aging for target</div>
<div class="line">networks.</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>11</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect.-</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">noise_sigma</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.1</p></td>
<td><div class="line-block">
<div class="line">Used for add noise during co-</div>
<div class="line">llection, through controlling</div>
<div class="line">the sigma of distribution</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">Sample noise from dis-</div>
<div class="line">tribution, Ornstein-</div>
<div class="line">Uhlenbeck process in</div>
<div class="line">DDPG paper, Gaussian</div>
<div class="line">process in ours.</div>
</div>
</td>
</tr>
</tbody>
</table>
</div></blockquote>
<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DDPGPolicy._forward_collect">
<span class="sig-name descname"><span class="pre">_forward_collect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../_modules/ding/policy/ddpg.html#DDPGPolicy._forward_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DDPGPolicy._forward_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward function of collect mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action), </dt><dd><p>values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): Dict type data, including at least inferred action according to input obs.</p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">logit</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DDPGPolicy._forward_eval">
<span class="sig-name descname"><span class="pre">_forward_eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../_modules/ding/policy/ddpg.html#DDPGPolicy._forward_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DDPGPolicy._forward_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward function of eval mode, similar to <code class="docutils literal notranslate"><span class="pre">self._forward_collect</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action), </dt><dd><p>values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): The dict of predicting action for the interaction with env.</p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">logit</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DDPGPolicy._forward_learn">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/ddpg.html#DDPGPolicy._forward_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DDPGPolicy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward and backward function of learn mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type data, including at least [‘obs’, ‘action’, ‘reward’, ‘next_obs’]</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Including at least actor and critic lr, different losses.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DDPGPolicy._init_collect">
<span class="sig-name descname"><span class="pre">_init_collect</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/ddpg.html#DDPGPolicy._init_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DDPGPolicy._init_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init traj and unroll length, collect model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DDPGPolicy._init_eval">
<span class="sig-name descname"><span class="pre">_init_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/ddpg.html#DDPGPolicy._init_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DDPGPolicy._init_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init eval model. Unlike learn and collect model, eval model does not need noise.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DDPGPolicy._init_learn">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/ddpg.html#DDPGPolicy._init_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DDPGPolicy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Learn mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init actor and critic optimizers, algorithm config, main and target models.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DDPGPolicy._monitor_vars_learn">
<span class="sig-name descname"><span class="pre">_monitor_vars_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/ddpg.html#DDPGPolicy._monitor_vars_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DDPGPolicy._monitor_vars_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return variables’ names if variables are to used in monitor.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>vars (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[str]</span></code>): Variables’ name list.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DDPGPolicy._process_transition">
<span class="sig-name descname"><span class="pre">_process_transition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_output</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timestep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">collections.namedtuple</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/ddpg.html#DDPGPolicy._process_transition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DDPGPolicy._process_transition" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Generate dict type transition data from inputs.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>obs (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>): Env observation</p></li>
<li><p>model_output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Output of collect model, including at least [‘action’]</p></li>
<li><dl class="simple">
<dt>timestep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">namedtuple</span></code>): Output after env step, including at least [‘obs’, ‘reward’, ‘done’] </dt><dd><p>(here ‘obs’ indicates obs after env step, i.e. next_obs).</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Return:</dt><dd><ul class="simple">
<li><p>transition (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type transition data.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="td3">
<h2>TD3<a class="headerlink" href="#td3" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/policy/td3.py</span></code> for more details.</p>
<section id="td3policy">
<h3>TD3Policy<a class="headerlink" href="#td3policy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.TD3Policy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">TD3Policy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/td3.html#TD3Policy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.TD3Policy" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Policy class of TD3 algorithm.</p>
<p>Since DDPG and TD3 share many common things, we can easily derive this TD3
class from DDPG class by changing <code class="docutils literal notranslate"><span class="pre">_actor_update_freq</span></code>, <code class="docutils literal notranslate"><span class="pre">_twin_critic</span></code> and noise in model wrapper.</p>
<p><a class="reference external" href="https://arxiv.org/pdf/1802.09477.pdf">https://arxiv.org/pdf/1802.09477.pdf</a></p>
</dd>
<dt>Property:</dt><dd><p>learn_mode, collect_mode, eval_mode</p>
</dd>
</dl>
<p>Config:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 2%" />
<col style="width: 19%" />
<col style="width: 8%" />
<col style="width: 17%" />
<col style="width: 32%" />
<col style="width: 22%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Symbol</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Other(Shape)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">type</span></code></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>str</p></td>
<td><p>td3</p></td>
<td><div class="line-block">
<div class="line">RL policy register name, refer</div>
<div class="line">to registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line">this arg is optional,</div>
<div class="line">a placeholder</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">cuda</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to use cuda for network</div>
</div>
</td>
<td><div class="line-block">
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">random_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect_size</span></code></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>int</p></td>
<td><p>25000</p></td>
<td><div class="line-block">
<div class="line">Number of randomly collected</div>
<div class="line">training samples in replay</div>
<div class="line">buffer when training starts.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Default to 25000 for</div>
<div class="line">DDPG/TD3, 10000 for</div>
<div class="line">sac.</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">model.twin_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">critic</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>True</p></td>
<td><div class="line-block">
<div class="line">Whether to use two critic</div>
<div class="line">networks or only one.</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">Default True for TD3,</div>
<div class="line">Clipped Double</div>
<div class="line">Q-learning method in</div>
<div class="line">TD3 paper.</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate_actor</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>1e-3</p></td>
<td><div class="line-block">
<div class="line">Learning rate for actor</div>
<div class="line">network(aka. policy).</div>
</div>
</td>
<td><div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate_critic</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>1e-3</p></td>
<td><div class="line-block">
<div class="line">Learning rates for critic</div>
<div class="line">network (aka. Q-network).</div>
</div>
</td>
<td><div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.actor_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">update_freq</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>int</p></td>
<td><p>2</p></td>
<td><div class="line-block">
<div class="line">When critic network updates</div>
<div class="line">once, how many times will actor</div>
<div class="line">network update.</div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">Default 2 for TD3, 1</div>
<div class="line">for DDPG. Delayed</div>
<div class="line">Policy Updates method</div>
<div class="line">in TD3 paper.</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.noise</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>True</p></td>
<td><div class="line-block">
<div class="line">Whether to add noise on target</div>
<div class="line">network’s action.</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">Default True for TD3,</div>
<div class="line">False for DDPG.</div>
<div class="line">Target Policy Smoo-</div>
<div class="line">thing Regularization</div>
<div class="line">in TD3 paper.</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.noise_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">range</span></code></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>dict</p></td>
<td><div class="line-block">
<div class="line">dict(min=-0.5,</div>
<div class="line-block">
<div class="line">max=0.5,)</div>
<div class="line"><br /></div>
</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Limit for range of target</div>
<div class="line">policy smoothing noise,</div>
<div class="line">aka. noise_clip.</div>
</div>
</td>
<td><div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.-</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">ignore_done</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Determine whether to ignore</div>
<div class="line">done flag.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Use ignore_done only</div>
<div class="line">in halfcheetah env.</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>11</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.-</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">target_theta</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.005</p></td>
<td><div class="line-block">
<div class="line">Used for soft update of the</div>
<div class="line">target network.</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">aka. Interpolation</div>
<div class="line">factor in polyak aver</div>
<div class="line">-aging for target</div>
<div class="line">networks.</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>12</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect.-</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">noise_sigma</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.1</p></td>
<td><div class="line-block">
<div class="line">Used for add noise during co-</div>
<div class="line">llection, through controlling</div>
<div class="line">the sigma of distribution</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">Sample noise from dis</div>
<div class="line">-tribution, Ornstein-</div>
<div class="line">Uhlenbeck process in</div>
<div class="line">DDPG paper, Gaussian</div>
<div class="line">process in ours.</div>
</div>
</td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.TD3Policy._forward_collect">
<span class="sig-name descname"><span class="pre">_forward_collect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#ding.policy.TD3Policy._forward_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward function of collect mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action), </dt><dd><p>values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): Dict type data, including at least inferred action according to input obs.</p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">logit</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.TD3Policy._forward_eval">
<span class="sig-name descname"><span class="pre">_forward_eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#ding.policy.TD3Policy._forward_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward function of eval mode, similar to <code class="docutils literal notranslate"><span class="pre">self._forward_collect</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action), </dt><dd><p>values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): The dict of predicting action for the interaction with env.</p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">logit</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.TD3Policy._forward_learn">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#ding.policy.TD3Policy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward and backward function of learn mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type data, including at least [‘obs’, ‘action’, ‘reward’, ‘next_obs’]</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Including at least actor and critic lr, different losses.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.TD3Policy._init_collect">
<span class="sig-name descname"><span class="pre">_init_collect</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#ding.policy.TD3Policy._init_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init traj and unroll length, collect model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.TD3Policy._init_eval">
<span class="sig-name descname"><span class="pre">_init_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#ding.policy.TD3Policy._init_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init eval model. Unlike learn and collect model, eval model does not need noise.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.TD3Policy._init_learn">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#ding.policy.TD3Policy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Learn mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init actor and critic optimizers, algorithm config, main and target models.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.TD3Policy._monitor_vars_learn">
<span class="sig-name descname"><span class="pre">_monitor_vars_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/td3.html#TD3Policy._monitor_vars_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.TD3Policy._monitor_vars_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return variables’ names if variables are to used in monitor.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>vars (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[str]</span></code>): Variables’ name list.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.TD3Policy._process_transition">
<span class="sig-name descname"><span class="pre">_process_transition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_output</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timestep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">collections.namedtuple</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#ding.policy.TD3Policy._process_transition" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Generate dict type transition data from inputs.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>obs (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>): Env observation</p></li>
<li><p>model_output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Output of collect model, including at least [‘action’]</p></li>
<li><dl class="simple">
<dt>timestep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">namedtuple</span></code>): Output after env step, including at least [‘obs’, ‘reward’, ‘done’] </dt><dd><p>(here ‘obs’ indicates obs after env step, i.e. next_obs).</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Return:</dt><dd><ul class="simple">
<li><p>transition (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type transition data.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="sac">
<h2>SAC<a class="headerlink" href="#sac" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/policy/sac.py</span></code> for more details.</p>
<section id="sacpolicy">
<h3>SACPolicy<a class="headerlink" href="#sacpolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.SACPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">SACPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/sac.html#SACPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.SACPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Policy class of continuous SAC algorithm. Paper link: <a class="reference external" href="https://arxiv.org/pdf/1801.01290.pdf">https://arxiv.org/pdf/1801.01290.pdf</a></p>
</dd>
<dt>Config:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 2%" />
<col style="width: 20%" />
<col style="width: 8%" />
<col style="width: 13%" />
<col style="width: 33%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Symbol</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Other</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">type</span></code></p></td>
<td><p>str</p></td>
<td><p>sac</p></td>
<td><div class="line-block">
<div class="line">RL policy register name, refer</div>
<div class="line">to registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line">this arg is optional,</div>
<div class="line">a placeholder</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cuda</span></code></p></td>
<td><p>bool</p></td>
<td><p>True</p></td>
<td><div class="line-block">
<div class="line">Whether to use cuda for network</div>
</div>
</td>
<td><div class="line-block">
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">on_policy</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">SAC is an off-policy</div>
<div class="line">algorithm.</div>
</div>
</td>
<td><div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">priority</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to use priority</div>
<div class="line">sampling in buffer.</div>
</div>
</td>
<td><div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">priority_IS_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">weight</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use Importance Sampling</div>
<div class="line">weight to correct biased update</div>
</div>
</td>
<td><div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">random_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect_size</span></code></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>int</p></td>
<td><p>10000</p></td>
<td><div class="line-block">
<div class="line">Number of randomly collected</div>
<div class="line">training samples in replay</div>
<div class="line">buffer when training starts.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Default to 10000 for</div>
<div class="line">SAC, 25000 for DDPG/</div>
<div class="line">TD3.</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate_q</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>3e-4</p></td>
<td><div class="line-block">
<div class="line">Learning rate for soft q</div>
<div class="line">network.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Defalut to 1e-3</div>
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate_policy</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>3e-4</p></td>
<td><div class="line-block">
<div class="line">Learning rate for policy</div>
<div class="line">network.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Defalut to 1e-3</div>
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.alpha</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.2</p></td>
<td><div class="line-block">
<div class="line">Entropy regularization</div>
<div class="line">coefficient.</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">alpha is initiali-</div>
<div class="line">zation for auto</div>
<div class="line"><cite>alpha</cite>, when</div>
<div class="line">auto_alpha is True</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">auto_alpha</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Determine whether to use</div>
<div class="line">auto temperature parameter</div>
<div class="line"><cite>alpha</cite>.</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">Temperature parameter</div>
<div class="line">determines the</div>
<div class="line">relative importance</div>
<div class="line">of the entropy term</div>
<div class="line">against the reward.</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>11</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.-</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">ignore_done</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Determine whether to ignore</div>
<div class="line">done flag.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Use ignore_done only</div>
<div class="line">in env like Pendulum</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>12</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.-</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">target_theta</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.005</p></td>
<td><div class="line-block">
<div class="line">Used for soft update of the</div>
<div class="line">target network.</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">aka. Interpolation</div>
<div class="line">factor in polyak aver</div>
<div class="line">aging for target</div>
<div class="line">networks.</div>
</div>
</td>
</tr>
</tbody>
</table>
</dd>
</dl>
</dd></dl>

</section>
<section id="discretesacpolicy">
<h3>DiscreteSACPolicy<a class="headerlink" href="#discretesacpolicy" title="Permalink to this headline">¶</a></h3>
</section>
<section id="sqilsacpolicy">
<h3>SQILSACPolicy<a class="headerlink" href="#sqilsacpolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.SQILSACPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">SQILSACPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/sac.html#SQILSACPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.SQILSACPolicy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
</section>
<section id="r2d2">
<h2>R2D2<a class="headerlink" href="#r2d2" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/policy/r2d2.py</span></code> for more details.</p>
<section id="r2d2policy">
<h3>R2D2Policy<a class="headerlink" href="#r2d2policy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.R2D2Policy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">R2D2Policy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/r2d2.html#R2D2Policy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.R2D2Policy" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Policy class of R2D2, from paper <cite>Recurrent Experience Replay in Distributed Reinforcement Learning</cite> .
R2D2 proposes that several tricks should be used to improve upon DRQN,
namely some recurrent experience replay tricks such as burn-in.</p>
</dd>
<dt>Config:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 2%" />
<col style="width: 19%" />
<col style="width: 7%" />
<col style="width: 13%" />
<col style="width: 37%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Symbol</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Other(Shape)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">type</span></code></p></td>
<td><p>str</p></td>
<td><p>dqn</p></td>
<td><div class="line-block">
<div class="line">RL policy register name, refer to</div>
<div class="line">registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line">This arg is optional,</div>
<div class="line">a placeholder</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cuda</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to use cuda for network</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This arg can be diff-</div>
<div class="line">erent from modes</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">on_policy</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether the RL algorithm is on-policy</div>
<div class="line">or off-policy</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">priority</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use priority(PER)</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Priority sample,</div>
<div class="line">update priority</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">priority_IS</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_weight</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use Importance Sampling Weight</div>
<div class="line">to correct biased update. If True,</div>
<div class="line">priority must be True.</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">discount_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">factor</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.997,
[0.95, 0.999]</p></td>
<td><div class="line-block">
<div class="line">Reward’s future discount factor, aka.</div>
<div class="line">gamma</div>
</div>
</td>
<td><div class="line-block">
<div class="line">May be 1 when sparse</div>
<div class="line">reward env</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nstep</span></code></p></td>
<td><p>int</p></td>
<td><p>3,
[3, 5]</p></td>
<td><div class="line-block">
<div class="line">N-step reward discount sum for target</div>
<div class="line">q_value estimation</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">burnin_step</span></code></p></td>
<td><p>int</p></td>
<td><p>2</p></td>
<td><div class="line-block">
<div class="line">The timestep of burnin operation,</div>
<div class="line">which is designed to RNN hidden state</div>
<div class="line">difference caused by off-policy</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.update</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">per_collect</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>1</p></td>
<td><div class="line-block">
<div class="line">How many updates(iterations) to train</div>
<div class="line">after collector’s one collection. Only</div>
<div class="line">valid in serial training</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This args can be vary</div>
<div class="line">from envs. Bigger val</div>
<div class="line">means more off-policy</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.batch_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">size</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>64</p></td>
<td><div class="line-block">
<div class="line">The number of samples of an iteration</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>11</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.001</p></td>
<td><div class="line-block">
<div class="line">Gradient step length of an iteration.</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>12</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.value_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">rescale</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>True</p></td>
<td><div class="line-block">
<div class="line">Whether use value_rescale function for</div>
<div class="line">predicted value</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>13</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.target_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">update_freq</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>100</p></td>
<td><div class="line-block">
<div class="line">Frequence of target network update.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Hard(assign) update</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>14</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.ignore_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">done</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether ignore done for target value</div>
<div class="line">calculation.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Enable it for some</div>
<div class="line">fake termination env</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>15</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">collect.n_sample</span></code></p></td>
<td><p>int</p></td>
<td><p>[8, 128]</p></td>
<td><div class="line-block">
<div class="line">The number of training samples of a</div>
<div class="line">call of collector.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">It varies from</div>
<div class="line">different envs</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>16</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect.unroll</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_len</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>1</p></td>
<td><div class="line-block">
<div class="line">unroll length of an iteration</div>
</div>
</td>
<td><div class="line-block">
<div class="line">In RNN, unroll_len&gt;1</div>
</div>
</td>
</tr>
</tbody>
</table>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.R2D2Policy._forward_collect">
<span class="sig-name descname"><span class="pre">_forward_collect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../_modules/ding/policy/r2d2.html#R2D2Policy._forward_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.R2D2Policy._forward_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward function for collect mode with eps_greedy</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action), </dt><dd><p>values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p>
</dd>
</dl>
</li>
<li><p>eps (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): epsilon value for exploration, which is decayed by collected env step.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): Dict type data, including at least inferred action according to input obs.</p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.R2D2Policy._forward_learn">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/r2d2.html#R2D2Policy._forward_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.R2D2Policy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward and backward function of learn mode.
Acquire the data, calculate the loss and optimize learner model.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type data, including at least </dt><dd><p>[‘main_obs’, ‘target_obs’, ‘burnin_obs’, ‘action’, ‘reward’, ‘done’, ‘weight’]</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Including cur_lr and total_loss</dt><dd><ul>
<li><p>cur_lr (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): Current learning rate</p></li>
<li><p>total_loss (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The calculated loss</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.R2D2Policy._get_train_sample">
<span class="sig-name descname"><span class="pre">_get_train_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/r2d2.html#R2D2Policy._get_train_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.R2D2Policy._get_train_sample" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Get the trajectory and the n step return data, then sample from the n_step return data</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code>): The trajectory’s cache</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>samples (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): The training samples generated</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.R2D2Policy._init_collect">
<span class="sig-name descname"><span class="pre">_init_collect</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/r2d2.html#R2D2Policy._init_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.R2D2Policy._init_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init traj and unroll length, collect model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.R2D2Policy._init_learn">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/r2d2.html#R2D2Policy._init_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.R2D2Policy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Init the learner model of R2D2Policy</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>learning_rate (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The learning rate fo the optimizer</p></li>
<li><p>gamma (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The discount factor</p></li>
<li><p>nstep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The num of n step return</p></li>
<li><p>value_rescale (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use value rescaled loss in algorithm</p></li>
<li><p>burnin_step (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The num of step of burnin</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The _init_learn method takes the argument from the self._cfg.learn in the config file</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.R2D2Policy._process_transition">
<span class="sig-name descname"><span class="pre">_process_transition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_output</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timestep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">collections.namedtuple</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../_modules/ding/policy/r2d2.html#R2D2Policy._process_transition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.R2D2Policy._process_transition" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Generate dict type transition data from inputs.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>obs (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>): Env observation</p></li>
<li><p>model_output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Output of collect model, including at least [‘action’, ‘prev_state’]</p></li>
<li><dl class="simple">
<dt>timestep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">namedtuple</span></code>): Output after env step, including at least [‘reward’, ‘done’] </dt><dd><p>(here ‘obs’ indicates obs after env step).</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>transition (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type transition data.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="impala">
<h2>IMPALA<a class="headerlink" href="#impala" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/policy/impala.py</span></code> for more details.</p>
<section id="impalapolicy">
<h3>IMPALAPolicy<a class="headerlink" href="#impalapolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.IMPALAPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">IMPALAPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/impala.html#IMPALAPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.IMPALAPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Policy class of IMPALA algorithm.</p>
</dd>
<dt>Config:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 2%" />
<col style="width: 19%" />
<col style="width: 7%" />
<col style="width: 13%" />
<col style="width: 37%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Symbol</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Other(Shape)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">type</span></code></p></td>
<td><p>str</p></td>
<td><p>impala</p></td>
<td><div class="line-block">
<div class="line">RL policy register name, refer to</div>
<div class="line">registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line">this arg is optional,</div>
<div class="line">a placeholder</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cuda</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to use cuda for network</div>
</div>
</td>
<td><div class="line-block">
<div class="line">this arg can be diff-</div>
<div class="line">erent from modes</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">on_policy</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether the RL algorithm is on-policy</div>
<div class="line">or off-policy</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><ol class="arabic simple" start="4">
<li></li>
</ol>
</td>
<td><p><code class="docutils literal notranslate"><span class="pre">priority</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use priority(PER)</div>
</div>
</td>
<td><div class="line-block">
<div class="line">priority sample,</div>
<div class="line">update priority</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">priority_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">IS_weight</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use Importance Sampling Weight</div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">If True, priority</div>
<div class="line">must be True</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">unroll_len</span></code></p></td>
<td><p>int</p></td>
<td><p>32</p></td>
<td><div class="line-block">
<div class="line">trajectory length to calculate v-trace</div>
<div class="line">target</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.update</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">per_collect</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>4</p></td>
<td><div class="line-block">
<div class="line">How many updates(iterations) to train</div>
<div class="line">after collector’s one collection. Only</div>
<div class="line">valid in serial training</div>
</div>
</td>
<td><div class="line-block">
<div class="line">this args can be vary</div>
<div class="line">from envs. Bigger val</div>
<div class="line">means more off-policy</div>
</div>
</td>
</tr>
</tbody>
</table>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.IMPALAPolicy._forward_collect">
<span class="sig-name descname"><span class="pre">_forward_collect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/impala.html#IMPALAPolicy._forward_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.IMPALAPolicy._forward_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Forward computation graph of collect mode(collect training data).</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting </p></li>
</ul>
<p>action, values are torch.Tensor or np.ndarray or dict/list combinations,keys are env_id indicated by integer.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Dict[str,Any]]</span></code>): Dict of predicting policy_output(logit, action) for each env.</p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">logit</span></code>, <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.IMPALAPolicy._forward_eval">
<span class="sig-name descname"><span class="pre">_forward_eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/impala.html#IMPALAPolicy._forward_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.IMPALAPolicy._forward_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward computation graph of eval mode(evaluate policy performance), at most cases, it is similar to <code class="docutils literal notranslate"><span class="pre">self._forward_collect</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action), </dt><dd><p>values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): The dict of predicting action for the interaction with env.</p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">logit</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.IMPALAPolicy._forward_learn">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/impala.html#IMPALAPolicy._forward_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.IMPALAPolicy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Forward computation graph of learn mode(updating policy).</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[Dict[str,</span> <span class="pre">Any]]</span></code>): List type data, a list of data for training. Each list element is a </p></li>
</ul>
<dl class="simple">
<dt>dict, whose values are torch.Tensor or np.ndarray or dict/list combinations, keys include at least ‘obs’,</dt><dd><p>‘next_obs’, ‘logit’, ‘action’, ‘reward’, ‘done’</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a info dict indicated training result, which will be </dt><dd><p>recorded in text log and tensorboard, values are python scalar or a list of scalars.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>ArgumentsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">obs</span></code>, <code class="docutils literal notranslate"><span class="pre">action</span></code>, <code class="docutils literal notranslate"><span class="pre">reward</span></code>, <code class="docutils literal notranslate"><span class="pre">next_obs</span></code>, <code class="docutils literal notranslate"><span class="pre">done</span></code></p></li>
<li><p>optional: ‘collect_iter’, ‘replay_unique_id’, ‘replay_buffer_idx’, ‘priority’, ‘staleness’, ‘use’, ‘IS’</p></li>
</ul>
</dd>
<dt>ReturnsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">cur_lr</span></code>, <code class="docutils literal notranslate"><span class="pre">total_loss</span></code>, <code class="docutils literal notranslate"><span class="pre">policy_loss`,``value_loss</span></code>,``entropy_loss``</p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">priority</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.IMPALAPolicy._get_train_sample">
<span class="sig-name descname"><span class="pre">_get_train_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/impala.html#IMPALAPolicy._get_train_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.IMPALAPolicy._get_train_sample" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>For a given trajectory(transitions, a list of transition) data, process it into a list of sample that can be used for training directly.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[Dict[str,</span> <span class="pre">Any]</span></code>): The trajectory data(a list of transition), each element is the same </dt><dd><p>format as the return value of <code class="docutils literal notranslate"><span class="pre">self._process_transition</span></code> method.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>samples (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): List of training samples.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We will vectorize <code class="docutils literal notranslate"><span class="pre">process_transition</span></code> and <code class="docutils literal notranslate"><span class="pre">get_train_sample</span></code> method in the following release version. And the user can customize the this data processing procedure by overriding this two methods and collector itself.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.IMPALAPolicy._init_collect">
<span class="sig-name descname"><span class="pre">_init_collect</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/impala.html#IMPALAPolicy._init_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.IMPALAPolicy._init_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>, initialize algorithm arguments and collect_model.
Use multinomial_sample to choose action.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.IMPALAPolicy._init_eval">
<span class="sig-name descname"><span class="pre">_init_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/impala.html#IMPALAPolicy._init_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.IMPALAPolicy._init_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>, initialize eval_model,
and use argmax_sample to choose action.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.IMPALAPolicy._init_learn">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/impala.html#IMPALAPolicy._init_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.IMPALAPolicy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Learn mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Initialize the optimizer, algorithm config and main model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.IMPALAPolicy._monitor_vars_learn">
<span class="sig-name descname"><span class="pre">_monitor_vars_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/impala.html#IMPALAPolicy._monitor_vars_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.IMPALAPolicy._monitor_vars_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return this algorithm default model setting for demonstration.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>model_info (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Tuple[str,</span> <span class="pre">List[str]]</span></code>): model name and mode import_names</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The user can define and use customized network model but must obey the same interface definition indicated by import_names path. For IMPALA, <code class="docutils literal notranslate"><span class="pre">ding.model.interface.IMPALA</span></code></p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.IMPALAPolicy._process_transition">
<span class="sig-name descname"><span class="pre">_process_transition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_output</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timestep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">collections.namedtuple</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/impala.html#IMPALAPolicy._process_transition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.IMPALAPolicy._process_transition" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Generate dict type transition data from inputs.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>obs (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>): Env observation,can be torch.Tensor or np.ndarray or dict/list combinations.</p></li>
<li><p>model_output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Output of collect model, including [‘logit’,’action’]</p></li>
<li><dl class="simple">
<dt>timestep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">namedtuple</span></code>): Output after env step, including at least [‘obs’, ‘reward’, ‘done’]</dt><dd><p>(here ‘obs’ indicates obs after env step).</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>transition (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type transition data, including at least [‘obs’,’next_obs’, ‘logit’,</p></li>
</ul>
<p>‘action’,’reward’, ‘done’]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="qmix">
<h2>QMIX<a class="headerlink" href="#qmix" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/policy/qmix.py</span></code> for more details.</p>
<section id="qmixpolicy">
<h3>QMIXPolicy<a class="headerlink" href="#qmixpolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.QMIXPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">QMIXPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/qmix.html#QMIXPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.QMIXPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Policy class of QMIX algorithm. QMIX is a multi model reinforcement learning algorithm,             you can view the paper in the following link <a class="reference external" href="https://arxiv.org/abs/1803.11485">https://arxiv.org/abs/1803.11485</a></p>
</dd>
<dt>Interface:</dt><dd><p>_init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn             _init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval             _reset_eval, _get_train_sample, default_model</p>
</dd>
<dt>Config:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 2%" />
<col style="width: 19%" />
<col style="width: 7%" />
<col style="width: 13%" />
<col style="width: 37%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Symbol</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Other(Shape)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">type</span></code></p></td>
<td><p>str</p></td>
<td><p>qmix</p></td>
<td><div class="line-block">
<div class="line">RL policy register name, refer to</div>
<div class="line">registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line">this arg is optional,</div>
<div class="line">a placeholder</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cuda</span></code></p></td>
<td><p>bool</p></td>
<td><p>True</p></td>
<td><div class="line-block">
<div class="line">Whether to use cuda for network</div>
</div>
</td>
<td><div class="line-block">
<div class="line">this arg can be diff-</div>
<div class="line">erent from modes</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">on_policy</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether the RL algorithm is on-policy</div>
<div class="line">or off-policy</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><ol class="arabic simple" start="4">
<li></li>
</ol>
</td>
<td><p><code class="docutils literal notranslate"><span class="pre">priority</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use priority(PER)</div>
</div>
</td>
<td><div class="line-block">
<div class="line">priority sample,</div>
<div class="line">update priority</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">priority_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">IS_weight</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use Importance Sampling</div>
<div class="line">Weight to correct biased update.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">IS weight</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.update_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">per_collect</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>20</p></td>
<td><div class="line-block">
<div class="line">How many updates(iterations) to train</div>
<div class="line">after collector’s one collection. Only</div>
<div class="line">valid in serial training</div>
</div>
</td>
<td><div class="line-block">
<div class="line">this args can be vary</div>
<div class="line">from envs. Bigger val</div>
<div class="line">means more off-policy</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.target_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">update_theta</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.001</p></td>
<td><div class="line-block">
<div class="line">Target network update momentum</div>
<div class="line">parameter.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">between[0,1]</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.discount</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_factor</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.99</p></td>
<td><div class="line-block">
<div class="line">Reward’s future discount factor, aka.</div>
<div class="line">gamma</div>
</div>
</td>
<td><div class="line-block">
<div class="line">may be 1 when sparse</div>
<div class="line">reward env</div>
</div>
</td>
</tr>
</tbody>
</table>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.QMIXPolicy._forward_collect">
<span class="sig-name descname"><span class="pre">_forward_collect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../_modules/ding/policy/qmix.html#QMIXPolicy._forward_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.QMIXPolicy._forward_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward function for collect mode with eps_greedy</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action), </dt><dd><p>values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p>
</dd>
</dl>
</li>
<li><p>eps (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): epsilon value for exploration, which is decayed by collected env step.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): Dict type data, including at least inferred action according to input obs.</p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.QMIXPolicy._forward_learn">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/qmix.html#QMIXPolicy._forward_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.QMIXPolicy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward and backward function of learn mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a batch of data for training, values are torch.Tensor or </dt><dd><p>np.ndarray or dict/list combinations.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a info dict indicated training result, which will be </dt><dd><p>recorded in text log and tensorboard, values are python scalar or a list of scalars.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>ArgumentsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">obs</span></code>, <code class="docutils literal notranslate"><span class="pre">next_obs</span></code>, <code class="docutils literal notranslate"><span class="pre">action</span></code>, <code class="docutils literal notranslate"><span class="pre">reward</span></code>, <code class="docutils literal notranslate"><span class="pre">weight</span></code>, <code class="docutils literal notranslate"><span class="pre">prev_state</span></code>, <code class="docutils literal notranslate"><span class="pre">done</span></code></p></li>
</ul>
</dd>
<dt>ReturnsKeys:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>necessary: <code class="docutils literal notranslate"><span class="pre">cur_lr</span></code>, <code class="docutils literal notranslate"><span class="pre">total_loss</span></code></dt><dd><ul>
<li><p>cur_lr (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): Current learning rate</p></li>
<li><p>total_loss (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The calculated loss</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.QMIXPolicy._get_train_sample">
<span class="sig-name descname"><span class="pre">_get_train_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/qmix.html#QMIXPolicy._get_train_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.QMIXPolicy._get_train_sample" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Get the train sample from trajectory.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code>): The trajectory’s cache</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>samples (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): The training samples generated</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.QMIXPolicy._init_collect">
<span class="sig-name descname"><span class="pre">_init_collect</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/qmix.html#QMIXPolicy._init_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.QMIXPolicy._init_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init traj and unroll length, collect model.
Enable the eps_greedy_sample and the hidden_state plugin.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.QMIXPolicy._init_learn">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/qmix.html#QMIXPolicy._init_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.QMIXPolicy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Learn mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init the learner model of QMIXPolicy</p>
</dd>
<dt>Arguments:</dt><dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>The _init_learn method takes the argument from the self._cfg.learn in the config file</p>
</div>
<ul class="simple">
<li><p>learning_rate (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The learning rate fo the optimizer</p></li>
<li><p>gamma (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The discount factor</p></li>
<li><p>agent_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): Since this is a multi-agent algorithm, we need to input the agent num.</p></li>
<li><p>batch_size (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): Need batch size info to init hidden_state plugins</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.QMIXPolicy._load_state_dict_learn">
<span class="sig-name descname"><span class="pre">_load_state_dict_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/qmix.html#QMIXPolicy._load_state_dict_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.QMIXPolicy._load_state_dict_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Load the state_dict variable into policy learn mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): the dict of policy learn state saved before.</p></li>
</ul>
</dd>
</dl>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If you want to only load some parts of model, you can simply set the <code class="docutils literal notranslate"><span class="pre">strict</span></code> argument in             load_state_dict to <code class="docutils literal notranslate"><span class="pre">False</span></code>, or refer to <code class="docutils literal notranslate"><span class="pre">ding.torch_utils.checkpoint_helper</span></code> for more             complicated operation.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.QMIXPolicy._monitor_vars_learn">
<span class="sig-name descname"><span class="pre">_monitor_vars_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/qmix.html#QMIXPolicy._monitor_vars_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.QMIXPolicy._monitor_vars_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return variables’ name if variables are to used in monitor.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>vars (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[str]</span></code>): Variables’ name list.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.QMIXPolicy._process_transition">
<span class="sig-name descname"><span class="pre">_process_transition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_output</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timestep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">collections.namedtuple</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../_modules/ding/policy/qmix.html#QMIXPolicy._process_transition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.QMIXPolicy._process_transition" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Generate dict type transition data from inputs.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>obs (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>): Env observation</p></li>
<li><p>model_output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Output of collect model, including at least [‘action’, ‘prev_state’]</p></li>
<li><dl class="simple">
<dt>timestep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">namedtuple</span></code>): Output after env step, including at least [‘obs’, ‘reward’, ‘done’]</dt><dd><p>(here ‘obs’ indicates obs after env step).</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>transition (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type transition data, including ‘obs’, ‘next_obs’, ‘prev_state’,</dt><dd><p>‘action’, ‘reward’, ‘done’</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.QMIXPolicy._reset_collect">
<span class="sig-name descname"><span class="pre">_reset_collect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/qmix.html#QMIXPolicy._reset_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.QMIXPolicy._reset_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Reset collect model to the state indicated by data_id</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data_id (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Optional[List[int]]</span></code>): The id that store the state and we will reset</dt><dd><p>the model state to the state indicated by data_id</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.QMIXPolicy._reset_eval">
<span class="sig-name descname"><span class="pre">_reset_eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/qmix.html#QMIXPolicy._reset_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.QMIXPolicy._reset_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Reset eval model to the state indicated by data_id</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data_id (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Optional[List[int]]</span></code>): The id that store the state and we will reset</dt><dd><p>the model state to the state indicated by data_id</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.QMIXPolicy._reset_learn">
<span class="sig-name descname"><span class="pre">_reset_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/qmix.html#QMIXPolicy._reset_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.QMIXPolicy._reset_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Reset learn model to the state indicated by data_id</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data_id (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Optional[List[int]]</span></code>): The id that store the state and we will reset</dt><dd><p>the model state to the state indicated by data_id</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.QMIXPolicy._state_dict_learn">
<span class="sig-name descname"><span class="pre">_state_dict_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/qmix.html#QMIXPolicy._state_dict_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.QMIXPolicy._state_dict_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return the state_dict of learn mode, usually including model and optimizer.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): the dict of current policy learn state, for saving and restoring.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.QMIXPolicy.default_model">
<span class="sig-name descname"><span class="pre">default_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/qmix.html#QMIXPolicy.default_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.QMIXPolicy.default_model" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return this algorithm default model setting for demonstration.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>model_info (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Tuple[str,</span> <span class="pre">List[str]]</span></code>): model name and mode import_names</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The user can define and use customized network model but must obey the same inferface definition indicated             by import_names path. For QMIX, <code class="docutils literal notranslate"><span class="pre">ding.model.qmix.qmix</span></code></p>
</div>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="cql">
<h2>CQL<a class="headerlink" href="#cql" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/policy/cql.py</span></code> for more details.</p>
<section id="cqlpolicy">
<h3>CQLPolicy<a class="headerlink" href="#cqlpolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.CQLPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">CQLPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/cql.html#CQLPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.CQLPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Policy class of CQL algorithm.</p>
</dd>
<dt>Config:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 2%" />
<col style="width: 20%" />
<col style="width: 8%" />
<col style="width: 13%" />
<col style="width: 33%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Symbol</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Other(Shape)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">type</span></code></p></td>
<td><p>str</p></td>
<td><p>td3</p></td>
<td><div class="line-block">
<div class="line">RL policy register name, refer</div>
<div class="line">to registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line">this arg is optional,</div>
<div class="line">a placeholder</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cuda</span></code></p></td>
<td><p>bool</p></td>
<td><p>True</p></td>
<td><div class="line-block">
<div class="line">Whether to use cuda for network</div>
</div>
</td>
<td><div class="line-block">
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">random_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect_size</span></code></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>int</p></td>
<td><p>10000</p></td>
<td><div class="line-block">
<div class="line">Number of randomly collected</div>
<div class="line">training samples in replay</div>
<div class="line">buffer when training starts.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Default to 10000 for</div>
<div class="line">SAC, 25000 for DDPG/</div>
<div class="line">TD3.</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">model.policy_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">embedding_size</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>256</p></td>
<td><div class="line-block">
<div class="line">Linear layer size for policy</div>
<div class="line">network.</div>
</div>
</td>
<td><div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">model.soft_q_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">embedding_size</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>256</p></td>
<td><div class="line-block">
<div class="line">Linear layer size for soft q</div>
<div class="line">network.</div>
</div>
</td>
<td><div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">model.value_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">embedding_size</span></code></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>int</p></td>
<td><p>256</p></td>
<td><div class="line-block">
<div class="line">Linear layer size for value</div>
<div class="line">network.</div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">Defalut to None when</div>
<div class="line">model.value_network</div>
<div class="line">is False.</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate_q</span></code></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>float</p></td>
<td><p>3e-4</p></td>
<td><div class="line-block">
<div class="line">Learning rate for soft q</div>
<div class="line">network.</div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">Defalut to 1e-3, when</div>
<div class="line">model.value_network</div>
<div class="line">is True.</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate_policy</span></code></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>float</p></td>
<td><p>3e-4</p></td>
<td><div class="line-block">
<div class="line">Learning rate for policy</div>
<div class="line">network.</div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">Defalut to 1e-3, when</div>
<div class="line">model.value_network</div>
<div class="line">is True.</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate_value</span></code></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>float</p></td>
<td><p>3e-4</p></td>
<td><div class="line-block">
<div class="line">Learning rate for policy</div>
<div class="line">network.</div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">Defalut to None when</div>
<div class="line">model.value_network</div>
<div class="line">is False.</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.alpha</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.2</p></td>
<td><div class="line-block">
<div class="line">Entropy regularization</div>
<div class="line">coefficient.</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">alpha is initiali-</div>
<div class="line">zation for auto</div>
<div class="line"><cite>alpha</cite>, when</div>
<div class="line">auto_alpha is True</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>11</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.repara_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">meterization</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>True</p></td>
<td><div class="line-block">
<div class="line">Determine whether to use</div>
<div class="line">reparameterization trick.</div>
</div>
</td>
<td><div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>12</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">auto_alpha</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Determine whether to use</div>
<div class="line">auto temperature parameter</div>
<div class="line"><cite>alpha</cite>.</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">Temperature parameter</div>
<div class="line">determines the</div>
<div class="line">relative importance</div>
<div class="line">of the entropy term</div>
<div class="line">against the reward.</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>13</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.-</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">ignore_done</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Determine whether to ignore</div>
<div class="line">done flag.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Use ignore_done only</div>
<div class="line">in halfcheetah env.</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>14</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.-</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">target_theta</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.005</p></td>
<td><div class="line-block">
<div class="line">Used for soft update of the</div>
<div class="line">target network.</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">aka. Interpolation</div>
<div class="line">factor in polyak aver</div>
<div class="line">aging for target</div>
<div class="line">networks.</div>
</div>
</td>
</tr>
</tbody>
</table>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.CQLPolicy._forward_learn">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/cql.html#CQLPolicy._forward_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.CQLPolicy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward and backward function of learn mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type data, including at least [‘obs’, ‘action’, ‘reward’, ‘next_obs’]</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Including current lr and loss.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.CQLPolicy._init_learn">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/cql.html#CQLPolicy._init_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.CQLPolicy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Learn mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init q, value and policy’s optimizers, algorithm config, main and target models.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="discretecqlpolicy">
<h3>DiscreteCQLPolicy<a class="headerlink" href="#discretecqlpolicy" title="Permalink to this headline">¶</a></h3>
</section>
</section>
<section id="decisiontransformer">
<h2>DecisionTransformer<a class="headerlink" href="#decisiontransformer" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/policy/dt.py</span></code> for more details.</p>
<section id="dtpolicy">
<h3>DTPolicy<a class="headerlink" href="#dtpolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.DTPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">DTPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/dt.html#DTPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DTPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Policy class of Decision Transformer algorithm in discrete environments.
Paper link: <a class="reference external" href="https://arxiv.org/abs/2106.01345">https://arxiv.org/abs/2106.01345</a></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DTPolicy._forward_learn">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/dt.html#DTPolicy._forward_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DTPolicy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward and backward function of learn mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type data, including at least [‘obs’, ‘action’, ‘reward’, ‘next_obs’]</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Including current lr and loss.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DTPolicy._init_eval">
<span class="sig-name descname"><span class="pre">_init_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/dt.html#DTPolicy._init_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DTPolicy._init_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>, initialize eval_model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.DTPolicy._init_learn">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/dt.html#DTPolicy._init_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.DTPolicy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Learn mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init the optimizer, algorithm config, main and target models.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="pdqn">
<h2>PDQN<a class="headerlink" href="#pdqn" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/policy/pdqn.py</span></code> for more details.</p>
<section id="pdqnpolicy">
<h3>PDQNPolicy<a class="headerlink" href="#pdqnpolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.PDQNPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">PDQNPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/pdqn.html#PDQNPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PDQNPolicy" title="Permalink to this definition">¶</a></dt>
<dd><p>:
Overview:</p>
<blockquote>
<div><p>Policy class of PDQN algorithm, which extends the DQN algorithm on discrete-continuous hybrid action spaces.</p>
</div></blockquote>
<dl>
<dt>Config:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 2%" />
<col style="width: 19%" />
<col style="width: 7%" />
<col style="width: 13%" />
<col style="width: 37%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Symbol</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Other(Shape)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">type</span></code></p></td>
<td><p>str</p></td>
<td><p>pdqn</p></td>
<td><div class="line-block">
<div class="line">RL policy register name, refer to</div>
<div class="line">registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line">This arg is optional,</div>
<div class="line">a placeholder</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cuda</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to use cuda for network</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This arg can be diff-</div>
<div class="line">erent from modes</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">on_policy</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether the RL algorithm is on-policy</div>
<div class="line">or off-policy</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This value is always</div>
<div class="line">False for PDQN</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">priority</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use priority(PER)</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Priority sample,</div>
<div class="line">update priority</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">priority_IS</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_weight</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use Importance Sampling Weight</div>
<div class="line">to correct biased update. If True,</div>
<div class="line">priority must be True.</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">discount_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">factor</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.97,
[0.95, 0.999]</p></td>
<td><div class="line-block">
<div class="line">Reward’s future discount factor, aka.</div>
<div class="line">gamma</div>
</div>
</td>
<td><div class="line-block">
<div class="line">May be 1 when sparse</div>
<div class="line">reward env</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nstep</span></code></p></td>
<td><p>int</p></td>
<td><p>1,
[3, 5]</p></td>
<td><div class="line-block">
<div class="line">N-step reward discount sum for target</div>
<div class="line">q_value estimation</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.update</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">per_collect</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>3</p></td>
<td><div class="line-block">
<div class="line">How many updates(iterations) to train</div>
<div class="line">after collector’s one collection. Only</div>
<div class="line">valid in serial training</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This args can be vary</div>
<div class="line">from envs. Bigger val</div>
<div class="line">means more off-policy</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.batch_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">size</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_gpu</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>64</p></td>
<td><div class="line-block">
<div class="line">The number of samples of an iteration</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>11</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.001</p></td>
<td><div class="line-block">
<div class="line">Gradient step length of an iteration.</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>12</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.target_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">update_freq</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>100</p></td>
<td><div class="line-block">
<div class="line">Frequence of target network update.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Hard(assign) update</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>13</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.ignore_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">done</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether ignore done for target value</div>
<div class="line">calculation.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Enable it for some</div>
<div class="line">fake termination env</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>14</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">collect.n_sample</span></code></p></td>
<td><p>int</p></td>
<td><p>[8, 128]</p></td>
<td><div class="line-block">
<div class="line">The number of training samples of a</div>
<div class="line">call of collector.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">It varies from</div>
<div class="line">different envs</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>15</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect.unroll</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_len</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>1</p></td>
<td><div class="line-block">
<div class="line">unroll length of an iteration</div>
</div>
</td>
<td><div class="line-block">
<div class="line">In RNN, unroll_len&gt;1</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>16</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect.noise</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_sigma</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.1</p></td>
<td><div class="line-block">
<div class="line">add noise to continuous args</div>
<div class="line">during collection</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>17</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">other.eps.type</span></code></div>
</div>
</td>
<td><p>str</p></td>
<td><p>exp</p></td>
<td><div class="line-block">
<div class="line">exploration rate decay type</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Support [‘exp’,</div>
<div class="line">‘linear’].</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>18</p></td>
<td><div class="line-block">
<div class="line"><a href="#id1"><span class="problematic" id="id2">``</span></a>other.eps.</div>
<div class="line-block">
<div class="line">start``</div>
</div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.95</p></td>
<td><div class="line-block">
<div class="line">start value of exploration rate</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[0,1]</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>19</p></td>
<td><div class="line-block">
<div class="line"><a href="#id3"><span class="problematic" id="id4">``</span></a>other.eps.</div>
<div class="line-block">
<div class="line">end``</div>
</div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.05</p></td>
<td><div class="line-block">
<div class="line">end value of exploration rate</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[0,1]</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>20</p></td>
<td><div class="line-block">
<div class="line"><a href="#id5"><span class="problematic" id="id6">``</span></a>other.eps.</div>
<div class="line-block">
<div class="line">decay``</div>
</div>
</div>
</td>
<td><p>int</p></td>
<td><p>10000</p></td>
<td><div class="line-block">
<div class="line">decay length of exploration</div>
</div>
</td>
<td><div class="line-block">
<div class="line">greater than 0. set</div>
<div class="line">decay=10000 means</div>
<div class="line">the exploration rate</div>
<div class="line">decay from start</div>
<div class="line">value to end value</div>
<div class="line">during decay length.</div>
</div>
</td>
</tr>
</tbody>
</table>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PDQNPolicy._forward_collect">
<span class="sig-name descname"><span class="pre">_forward_collect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/pdqn.html#PDQNPolicy._forward_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PDQNPolicy._forward_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward computation graph of collect mode(collect training data), with eps_greedy for exploration.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action),                 values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p></li>
<li><p>eps (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): epsilon value for exploration, which is decayed by collected env step.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): The dict of predicting policy_output(action) for the interaction with                 env and the constructing of transition.</p></li>
</ul>
</dd>
<dt>ArgumentsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">obs</span></code></p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">logit</span></code>, <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PDQNPolicy._forward_eval">
<span class="sig-name descname"><span class="pre">_forward_eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../_modules/ding/policy/pdqn.html#PDQNPolicy._forward_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PDQNPolicy._forward_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward function of eval mode, similar to <code class="docutils literal notranslate"><span class="pre">self._forward_collect</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action), </dt><dd><p>values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): The dict of predicting action for the interaction with env.</p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">logit</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PDQNPolicy._forward_learn">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/pdqn.html#PDQNPolicy._forward_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PDQNPolicy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward computation graph of learn mode(updating policy).</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a batch of data for training, values are torch.Tensor or                 np.ndarray or dict/list combinations.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a info dict indicated training result, which will be                 recorded in text log and tensorboard, values are python scalar or a list of scalars.</p></li>
</ul>
</dd>
<dt>ArgumentsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">obs</span></code>, <code class="docutils literal notranslate"><span class="pre">action</span></code>, <code class="docutils literal notranslate"><span class="pre">reward</span></code>, <code class="docutils literal notranslate"><span class="pre">next_obs</span></code>, <code class="docutils literal notranslate"><span class="pre">done</span></code></p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">value_gamma</span></code>, <code class="docutils literal notranslate"><span class="pre">IS</span></code></p></li>
</ul>
</dd>
<dt>ReturnsKeys:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>necessary: <code class="docutils literal notranslate"><span class="pre">cur_lr</span></code>, <code class="docutils literal notranslate"><span class="pre">q_loss</span></code>, <code class="docutils literal notranslate"><span class="pre">continuous_loss</span></code>,</dt><dd><p><code class="docutils literal notranslate"><span class="pre">q_value</span></code>, <code class="docutils literal notranslate"><span class="pre">priority</span></code>, <code class="docutils literal notranslate"><span class="pre">reward</span></code>, <code class="docutils literal notranslate"><span class="pre">target_q_value</span></code></p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PDQNPolicy._get_train_sample">
<span class="sig-name descname"><span class="pre">_get_train_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/pdqn.html#PDQNPolicy._get_train_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PDQNPolicy._get_train_sample" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>For a given trajectory(transitions, a list of transition) data, process it into a list of sample that             can be used for training directly. A train sample can be a processed transition(DQN with nstep TD)             or some continuous transitions(DRQN).</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[Dict[str,</span> <span class="pre">Any]</span></code>): The trajectory data(a list of transition), each element is the same                 format as the return value of <code class="docutils literal notranslate"><span class="pre">self._process_transition</span></code> method.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>samples (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): The list of training samples.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We will vectorize <code class="docutils literal notranslate"><span class="pre">process_transition</span></code> and <code class="docutils literal notranslate"><span class="pre">get_train_sample</span></code> method in the following release version.             And the user can customize the this data processing procecure by overriding this two methods and collector             itself.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PDQNPolicy._init_collect">
<span class="sig-name descname"><span class="pre">_init_collect</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/pdqn.html#PDQNPolicy._init_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PDQNPolicy._init_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>, initialize algorithm arguments and collect_model,             enable the eps_greedy_sample for exploration.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PDQNPolicy._init_eval">
<span class="sig-name descname"><span class="pre">_init_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/pdqn.html#PDQNPolicy._init_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PDQNPolicy._init_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>, initialize eval_model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PDQNPolicy._init_learn">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/pdqn.html#PDQNPolicy._init_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PDQNPolicy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Learn mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>, initialize the optimizer, algorithm arguments, main             and target model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PDQNPolicy._load_state_dict_learn">
<span class="sig-name descname"><span class="pre">_load_state_dict_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/pdqn.html#PDQNPolicy._load_state_dict_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PDQNPolicy._load_state_dict_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Load the state_dict variable into policy learn mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): the dict of policy learn state saved before.</p></li>
</ul>
</dd>
</dl>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If you want to only load some parts of model, you can simply set the <code class="docutils literal notranslate"><span class="pre">strict</span></code> argument in             load_state_dict to <code class="docutils literal notranslate"><span class="pre">False</span></code>, or refer to <code class="docutils literal notranslate"><span class="pre">ding.torch_utils.checkpoint_helper</span></code> for more             complicated operation.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PDQNPolicy._monitor_vars_learn">
<span class="sig-name descname"><span class="pre">_monitor_vars_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/pdqn.html#PDQNPolicy._monitor_vars_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PDQNPolicy._monitor_vars_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return variables’ names if variables are to used in monitor.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>vars (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[str]</span></code>): Variables’ name list.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PDQNPolicy._process_transition">
<span class="sig-name descname"><span class="pre">_process_transition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_output</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timestep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">collections.namedtuple</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/pdqn.html#PDQNPolicy._process_transition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PDQNPolicy._process_transition" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Generate a transition(e.g.: &lt;s, a, s’, r, d&gt;) for this algorithm training.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>obs (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>): Env observation.</p></li>
<li><p>policy_output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): The output of policy collect mode(<code class="docutils literal notranslate"><span class="pre">self._forward_collect</span></code>),                including at least <code class="docutils literal notranslate"><span class="pre">action</span></code>.</p></li>
<li><p>timestep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">namedtuple</span></code>): The output after env step(execute policy output action), including at                 least <code class="docutils literal notranslate"><span class="pre">obs</span></code>, <code class="docutils literal notranslate"><span class="pre">reward</span></code>, <code class="docutils literal notranslate"><span class="pre">done</span></code>, (here obs indicates obs after env step).</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>transition (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type transition data.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PDQNPolicy._state_dict_learn">
<span class="sig-name descname"><span class="pre">_state_dict_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/pdqn.html#PDQNPolicy._state_dict_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PDQNPolicy._state_dict_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return the state_dict of learn mode, usually including model and optimizer.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): the dict of current policy learn state, for saving and restoring.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.PDQNPolicy.default_model">
<span class="sig-name descname"><span class="pre">default_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/pdqn.html#PDQNPolicy.default_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PDQNPolicy.default_model" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return this algorithm default model setting for demonstration.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>model_info (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Tuple[str,</span> <span class="pre">List[str]]</span></code>): model name and mode import_names</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The user can define and use customized network model but must obey the same inferface definition indicated             by import_names path. For PDQN, <code class="docutils literal notranslate"><span class="pre">ding.model.template.pdqn.PDQN</span></code></p>
</div>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="mdqn">
<h2>MDQN<a class="headerlink" href="#mdqn" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/policy/mdqn.py</span></code> for more details.</p>
<section id="mdqnpolicy">
<h3>MDQNPolicy<a class="headerlink" href="#mdqnpolicy" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.MDQNPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">MDQNPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/mdqn.html#MDQNPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.MDQNPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Policy class of Munchausen DQN algorithm, extended by auxiliary objectives.
Paper link: <a class="reference external" href="https://arxiv.org/abs/2007.14430">https://arxiv.org/abs/2007.14430</a></p>
</dd>
<dt>Config:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 2%" />
<col style="width: 19%" />
<col style="width: 7%" />
<col style="width: 13%" />
<col style="width: 37%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Symbol</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Other(Shape)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">type</span></code></p></td>
<td><p>str</p></td>
<td><p>mdqn</p></td>
<td><div class="line-block">
<div class="line">RL policy register name, refer to</div>
<div class="line">registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line">This arg is optional,</div>
<div class="line">a placeholder</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cuda</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to use cuda for network</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This arg can be diff-</div>
<div class="line">erent from modes</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">on_policy</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether the RL algorithm is on-policy</div>
<div class="line">or off-policy</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">priority</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use priority(PER)</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Priority sample,</div>
<div class="line">update priority</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">priority_IS</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_weight</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use Importance Sampling Weight</div>
<div class="line">to correct biased update. If True,</div>
<div class="line">priority must be True.</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">discount_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">factor</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.97,
[0.95, 0.999]</p></td>
<td><div class="line-block">
<div class="line">Reward’s future discount factor, aka.</div>
<div class="line">gamma</div>
</div>
</td>
<td><div class="line-block">
<div class="line">May be 1 when sparse</div>
<div class="line">reward env</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nstep</span></code></p></td>
<td><p>int</p></td>
<td><p>1,
[3, 5]</p></td>
<td><div class="line-block">
<div class="line">N-step reward discount sum for target</div>
<div class="line">q_value estimation</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.update</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">per_collect</span></code></div>
</div>
<div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">_gpu</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>1</p></td>
<td><div class="line-block">
<div class="line">How many updates(iterations) to train</div>
<div class="line">after collector’s one collection. Only</div>
<div class="line">valid in serial training</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This args can be vary</div>
<div class="line">from envs. Bigger val</div>
<div class="line">means more off-policy</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>10</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.batch_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">size</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>32</p></td>
<td><div class="line-block">
<div class="line">The number of samples of an iteration</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>11</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.001</p></td>
<td><div class="line-block">
<div class="line">Gradient step length of an iteration.</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>12</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.target_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">update_freq</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>2000</p></td>
<td><div class="line-block">
<div class="line">Frequence of target network update.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Hard(assign) update</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>13</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.ignore_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">done</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether ignore done for target value</div>
<div class="line">calculation.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Enable it for some</div>
<div class="line">fake termination env</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>14</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">collect.n_sample</span></code></p></td>
<td><p>int</p></td>
<td><p>4</p></td>
<td><div class="line-block">
<div class="line">The number of training samples of a</div>
<div class="line">call of collector.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">It varies from</div>
<div class="line">different envs</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>15</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect.unroll</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_len</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>1</p></td>
<td><div class="line-block">
<div class="line">unroll length of an iteration</div>
</div>
</td>
<td><div class="line-block">
<div class="line">In RNN, unroll_len&gt;1</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>16</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">other.eps.type</span></code></div>
</div>
</td>
<td><p>str</p></td>
<td><p>exp</p></td>
<td><div class="line-block">
<div class="line">exploration rate decay type</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Support [‘exp’,</div>
<div class="line">‘linear’].</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>17</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">other.eps.</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">start</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.01</p></td>
<td><div class="line-block">
<div class="line">start value of exploration rate</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[0,1]</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>18</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">other.eps.</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">end</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.001</p></td>
<td><div class="line-block">
<div class="line">end value of exploration rate</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[0,1]</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>19</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">other.eps.</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">decay</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>250000</p></td>
<td><div class="line-block">
<div class="line">decay length of exploration</div>
</div>
</td>
<td><div class="line-block">
<div class="line">greater than 0. set</div>
<div class="line">decay=250000 means</div>
<div class="line">the exploration rate</div>
<div class="line">decay from start</div>
<div class="line">value to end value</div>
<div class="line">during decay length.</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>20</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">entropy_tau</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.003</p></td>
<td><div class="line-block">
<div class="line">the ration of entropy in TD loss</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>21</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">alpha</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.9</p></td>
<td><div class="line-block">
<div class="line">the ration of Munchausen term to the</div>
<div class="line">TD loss</div>
</div>
</td>
<td></td>
</tr>
</tbody>
</table>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.MDQNPolicy._forward_learn">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/ding/policy/mdqn.html#MDQNPolicy._forward_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.MDQNPolicy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward computation graph of learn mode(updating policy).</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a batch of data for training, values are torch.Tensor or                 np.ndarray or dict/list combinations.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a info dict indicated training result, which will be                 recorded in text log and tensorboard, values are python scalar or a list of scalars.</p></li>
</ul>
</dd>
<dt>ArgumentsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">obs</span></code>, <code class="docutils literal notranslate"><span class="pre">action</span></code>, <code class="docutils literal notranslate"><span class="pre">reward</span></code>, <code class="docutils literal notranslate"><span class="pre">next_obs</span></code>, <code class="docutils literal notranslate"><span class="pre">done</span></code></p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">value_gamma</span></code>, <code class="docutils literal notranslate"><span class="pre">IS</span></code></p></li>
</ul>
</dd>
<dt>ReturnsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">cur_lr</span></code>, <code class="docutils literal notranslate"><span class="pre">total_loss</span></code>, <code class="docutils literal notranslate"><span class="pre">priority</span></code>, <code class="docutils literal notranslate"><span class="pre">action_gap</span></code>, <code class="docutils literal notranslate"><span class="pre">clip_frac</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.MDQNPolicy._init_learn">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/policy/mdqn.html#MDQNPolicy._init_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.MDQNPolicy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Learn mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>, initialize the optimizer, algorithm arguments, main             and target model.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="policy-factory">
<h2>Policy Factory<a class="headerlink" href="#policy-factory" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/policy/policy_factory.py</span></code> for more details.</p>
<section id="policyfactory">
<h3>PolicyFactory<a class="headerlink" href="#policyfactory" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.PolicyFactory">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">PolicyFactory</span></span><a class="reference internal" href="../_modules/ding/policy/policy_factory.html#PolicyFactory"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.PolicyFactory" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Pure random policy. Only used for initial sample collecting if <cite>cfg.policy.random_collect_size</cite> &gt; 0.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="get-random-policy">
<h3>get_random_policy<a class="headerlink" href="#get-random-policy" title="Permalink to this headline">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="ding.policy.get_random_policy">
<span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">get_random_policy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">easydict.EasyDict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Policy.collect_mode</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseEnvManager</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/policy_factory.html#get_random_policy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.get_random_policy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
</section>
<section id="common-utilities">
<h2>Common Utilities<a class="headerlink" href="#common-utilities" title="Permalink to this headline">¶</a></h2>
<p>Please refer to <code class="docutils literal notranslate"><span class="pre">ding/policy/common_utils.py</span></code> for more details.</p>
<section id="default-preprocess-learn">
<h3>default_preprocess_learn<a class="headerlink" href="#default-preprocess-learn" title="Permalink to this headline">¶</a></h3>
</section>
<section id="single-env-forward-wrapper">
<h3>single_env_forward_wrapper<a class="headerlink" href="#single-env-forward-wrapper" title="Permalink to this headline">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="ding.policy.single_env_forward_wrapper">
<span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">single_env_forward_wrapper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_fn</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/common_utils.html#single_env_forward_wrapper"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.single_env_forward_wrapper" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="single-env-forward-wrapper-ttorch">
<h3>single_env_forward_wrapper_ttorch<a class="headerlink" href="#single-env-forward-wrapper-ttorch" title="Permalink to this headline">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="ding.policy.single_env_forward_wrapper_ttorch">
<span class="sig-prename descclassname"><span class="pre">ding.policy.</span></span><span class="sig-name descname"><span class="pre">single_env_forward_wrapper_ttorch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cuda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/common_utils.html#single_env_forward_wrapper_ttorch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.single_env_forward_wrapper_ttorch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
</section>
</section>


              </article>
              
            </div>
            <footer>
  
  <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
    
    <a href="framework/index.html" class="btn btn-neutral float-right" title="Framework" accesskey="n"
      rel="next">Next <img src="../_static/images/chevron-right-blue.svg"
        class="next-page"></a>
    
    
    <a href="model.html" class="btn btn-neutral" title="ding.model" accesskey="p"
      rel="prev"><img src="../_static/images/chevron-right-blue.svg" class="previous-page"> Previous</a>
    
  </div>
  

  <hr>

  <div role="contentinfo">
    <p>
      &copy; Copyright 2021, OpenDILab Contributors.

    </p>
  </div>
  
  <div>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a
      href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the
      Docs</a>.
  </div>
   

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">ding.policy</a><ul>
<li><a class="reference internal" href="#base-policy">Base Policy</a><ul>
<li><a class="reference internal" href="#policy">Policy</a></li>
<li><a class="reference internal" href="#commandmodepolicy">CommandModePolicy</a></li>
<li><a class="reference internal" href="#create-policy">create_policy</a></li>
<li><a class="reference internal" href="#get-policy-cls">get_policy_cls</a></li>
</ul>
</li>
<li><a class="reference internal" href="#dqn">DQN</a><ul>
<li><a class="reference internal" href="#dqnpolicy">DQNPolicy</a></li>
<li><a class="reference internal" href="#dqnstdimpolicy">DQNSTDIMPolicy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#ppo">PPO</a><ul>
<li><a class="reference internal" href="#ppopolicy">PPOPolicy</a></li>
<li><a class="reference internal" href="#ppopgpolicy">PPOPGPolicy</a></li>
<li><a class="reference internal" href="#ppooffpolicy">PPOOffPolicy</a></li>
<li><a class="reference internal" href="#ppostdimpolicy">PPOSTDIMPolicy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#bc">BC</a><ul>
<li><a class="reference internal" href="#behaviourcloningpolicy">BehaviourCloningPolicy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#ddpg">DDPG</a><ul>
<li><a class="reference internal" href="#ddpgpolicy">DDPGPolicy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#td3">TD3</a><ul>
<li><a class="reference internal" href="#td3policy">TD3Policy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sac">SAC</a><ul>
<li><a class="reference internal" href="#sacpolicy">SACPolicy</a></li>
<li><a class="reference internal" href="#discretesacpolicy">DiscreteSACPolicy</a></li>
<li><a class="reference internal" href="#sqilsacpolicy">SQILSACPolicy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#r2d2">R2D2</a><ul>
<li><a class="reference internal" href="#r2d2policy">R2D2Policy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#impala">IMPALA</a><ul>
<li><a class="reference internal" href="#impalapolicy">IMPALAPolicy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#qmix">QMIX</a><ul>
<li><a class="reference internal" href="#qmixpolicy">QMIXPolicy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#cql">CQL</a><ul>
<li><a class="reference internal" href="#cqlpolicy">CQLPolicy</a></li>
<li><a class="reference internal" href="#discretecqlpolicy">DiscreteCQLPolicy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#decisiontransformer">DecisionTransformer</a><ul>
<li><a class="reference internal" href="#dtpolicy">DTPolicy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#pdqn">PDQN</a><ul>
<li><a class="reference internal" href="#pdqnpolicy">PDQNPolicy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#mdqn">MDQN</a><ul>
<li><a class="reference internal" href="#mdqnpolicy">MDQNPolicy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#policy-factory">Policy Factory</a><ul>
<li><a class="reference internal" href="#policyfactory">PolicyFactory</a></li>
<li><a class="reference internal" href="#get-random-policy">get_random_policy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#common-utilities">Common Utilities</a><ul>
<li><a class="reference internal" href="#default-preprocess-learn">default_preprocess_learn</a></li>
<li><a class="reference internal" href="#single-env-forward-wrapper">single_env_forward_wrapper</a></li>
<li><a class="reference internal" href="#single-env-forward-wrapper-ttorch">single_env_forward_wrapper_ttorch</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="../"
    src="../_static/documentation_options.js"></script>
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
  <script src="../_static/jquery.js"></script>
  <script src="../_static/underscore.js"></script>
  <script src="../_static/doctools.js"></script>
  

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  </div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/" aria-label="OpenMMLab"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/DI-engine" target="_blank">GitHub</a>
          </li>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>