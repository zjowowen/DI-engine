


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>PPG &mdash; DI-engine 0.1.0 documentation</title>
  

  <link rel="shortcut icon" href="../../_static/images/favicon.ico" />
  
  

  

  
  
  

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/style.css" type="text/css" />
  <link rel="index" title="Index" href="../../genindex.html" />
  <link rel="search" title="Search" href="../../search.html" />
  <link rel="next" title="Model" href="../model/index.html" />
  <link rel="prev" title="CollaQ" href="collaq.html" />
    <link href="../../_static/css/style.css" rel="stylesheet" type="text/css">


  
  <script src="../../_static/js/modernizr.min.js"></script>
  <script>
    MathJax = {
        chtml: {
            scale: 1,
            minScale: 1,
        },
        svg: {
            scale: 1,
            minScale: 1,
        }
    }
</script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/"
        aria-label="OpenMMLab"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/DI-engine" target="_blank">GitHub</a>
          </li>
          <li >
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a
                class="resource-option with-down-arrow">
                OpenDILab
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-engine" target="_blank">
                  <span class="dropdown-title">DI-engine </span>
                  <p>OpenDILab Decision AI Engine</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-star" target="_blank">
                  <span class="dropdown-title">DI-star </span>
                  <p>OpenDILab Decision AI in StarCraftII</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-drive" target="_blank">
                  <span class="dropdown-title">DI-drive </span>
                  <p>OpenDILab Auto-driving platform</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/GoBigger" target="_blank">
                  <span class="dropdown-title">GoBigger </span>
                  <p>OpenDILab Multi-Agent Environment</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-smartcross" target="_blank">
                  <span class="dropdown-title">DI-smartcross </span>
                  <p>Decision Intelligence Platform for Traffic Crossing Signal Control</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-treetensor" target="_blank">
                  <span class="dropdown-title">DI-treetensor </span>
                  <p>Tree Nested PyTorch Tensor Lib</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-model-based-RL" target="_blank">
                  <span class="dropdown-title">awesome-model-based-RL </span>
                  <p>A curated list of awesome model based RL resources (continually updated)</p>
                </a>
              </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../00_intro/index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01_quickstart/index.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../02_algo/index.html">RL Algorithm Taxonomy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../03_system/index.html">System Design</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">API Doc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../06_faq/index.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reinforcement Learning Tutorial</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../10_concepts/index.html">Introduction to RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11_dizoo/index.html">Learn From DI-zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12_policies/index.html">RL Algorithms Cheat Sheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../13_envs/index.html">RL Env Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../20_spec/index.html">Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../21_code_style/index.html">Code Style Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../22_test/index.html">Unit Test Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../23_visual/index.html">Diagrams and Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../24_cooperation/index.html">Github Cooperation</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
            Docs
        </a> &gt;
      </li>

        
          <li><a href="../index.html">API Doc</a> &gt;</li>
        
          <li><a href="index.html">Policy</a> &gt;</li>
        
      <li>PPG</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../../_sources/05_api_doc/policy/ppg.rst.txt" rel="nofollow"><img src="../../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
  <section id="ppg">
<h1>PPG<a class="headerlink" href="#ppg" title="Permalink to this headline">¶</a></h1>
<section id="ppgpolicy">
<h2>PPGPolicy<a class="headerlink" href="#ppgpolicy" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.ppg.PPGPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.ppg.</span></span><span class="sig-name descname"><span class="pre">PPGPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/ding/policy/ppg.html#PPGPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.ppg.PPGPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Policy class of PPG algorithm.</p>
</dd>
<dt>Interface:</dt><dd><p>_init_learn, _data_preprocess_learn, _forward_learn, _state_dict_learn, _load_state_dict_learn            _init_collect, _forward_collect, _process_transition, _get_train_sample, _get_batch_size, _init_eval,            _forward_eval, default_model, _monitor_vars_learn, learn_aux</p>
</dd>
<dt>Config:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 2%" />
<col style="width: 19%" />
<col style="width: 7%" />
<col style="width: 13%" />
<col style="width: 37%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Symbol</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Other(Shape)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">type</span></code></p></td>
<td><p>str</p></td>
<td><p>ppg</p></td>
<td><div class="line-block">
<div class="line">RL policy register name, refer to</div>
<div class="line">registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line">this arg is optional,</div>
<div class="line">a placeholder</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cuda</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to use cuda for network</div>
</div>
</td>
<td><div class="line-block">
<div class="line">this arg can be diff-</div>
<div class="line">erent from modes</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">on_policy</span></code></p></td>
<td><p>bool</p></td>
<td><p>True</p></td>
<td><div class="line-block">
<div class="line">Whether the RL algorithm is on-policy</div>
<div class="line">or off-policy</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><ol class="arabic simple" start="4">
<li></li>
</ol>
</td>
<td><p><code class="docutils literal notranslate"><span class="pre">priority</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use priority(PER)</div>
</div>
</td>
<td><div class="line-block">
<div class="line">priority sample,</div>
<div class="line">update priority</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">priority_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">IS_weight</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use Importance Sampling</div>
<div class="line">Weight to correct biased update.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">IS weight</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.update</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_per_collect</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>5</p></td>
<td><div class="line-block">
<div class="line">How many updates(iterations) to train</div>
<div class="line">after collector’s one collection. Only</div>
<div class="line">valid in serial training</div>
</div>
</td>
<td><div class="line-block">
<div class="line">this args can be vary</div>
<div class="line">from envs. Bigger val</div>
<div class="line">means more off-policy</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.value_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">weight</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>1.0</p></td>
<td><div class="line-block">
<div class="line">The loss weight of value network</div>
</div>
</td>
<td><div class="line-block">
<div class="line">policy network weight</div>
<div class="line">is set to 1</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.entropy_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">weight</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.01</p></td>
<td><div class="line-block">
<div class="line">The loss weight of entropy</div>
<div class="line">regularization</div>
</div>
</td>
<td><div class="line-block">
<div class="line">policy network weight</div>
<div class="line">is set to 1</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.clip_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">ratio</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.2</p></td>
<td><div class="line-block">
<div class="line">PPO clip ratio</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.adv_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">norm</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to use advantage norm in</div>
<div class="line">a whole training batch</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>11</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.aux_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">freq</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>5</p></td>
<td><div class="line-block">
<div class="line">The frequency(normal update times)</div>
<div class="line">of auxiliary phase training</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>12</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.aux_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">train_epoch</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>6</p></td>
<td><div class="line-block">
<div class="line">The training epochs of auxiliary</div>
<div class="line">phase</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>13</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.aux_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">bc_weight</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>1</p></td>
<td><div class="line-block">
<div class="line">The loss weight of behavioral_cloning</div>
<div class="line">in auxiliary phase</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>14</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect.dis</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">count_factor</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.99</p></td>
<td><div class="line-block">
<div class="line">Reward’s future discount factor, aka.</div>
<div class="line">gamma</div>
</div>
</td>
<td><div class="line-block">
<div class="line">may be 1 when sparse</div>
<div class="line">reward env</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>15</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect.gae_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">lambda</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.95</p></td>
<td><div class="line-block">
<div class="line">GAE lambda factor for the balance</div>
<div class="line">of bias and variance(1-step td and mc)</div>
</div>
</td>
<td></td>
</tr>
</tbody>
</table>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.ppg.PPGPolicy._data_preprocess_learn">
<span class="sig-name descname"><span class="pre">_data_preprocess_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../../_modules/ding/policy/ppg.html#PPGPolicy._data_preprocess_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.ppg.PPGPolicy._data_preprocess_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Preprocess the data to fit the required data format for learning, including             collate(stack data into batch), ignore done(in some fake terminate env),            prepare loss weight per training sample, and cpu tensor to cuda.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[Dict[str,</span> <span class="pre">Any]]</span></code>): the data collected from collect function</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): the processed data, including at least [‘done’, ‘weight’]</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.ppg.PPGPolicy._forward_collect">
<span class="sig-name descname"><span class="pre">_forward_collect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../../_modules/ding/policy/ppg.html#PPGPolicy._forward_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.ppg.PPGPolicy._forward_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward function of collect mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action), </dt><dd><p>values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): Dict type data, including at least inferred action according to input obs.</p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.ppg.PPGPolicy._forward_eval">
<span class="sig-name descname"><span class="pre">_forward_eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../../_modules/ding/policy/ppg.html#PPGPolicy._forward_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.ppg.PPGPolicy._forward_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward function of eval mode, similar to <code class="docutils literal notranslate"><span class="pre">self._forward_collect</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action), </dt><dd><p>values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): The dict of predicting action for the interaction with env.</p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.ppg.PPGPolicy._forward_learn">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/ding/policy/ppg.html#PPGPolicy._forward_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.ppg.PPGPolicy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Forward and backward function of learn mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a batch of data for training, values are torch.Tensor or                 np.ndarray or dict/list combinations.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a info dict indicated training result, which will be                 recorded in text log and tensorboard, values are python scalar or a list of scalars.</p></li>
</ul>
</dd>
<dt>ArgumentsKeys:</dt><dd><ul class="simple">
<li><p>necessary: ‘obs’, ‘logit’, ‘action’, ‘value’, ‘reward’, ‘done’</p></li>
</ul>
</dd>
<dt>ReturnsKeys:</dt><dd><ul>
<li><p>necessary: current lr, total_loss, policy_loss, value_loss, entropy_loss,                         adv_abs_max, approx_kl, clipfrac                        aux_value_loss, auxiliary_loss, behavioral_cloning_loss</p>
<blockquote>
<div><ul class="simple">
<li><p>current_lr (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): Current learning rate</p></li>
<li><p>total_loss (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The calculated loss</p></li>
<li><p>policy_loss (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The policy(actor) loss of ppg</p></li>
<li><p>value_loss (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The value(critic) loss of ppg</p></li>
<li><p>entropy_loss (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The entropy loss</p></li>
<li><p>auxiliary_loss (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The auxiliary loss, we use the value function loss                     as the auxiliary objective, thereby sharing features between the policy and value function                    while minimizing distortions to the policy</p></li>
<li><p>aux_value_loss (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The auxiliary value loss, we need to train the value network extra                     during the auxiliary phase, it’s the value loss we train the value network during auxiliary phase</p></li>
<li><p>behavioral_cloning_loss (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The behavioral cloning loss, used to optimize the auxiliary                     objective while otherwise preserving the original policy</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.ppg.PPGPolicy._get_batch_size">
<span class="sig-name descname"><span class="pre">_get_batch_size</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/ding/policy/ppg.html#PPGPolicy._get_batch_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.ppg.PPGPolicy._get_batch_size" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Get learn batch size. In the PPG algorithm, different networks require different data.            We need to get data[‘policy’] and data[‘value’] to train policy net and value net,            this function is used to get the batch size of data[‘policy’] and data[‘value’].</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict[str,</span> <span class="pre">int]</span></code>): Dict type data, including str type batch size and int type batch size.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.ppg.PPGPolicy._get_train_sample">
<span class="sig-name descname"><span class="pre">_get_train_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/ding/policy/ppg.html#PPGPolicy._get_train_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.ppg.PPGPolicy._get_train_sample" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Get the trajectory and calculate GAE, return one data to cache for next time calculation</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code>): The trajectory’s cache</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>samples (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): The training samples generated</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.ppg.PPGPolicy._init_collect">
<span class="sig-name descname"><span class="pre">_init_collect</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../../_modules/ding/policy/ppg.html#PPGPolicy._init_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.ppg.PPGPolicy._init_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init unroll length, collect model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.ppg.PPGPolicy._init_eval">
<span class="sig-name descname"><span class="pre">_init_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../../_modules/ding/policy/ppg.html#PPGPolicy._init_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.ppg.PPGPolicy._init_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init eval model with argmax strategy.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.ppg.PPGPolicy._init_learn">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../../_modules/ding/policy/ppg.html#PPGPolicy._init_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.ppg.PPGPolicy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Learn mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>.
Init the optimizer, algorithm config and the main model.</p>
</dd>
<dt>Arguments:</dt><dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>The _init_learn method takes the argument from the self._cfg.learn in the config file</p>
</div>
<ul class="simple">
<li><p>learning_rate (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): The learning rate fo the optimizer</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.ppg.PPGPolicy._load_state_dict_learn">
<span class="sig-name descname"><span class="pre">_load_state_dict_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../../_modules/ding/policy/ppg.html#PPGPolicy._load_state_dict_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.ppg.PPGPolicy._load_state_dict_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Load the state_dict variable into policy learn mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): the dict of policy learn state saved before.                When the value is distilled into the policy network, we need to make sure the policy                 network does not change the action predictions, we need two optimizers,                 _optimizer_ac is used in policy net, and _optimizer_aux_critic is used in value net.</p></li>
</ul>
</dd>
</dl>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If you want to only load some parts of model, you can simply set the <code class="docutils literal notranslate"><span class="pre">strict</span></code> argument in             load_state_dict to <code class="docutils literal notranslate"><span class="pre">False</span></code>, or refer to <code class="docutils literal notranslate"><span class="pre">ding.torch_utils.checkpoint_helper</span></code> for more             complicated operation.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.ppg.PPGPolicy._monitor_vars_learn">
<span class="sig-name descname"><span class="pre">_monitor_vars_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/ding/policy/ppg.html#PPGPolicy._monitor_vars_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.ppg.PPGPolicy._monitor_vars_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return variables’ name if variables are to used in monitor.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>vars (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[str]</span></code>): Variables’ name list.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.ppg.PPGPolicy._process_transition">
<span class="sig-name descname"><span class="pre">_process_transition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_output</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timestep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">collections.namedtuple</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="../../_modules/ding/policy/ppg.html#PPGPolicy._process_transition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.ppg.PPGPolicy._process_transition" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Generate dict type transition data from inputs.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>obs (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>): Env observation</p></li>
<li><p>model_output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Output of collect model, including at least [‘action’]</p></li>
<li><p>timestep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">namedtuple</span></code>): Output after env step, including at least [‘obs’, ‘reward’, ‘done’]                       (here ‘obs’ indicates obs after env step).</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>transition (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type transition data.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.ppg.PPGPolicy._state_dict_learn">
<span class="sig-name descname"><span class="pre">_state_dict_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/ding/policy/ppg.html#PPGPolicy._state_dict_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.ppg.PPGPolicy._state_dict_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return the state_dict of learn mode, usually including model and optimizer.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): the dict of current policy learn state, for saving and restoring.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.ppg.PPGPolicy.default_model">
<span class="sig-name descname"><span class="pre">default_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/ding/policy/ppg.html#PPGPolicy.default_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.ppg.PPGPolicy.default_model" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return this algorithm default model setting for demonstration.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>model_info (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Tuple[str,</span> <span class="pre">List[str]]</span></code>): model name and mode import_names</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The user can define and use customized network model but must obey the same inferface definition indicated             by import_names path.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.ppg.PPGPolicy.learn_aux">
<span class="sig-name descname"><span class="pre">learn_aux</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/ding/policy/ppg.html#PPGPolicy.learn_aux"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.ppg.PPGPolicy.learn_aux" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>The auxiliary phase training, where the value is distilled into the policy network</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>aux_loss (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Tuple[torch.Tensor,</span> <span class="pre">torch.Tensor,</span> <span class="pre">torch.Tensor]</span></code>): including average auxiliary loss                average behavioral cloning loss, and average auxiliary value loss</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


              </article>
              
            </div>
            <footer>
  
  <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
    
    <a href="../model/index.html" class="btn btn-neutral float-right" title="Model" accesskey="n"
      rel="next">Next <img src="../../_static/images/chevron-right-blue.svg"
        class="next-page"></a>
    
    
    <a href="collaq.html" class="btn btn-neutral" title="CollaQ" accesskey="p"
      rel="prev"><img src="../../_static/images/chevron-right-blue.svg" class="previous-page"> Previous</a>
    
  </div>
  

  <hr>

  <div role="contentinfo">
    <p>
      &copy; Copyright 2021, OpenDILab Contributors.

    </p>
  </div>
  
  <div>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a
      href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the
      Docs</a>.
  </div>
   

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">PPG</a><ul>
<li><a class="reference internal" href="#ppgpolicy">PPGPolicy</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="../../"
    src="../../_static/documentation_options.js"></script>
  <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
  <script src="../../_static/jquery.js"></script>
  <script src="../../_static/underscore.js"></script>
  <script src="../../_static/doctools.js"></script>
  

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  </div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/" aria-label="OpenMMLab"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/DI-engine" target="_blank">GitHub</a>
          </li>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>